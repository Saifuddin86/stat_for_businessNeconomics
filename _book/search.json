[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Business and Economics",
    "section": "",
    "text": "Preface\nThis book is specially for the undergrad students of Business and Economics program providing basic to advance statistical tools and techniques to handle data .",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Data and Statistics",
    "section": "",
    "text": "1.1 Statistics\nStatistics is defined as the art and science of collecting, analyzing, presenting, and interpreting data.\nParticularly in business and economics, the information provided by collecting, analyzing, presenting, and interpreting data gives managers and decision makers a better understanding of the business and economic environment and thus enables them to make more informed and better decisions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#applications-in-business-and-economics",
    "href": "intro.html#applications-in-business-and-economics",
    "title": "1  Data and Statistics",
    "section": "1.2 Applications in Business and Economics",
    "text": "1.2 Applications in Business and Economics\n\nAccounting Public accounting firms use statistical sampling procedures when conducting audits for their clients.\nFinance Financial analysts use a variety of statistical information to guide their investment recommendations.\nMarketing Electronic scanners at retail checkout counters collect data for a variety of marketing research applications.\nProduction Today’s emphasis on quality makes quality control an important application of statistics in production.\nEconomics Economists frequently provide forecasts about the future of the economy or some aspect of it. They use a variety of statistical information in making such forecasts.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#data",
    "href": "intro.html#data",
    "title": "1  Data and Statistics",
    "section": "1.3 Data",
    "text": "1.3 Data\nData are the facts and figures collected, analyzed, and summarized for presentation and interpretation. All the data collected in a particular study are referred to as the data set for the study.\nTable 1.1 shows a data set containing information for 25 mutual funds that are part of the Morningstar Funds500 for 2008.\n\n\n\nTable 1.1: Data Set For 25 Mutual Funds\n\n\n\n\n\n\n\n\n\n\n\n\n\nFund Name\nFund Type\nNet Asset Value ($)\n5-Year Average Return (%)\nExpense Ratio (%)\nMorningstar Rank\n\n\n\n\nAmerican Century Intl. Disc\nIE\n14.37\n30.53\n1.41\n3-Star\n\n\nAmerican Century Tax-Free Bond\nFI\n10.73\n3.34\n0.49\n4-Star\n\n\nAmerican Century Ultra\nDE\n29.84\n15.04\n0.97\n3-Star\n\n\nArtisan Small Cap\nDE\n16.52\n18.87\n1.25\n4-Star\n\n\nBrown Cap Small\nDE\n33.97\n15.53\n1.08\n3-Star\n\n\nDFA U.S. Micro Cap\nDE\n18.33\n17.57\n0.52\n5-Star\n\n\nFidelity Contrafund\nDE\n49.80\n12.36\n0.89\n4-Star\n\n\nFidelity Overseas\nIE\n48.99\n23.06\n1.06\n3-Star\n\n\nFidelity Sel Electronics\nDE\n22.40\n17.70\n0.89\n4-Star\n\n\nFidelity Sh-Term Bond\nFI\n17.46\n4.10\n0.45\n3-Star\n\n\nGabelli Asset AAA\nDE\n48.84\n15.70\n1.36\n4-Star\n\n\nKalmar Grwth Sm Cp\nDE\n40.13\n16.20\n1.25\n3-Star\n\n\nMairs & Power Grwth\nDE\n27.64\n12.70\n0.69\n5-Star\n\n\nMatthews Pacific Tiger\nIE\n40.07\n19.51\n1.05\n4-Star\n\n\nOakmark I\nDE\n37.78\n9.57\n1.06\n4-Star\n\n\nPIMCO Emerg Mkts Bd D\nFI\n26.39\n12.31\n1.00\n3-Star\n\n\nRS Value A\nDE\n22.67\n15.14\n1.44\n3-Star\n\n\nT. Rowe Price Latin Am.\nIE\n33.59\n32.06\n1.24\n4-Star\n\n\nT. Rowe Price Mid Val\nDE\n26.37\n14.40\n0.80\n4-Star\n\n\nThornburg Int’l Val\nIE\n21.10\n23.64\n1.40\n5-Star\n\n\nUSAA Income\nFI\n12.10\n5.13\n0.62\n3-Star\n\n\nVanguard Sel Val\nDE\n21.23\n16.20\n0.44\n4-Star\n\n\nVanguard Sh-Tm TE\nFI\n11.20\n3.80\n0.13\n3-Star\n\n\nVanguard Sm Cp Idx\nDE\n25.32\n17.01\n0.23\n5-Star\n\n\nWasatch Sm Cp Growth\nDE\n35.41\n13.98\n1.19\n4-Star",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#elements-variables-and-observations",
    "href": "intro.html#elements-variables-and-observations",
    "title": "1  Data and Statistics",
    "section": "1.4 Elements, Variables, and Observations",
    "text": "1.4 Elements, Variables, and Observations\nElements are the entities on which data are collected. For the data set in Table 1.1 each individual mutual fund is an element: the element names appear in the first column. With 25 mutual funds, the data set contains 25 elements.\nA variable is a characteristic of interest for the elements.\nThe data set in Table 1.1 includes the following five variables:\n\nFund Type: The type of mutual fund\nNet Asset Value ($): The closing price per share on December 31, 2007\n5-Year Average Return (%): The average annual return for the fund over the past 5 years\nExpense Ratio: The percentage of assets deducted each fiscal year for fund expenses\nMorningstar Rank: The overall risk-adjusted star rating for each fund; Morningstar ranks go from a low of 1-Star to a high of 5-Stars\n\nObservation Measurements collected on each variable for every element in a study provide the data. The set of measurements obtained for a particular element is called an observation.\n\nReferring to Table 1.1 we see that the set of measurements for the first observation (American Century Intl. Disc) is IE, 14.37, 30.53, 1.41, and 3-Star.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#scales-of-measurement",
    "href": "intro.html#scales-of-measurement",
    "title": "1  Data and Statistics",
    "section": "1.5 Scales of Measurement",
    "text": "1.5 Scales of Measurement\nData collection requires one of the following scales of measurement: nominal, ordinal, interval, or ratio .\n\nWhen the data for a variable consist of labels or names used to identify an attribute of the element, the scale of measurement is considered a nominal scale ( Example: Fund Type).\nThe scale of measurement for a variable is called an ordinal scale if the data exhibit the properties of nominal data and the order or rank of the data is meaningful ( Example: Morningstar Rank).\nThe scale of measurement for a variable is an interval scale if the data have all the properties of ordinal data and the interval between values is expressed in terms of a fixed unit of measure. Interval data are always numeric ( Example: Temperature ).\nThe scale of measurement for a variable is a ratio scale if the data have all the properties of interval data and the ratio of two values is meaningful ( Example: distance, height, weight,time etc.).\n\nThis scale requires that a zero value be included to indicate that nothing exists for the variable at the zero point.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#quantitative-and-categorical-and-data",
    "href": "intro.html#quantitative-and-categorical-and-data",
    "title": "1  Data and Statistics",
    "section": "1.6 Quantitative and Categorical and Data",
    "text": "1.6 Quantitative and Categorical and Data\nData can be classified as either quantitative or categorical .\nQuantitative Data (Numerical Data)\n\nData that represents numerical values.\nExample: Heights of people, temperatures, test scores.\nSubtypes:\n\nDiscrete Data: Countable values (e.g., number of students in a class).\nContinuous Data: Measurable values that can take any value within a range (e.g., weight, time).\n\n\nQualitative Data (Categorical Data)\n\nData that represents categories or labels.\nExample: Colors of cars, types of animals, survey responses (e.g., yes/no).\nSubtypes:\n\nNominal Data: Categories without a natural order (e.g., gender, blood type).\nOrdinal Data: Categories with a meaningful order (e.g., rankings, education levels).\n\n\nThe statistical analysis appropriate for a particular variable depends upon whether the variable is categorical or quantitative.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#cross-sectional-and-time-series-data",
    "href": "intro.html#cross-sectional-and-time-series-data",
    "title": "1  Data and Statistics",
    "section": "1.7 Cross-Sectional and Time Series Data",
    "text": "1.7 Cross-Sectional and Time Series Data\nFor purposes of statistical analysis, distinguishing between cross-sectional data and time series data is important.\nCross-sectional data are data collected at the same or approximately the same point in time. The data in Table 1.1 are cross-sectional because they describe the five variables for the 25 mutual funds at the same point in time.\nTime series data are data collected over several time periods. For example, the time series in Figure 1.1 shows the U.S. average price per gallon of conventional regular gasoline between 2006 and 2009.\n\n\n\n\n\n\nFigure 1.1: U.S. Average price per gallon for conventional regular gasoline",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#descriptive-statistics",
    "href": "intro.html#descriptive-statistics",
    "title": "1  Data and Statistics",
    "section": "1.8 Descriptive Statistics",
    "text": "1.8 Descriptive Statistics\nMost of the statistical information in newspapers, magazines, company reports, and other publications consists of data that are summarized and presented in a form that is easy for the reader to understand. Such summaries of data, which may be tabular, graphical, or numerical, are referred to as descriptive statistics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#inferential-statistics-statistical-inference",
    "href": "intro.html#inferential-statistics-statistical-inference",
    "title": "1  Data and Statistics",
    "section": "1.9 Inferential statistics (Statistical Inference)",
    "text": "1.9 Inferential statistics (Statistical Inference)\nMany situations require information about a large group of elements (individuals, companies, voters, households, products, customers, and so on). But, because of time, cost, and other considerations, data can be collected from only a small portion of the group. The larger group of elements in a particular study is called the population, and the smaller group is called the sample. Formally, we use the following definitions.\n\nPopulation A population is the set of all elements of interest in a particular study.\nSample A sample is a subset of the population.\n\nThe process of conducting a survey to collect data for the entire population is called a census.\nThe process of conducting a survey to collect data for a sample is called a sample survey.\nAs one of its major contributions, statistics uses data from a sample to make estimates and test hypotheses about the characteristics of a population through a process referred to as statistical inference.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "intro.html#exercise",
    "href": "intro.html#exercise",
    "title": "1  Data and Statistics",
    "section": "1.10 Exercise",
    "text": "1.10 Exercise\n\nWhat is the level of measurement / categorical (nominal, ordinal ) or quantitative (discrete, continuous) for each of the following variables?\n\n\n\nStudent IQ ratings.\nDistance students travel to class.\nThe jersey numbers of a sorority soccer team.\nA classification of students by state of birth.\nA summary of students by academic class—that is, freshman, sophomore, junior, and senior.\nNumber of hours students study per week.\n\n\n\nWhat is the level of measurement / categorical (nominal, ordinal ) or quantitative (discrete, continuous) for these items related to the newspaper business?\n\n\n\nThe number of papers sold each Sunday during 2011.\nThe departments, such as editorial, advertising, sports, etc.\nA summary of the number of papers sold by county.\nThe number of years with the paper for each employee.\n\n\n\nWhat is the level of measurement / categorical (nominal, ordinal ) or quantitative (discrete, continuous) for these following items?\n\n\n\nSalary\nGender\nSales volume of MP3 players\nSoft drink preference\nTemperature\nSAT scores\nStudent rank in class\nRating of a finance professor\nNumber of home computers\n\n\n\nFor each of the following, determine whether the group is a sample or a population.\n\n\n\nThe participants in a study of a new cholesterol drug.\nThe drivers who received a speeding ticket in Kansas City last month.\nThose on welfare in Cook County (Chicago), Illinois.\nThe 30 stocks reported as a part of the Dow Jones Industrial Average.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data and Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html",
    "href": "descriptive_graph_tab.html",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "",
    "text": "2.1 Summarizing Categorical Data\nFrequency Distribution\nA frequency distribution is a tabular summary of data showing the number (frequency) of items in each of several non overlapping classes.\nExample 2.1 Consider the following data shown in Table 2.1.\nNow we will construct a frequency distribution by simply counting each type of soft-drink.\nCode\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(knitr)\nMBA &lt;- read_excel(\"StatForBandE_data.xlsx\",sheet = \"Sheet1\",range = \"A1:A51\")\n\nMBA %&gt;% count(`Soft Drink`) %&gt;% kable(col.names = c(\"Soft Drink\",\"Frequency\"),align = c(\"l\",\"c\"))\n\n\n\n\nTable 2.2: Frequency distribution of Soft Drink Purchases\n\n\n\n\n\n\nSoft Drink\nFrequency\n\n\n\n\nCoke Classic\n19\n\n\nDiet Coke\n8\n\n\nDr. Pepper\n5\n\n\nPepsi\n13\n\n\nSprite\n5\nRelative Frequency and Percent Frequency Distributions",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#summarizing-categorical-data",
    "href": "descriptive_graph_tab.html#summarizing-categorical-data",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "",
    "text": "Table 2.1: Data from a sample of 50 soft drink purchases\n\n\n\n\n\nCoke Classic\nCoke Classic\nCoke Classic\n\n\nDiet Coke\nDiet Coke\nCoke Classic\n\n\nPepsi\nCoke Classic\nPepsi\n\n\nDiet Coke\nDiet Coke\nDr. Pepper\n\n\nCoke Classic\nCoke Classic\nCoke Classic\n\n\nCoke Classic\nSprite\nDiet Coke\n\n\nDr. Pepper\nPepsi\nPepsi\n\n\nDiet Coke\nCoke Classic\nPepsi\n\n\nPepsi\nCoke Classic\nPepsi\n\n\nPepsi\nCoke Classic\nPepsi\n\n\nCoke Classic\nPepsi\nCoke Classic\n\n\nDr. Pepper\nCoke Classic\nDr. Pepper\n\n\nSprite\nSprite\nPepsi\n\n\nCoke Classic\nDr. Pepper\nSprite\n\n\nDiet Coke\nPepsi\nCoke Classic\n\n\nCoke Classic\nDiet Coke\nSprite\n\n\nCoke Classic\nPepsi\n\n\n\n\n\n\n\n\n\n\n\nRelative Frequency \\(=\\frac{Frequency \\ \\ of \\ \\ the \\ \\ class}{n}\\)\nThe percent frequency of a class is the relative frequency multiplied by 100.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#bar-charts-and-pie-charts",
    "href": "descriptive_graph_tab.html#bar-charts-and-pie-charts",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.2 Bar Charts and Pie Charts",
    "text": "2.2 Bar Charts and Pie Charts\n\nBar chart: A graphical device for depicting qualitative data that have been summarized in a frequency, relative frequency, or percent frequency distribution.\nPie chart: A graphical device for presenting data summaries based on subdivision of a circle into sectors that correspond to the relative frequency for each class.\n\nFrom the frequency table of soft drinks purchase, we will develop relative and percent frequency distribution (see Table 2.3) and will construct a bar-chart and pie-chart.\n\n\nCode\nMBA %&gt;% count(`Soft Drink`) %&gt;% mutate(RF=n/sum(n),PF=RF*100) %&gt;%\n  kable(digits = 2,col.names = c(\"Soft Drink\",\"Frequency (f)\",\"Relative Frequency(Rf)\", \"Percent Frequency (Pf)\"),\n        align = c(\"l\",\"c\",\"c\",\"c\"))\n\n\n\n\nTable 2.3: Frequency, Relative And Percent Frequency Distributions Of Soft Drink Purchases\n\n\n\n\n\n\n\n\n\n\n\n\nSoft Drink\nFrequency (f)\nRelative Frequency(Rf)\nPercent Frequency (Pf)\n\n\n\n\nCoke Classic\n19\n0.38\n38\n\n\nDiet Coke\n8\n0.16\n16\n\n\nDr. Pepper\n5\n0.10\n10\n\n\nPepsi\n13\n0.26\n26\n\n\nSprite\n5\n0.10\n10\n\n\n\n\n\n\n\n\nNow we construct a bar chart and pie chart.\n\n\nCode\nlibrary(patchwork)\n\nbar&lt;-MBA %&gt;% ggplot(aes(x=`Soft Drink`,fill=`Soft Drink`))+\n  geom_bar(color=\"black\",lwd=.7)+\n  scale_y_continuous(breaks = seq(0,30,2))+\n  guides(fill=FALSE)+\n  theme_classic()+\n  #labs(title = \"BAR CHART OF SOFT DRINK PURCHASES\",y=\"Frequency\")+\n  theme(axis.text=  element_text(color = \"black\"))\n  \nbar\n\n\n\n\n\n\n\n\nFigure 2.1: Bar chart of Soft drink purchases\n\n\n\n\n\n\n\nCode\npi_data&lt;-MBA %&gt;% count(`Soft Drink`) %&gt;% mutate(RF=n/sum(n),labels = scales::percent(RF))\n\n\npi_chart&lt;-ggplot(pi_data, aes(x = \"\", y = RF, fill = `Soft Drink`)) +\n  geom_col() +\n  geom_label(aes(label = labels),color = c(\"white\",\"white\",\"white\",\"white\",\"black\"),\n            position = position_stack(vjust = 0.5),\n            show.legend = FALSE,color=\"white\") +\n  guides(fill = guide_legend(title = \"Soft Drink\")) +\n  scale_fill_viridis_d() +\n  coord_polar(theta = \"y\") + \n  #labs(title = \"PIE CHART OF SOFT DRINK PURCHASES\")+ \n  theme_void()\n\npi_chart\n\n\n\n\n\n\n\n\nFigure 2.2: Pie chart of Soft drink purchases",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#summarizing-quantitative-data",
    "href": "descriptive_graph_tab.html#summarizing-quantitative-data",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.3 Summarizing Quantitative Data",
    "text": "2.3 Summarizing Quantitative Data\nFrequency Distribution of quantitative data: Consider the following data.\nYEAR-END AUDIT TIMES (IN DAYS): 12, 14, 19, 18, 15, 15, 18, 17, 20, 27, 22, 23, 22, 21, 33, 28, 14, 18, 16, 13,\n\n\nCode\nAudit&lt;-c(12, 14, 19, 18, 15, 15, 18, 17,\n20, 27, 22, 23, 22, 21, 33, 28,14, 18, 16, 13)\n#summary(Audit)\n\n\nTo construct a frequency distribution we have to\n\nDetermine the number of non overlapping classes(k).\nDetermine the width of each class.\nDetermine the class limits.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#frequency-distribution-of-quantitative-data",
    "href": "descriptive_graph_tab.html#frequency-distribution-of-quantitative-data",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.4 Frequency Distribution of quantitative data",
    "text": "2.4 Frequency Distribution of quantitative data\nHere, \\(n=20\\), Smallest value=12, Largest value=33.\n\nDetermine number of classes, \\(k\\) as : \\(k=\\sqrt n=\\sqrt 20=4.47\\approx5\\). So \\(5\\) is the number of classes.\nClass width \\(w\\) as: \\(w=\\frac{Largest-Smallest}{k}=\\frac{33-12}{5}=4.2\\approx 5\\)\nClass limits: Start from near smallest value (12) say from \\(10\\) we have the following classes (exclusive method-where upper bound of the class is excluded):\n\n[10,15), [15,20), [20,25), [25,30), and [30,35)\nNow count the data values in corresponding classes and thus we have the frequency distribution. Once we have the frequency distribution then we also can produce the relative and percent frequency distribution (Table 2.4 ).\n\n\nCode\ndata.frame(Audit)-&gt;fd_data\n\nfd_data %&gt;% mutate(Audit_clas=ifelse(Audit%in%c(10:14),\"[10,15)\",\n                              ifelse(Audit%in%c(15:19),\"[15,20)\",\n                              ifelse(Audit%in%c(20:24),\"[20,25)\",                                         ifelse(Audit%in%c(25:29),\"[25,30)\",\"[30,35)\")))))-&gt;fd\n\nfd %&gt;% count(Audit_clas) %&gt;% mutate(rf=n/sum(n),pf=100*rf)-&gt;fd \n\nfd %&gt;% kable(digits = 2,col.names = c(\"Audit Time (days)\",\"Frequency (f) \",\"Rf\", \"Pf\"),align = \"c\")\n\n\n\n\nTable 2.4: Frequency, relative frequency (rf) and percent frequency (pf) distribution for the audit time data (n=20)\n\n\n\n\n\n\nAudit Time (days)\nFrequency (f)\nRf\nPf\n\n\n\n\n[10,15)\n4\n0.20\n20\n\n\n[15,20)\n8\n0.40\n40\n\n\n[20,25)\n5\n0.25\n25\n\n\n[25,30)\n2\n0.10\n10\n\n\n[30,35)\n1\n0.05\n5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#histogram",
    "href": "descriptive_graph_tab.html#histogram",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.5 Histogram",
    "text": "2.5 Histogram\nA common graphical presentation of quantitative data is a histogram. This graphical summary can be prepared for data previously summarized in either a frequency, relative frequency, or percent frequency distribution.\n\n\nCode\n#png(filename=\"HISTOGRAM.png\", width=600, height=600)\n\nfd %&gt;% ggplot(aes(x=Audit_clas,y=n))+geom_col(width =1,col=\"black\",fill=\"steelblue\")+\n  scale_y_continuous(breaks = 0:8)+\n  theme_classic()+\n  labs(x=\"Audit Time (days)\",y=\"Frequency\")\n\n#dev.off()\n\n\n\n\n\n\n\n\nFigure 2.3: HISTOGRAM FOR THE AUDIT TIME DATA",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#histogram-and-shape-of-the-distribution",
    "href": "descriptive_graph_tab.html#histogram-and-shape-of-the-distribution",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.6 HISTOGRAM and shape of the distribution",
    "text": "2.6 HISTOGRAM and shape of the distribution",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#cumulative-distributions",
    "href": "descriptive_graph_tab.html#cumulative-distributions",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.7 Cumulative Distributions",
    "text": "2.7 Cumulative Distributions\nA variation of the frequency distribution that provides another tabular summary of quantitative data is the cumulative frequency distribution.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#the-stem-and-leaf-display",
    "href": "descriptive_graph_tab.html#the-stem-and-leaf-display",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.8 The Stem-and-Leaf Display",
    "text": "2.8 The Stem-and-Leaf Display\nThe techniques of exploratory data analysis consist of simple arithmetic and easy-to-draw graphs that can be used to summarize data quickly. One technique—referred to as a stem-and-leaf display—can be used to show both the rank order and shape of a data set simultaneously (Anderson and Sweeney 2011).\nSteps to Construct a Stem-and-Leaf Diagram\n(1) Divide each number into two parts: a stem, consisting of one or more of the leading digits, and a leaf, consisting of the remaining digit.\n(2) List the stem values in a vertical column.\n(3) Record the leaf for each observation beside its stem.\n(4) Write the units for stems and leaves on the display.\n\nExample 2.2 Here are the number of questions answered correctly on an aptitude test given to 50 individuals recently interviewed for a position at Haskens Manufacturing.\n\nDataStem-and-leaf display\n\n\n112, 72, 69, 97, 107,73, 92, 76, 86, 73, 126, 128, 118, 127, 124,82, 104, 132, 134, 83, 92, 108, 96, 100, 92,115, 76, 91, 102, 81, 95, 141, 81, 80, 106,84, 119, 113, 98, 75, 68, 98, 115, 106, 95,100, 85, 94, 106, 119\n\n\n\n\nCode\nstemleaf=c(112,72,69,97,107,73,92,76,86,73,126,128,118,127,124,82,104,132,134,83,92,108,96,100,92,115,76,91,102,81,95,141,81,80,106,84,119,113,98,75,68,98,115,106,95,100,85,94,106,119)\n\n#summary(stemleaf)\n\nstem(stemleaf)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n   6 | 89\n   7 | 233566\n   8 | 01123456\n   9 | 12224556788\n  10 | 002466678\n  11 | 2355899\n  12 | 4678\n  13 | 24\n  14 | 1\n\n\n\n\n\nException\nIn some data sets, providing more classes or stems may be desirable. One way to do this would be to modify the original stems as follows: For example, divide stem 5 into two new stems, 5L and 5U. Stem 5L has leaves 0, 1, 2, 3, and 4, and stem 5U has leaves 5, 6, 7, 8, and 9. This will double the number of original stems. However, there may be various type of data in practical situations. So, we have to figure out the suitable stem-and-leaf plot.\nExample 2.3: Construct a stem-and-leaf plot from the following data:\n88.5, 98.8, 89.6, 92.2, 92.7, 88.4, 87.5, 90.9, 94.7, 88.3, 90.4, 83.4, 87.9, 92.6, 87.8, 89.9, 84.3, 90.4, 91.6, 91.0\n\nSolution-ISolution-II\n\n\n\n\nCode\nsl&lt;-c(88.5, 98.8, 89.6, 92.2, 92.7, 88.4, 87.5, 90.9,94.7, 88.3, 90.4, 83.4, 87.9, 92.6, 87.8, 89.9,84.3, 90.4, 91.6, 91.0)\n\nstem(sl)\n\n\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  8 | 34\n  8 | 888889\n  9 | 0000112233\n  9 | 59\n\n\n\n\n\n\nCode\nstem(sl,scale = 2)\n\n\n\n  The decimal point is at the |\n\n  82 | 4\n  84 | 3\n  86 | 589\n  88 | 34569\n  90 | 44906\n  92 | 267\n  94 | 7\n  96 | \n  98 | 8\n\n\n\n\n\nExample 2.4 (Another example): Construct a stem-and-leaf plot from the following data: 7,8,2,1,8,3,5,7,1,2,2,5,8,5,5,7,8,7,5,3\nSolution:\n\n\nCode\nsingldigit=c(7,8,2,1,8,3,5,7,1,2,2,5,8,5,5,7,8,7,5,3)\nstem(singldigit,2)\n\n\n\n  The decimal point is at the |\n\n  1 | 00\n  2 | 000\n  3 | 00\n  4 | \n  5 | 00000\n  6 | \n  7 | 0000\n  8 | 0000",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_graph_tab.html#exercises",
    "href": "descriptive_graph_tab.html#exercises",
    "title": "2  Descriptive statistic: Tabular and Graphical Presentations",
    "section": "2.9 Exercises",
    "text": "2.9 Exercises\n2.1 A doctor’s office staff studied the waiting times for patients who arrive at the office with a request for emergency service. The following data with waiting times in minutes were collected over a one-month period.\n\n2, 5, 10, 12, 4, 4, 5, 17, 11, 8, 9, 8, 12, 21, 6, 8, 7, 13, 18, 3\n\nUse class interval/width of 5 in the following (start your class limit from 0):\n\nShow the frequency distribution.\nShow the relative frequency distribution.\nShow the cumulative frequency distribution.\nShow the cumulative relative frequency distribution.\nWhat proportion of patients needing emergency service wait less than 10 minutes or less?\n\n\n2.2 A shortage of candidates has required school districts to pay higher salaries and offer extras to attract and retain school district superintendents. The following data show the annual base salary ($1000s) for superintendents in 20 districts in the greater Rochester, New York, area (The Rochester Democrat and Chronicle, February 10, 2008).\n\n187, 184, 174, 185, 175, 172, 202, 197, 165, 208, 215, 164, 162, 172, 182, 156, 172, 175, 170, 183\n\nUse appropriate number classes/ class width in the following.\n\nShow the frequency distribution.\nShow the percent frequency distribution.\nShow the cumulative percent frequency distribution.\nDevelop a histogram for the annual base salary.\nDo the data appear to be skewed? Explain.\nWhich salary range belongs to the highest percentage of superintendents ?\n\n\nDataHistogram\n\n\n\n187, 184, 174, 185, 175, 172, 202, 197, 165, 208, 215, 164, 162, 172, 182, 156, 172, 175, 170, 183\n\n\n\n\n\nCode\nsalary=c(187, 184, 174, 185, 175, 172, 202, 197, 165, 208, 215, 164, 162, 172, 182, 156, 172, 175, 170, 183)\n\n#sort(salary)\n\n#summary(salary)\n\nhist(salary,\n     breaks = seq(155,225,10),\n     right = FALSE,\n     xaxt = 'n',labels = TRUE,ylim = c(0,7))\naxis(1, at = seq(from = 155, to = 225, by = 10))\n\n\n\n\n\n\n\n\n\nCode\n#hist(salary,xlim = c(155, 220),right = FALSE)\n\n\n\n\n\n2.3 NRF/BIG research provided results of a consumer holiday spending survey (USA Today, December 20, 2005). The following data provide the dollar amount of holiday spending for a sample of 25 consumers.\n\n1200, 850, 740, 590, 340, 450, 890, 260, 610, 350, 1780, 180, 850,2050, 770, 800, 1090, 510, 520, 220, 1450, 280, 1120, 200 350\n\n\nWhat is the lowest holiday spending? The highest?\nUse a class width of $250 to prepare a frequency distribution and a percent frequency distribution for the data.\nPrepare a histogram and comment on the shape of the distribution.\nWhat observations can you make about holiday spending?\n\n\nDataHistogram\n\n\n\n1200, 850, 740, 590, 340, 450, 890, 260, 610, 350, 1780, 180, 850,2050, 770, 800, 1090, 510, 520, 220, 1450, 280, 1120, 200, 350\n\n\n\n\n\nCode\nspending=c(1200, 850, 740, 590, 340, 450, 890, 260, 610, 350, 1780, 180, 850,2050, 770, 800, 1090, 510, 520, 220, 1450, 280, 1120, 200, 350)\n\n#summary(spending)\n\nhist(spending,breaks = seq(180,2180,250),xaxt=\"n\",main = \"Frequency histogram of holiday spending (USD)\",xlab = \"Holiday spending\",labels = TRUE,ylim = c(0,9))\naxis(1, at = seq(180,2180,250))\n\n\n\n\n\n\n\n\n\n\n\n\n2.4 Construct a stem-and-leaf display for the following data.\n\n70, 72, 75, 64, 58, 83, 80, 82, 76, 75, 68, 65, 57, 78, 85, 72\n\n2.5 Construct a stem-and-leaf display for the following data.\n\n11.3, 9.6, 10.4, 7.5, 8.3, 10.5, 10.0, 9.3, 8.1, 7.7, 7.5, 8.4, 6.3, 8.8\n\n2.6 A psychologist developed a new test of adult intelligence. The test was administered to 20 individuals, and the following data were obtained.\n\n114, 99, 131, 124, 117, 102, 106, 127, 119, 115,98, 104, 144, 151, 132, 106, 125, 122, 118, 118\n\nConstruct a stem-and-leaf display for the data.\n\n\n\n\nAnderson, David R., and Dennis J. Sweeney. 2011. Statistics for Business and Economics. 11e [ed.]. Australia ; Mason, Ohio: South-Western Cengage Learning.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive statistic: Tabular and Graphical Presentations</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html",
    "href": "descriptive_numer_measures.html",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "",
    "text": "3.1 Measures of location\nIn statistics, measures of location, also known as measures of central tendency, are used to describe the central value or position of a distribution. They provide information about where the “center” of the distribution lies. Common measures of location include:\na) Mean b) Median c) Mode d) Percentiles e) Quartiles",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#measures-of-location",
    "href": "descriptive_numer_measures.html#measures-of-location",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "",
    "text": "3.1.1 Mean\n\nSample mean: Suppose \\(n\\) observation of a variable \\(X\\) is drawn from a population. Then the sample mean is denoted by \\(\\bar x\\) and\n\n\\[\n\\bar x =\\frac{\\sum x}{n}\n\\]\nThe sample mean \\(\\bar x\\) is a sample statistic.\n\nPopulation mean: Suppose in a population there are \\(N\\) values of variable \\(X\\). Then the population mean is denoted by \\(\\mu\\) and\n\n\\[\n\\mu =\\frac{\\sum x}{N}\n\\]\nThe \\(\\bar x\\) is a point estimator of the population mean \\(\\mu\\).\n\n\n3.1.2 Weighted mean\nThe weighted mean is a special case of the arithmetic mean. It occurs when there are several observations of the same value.\n\nWeighted mean:\n\n\\[\n\\bar x=\\frac{\\sum w_i x_i}{\\sum w_i}\n\\]\nwhere, \\(w_i=\\) weight for observation \\(i\\)\nExample 3.1 (Lind, Marchal, and Wathen 2012): The Carter Construction Company pays its hourly employees $16.50, $19.00, or $25.00 per hour. There are 26 hourly employees, 14 of which are paid at the $16.50 rate, 10 at the $19.00 rate, and 2 at the $25.00 rate. What is the mean hourly rate paid the 26 employees?\nSolution:\n\n\nCode\nxi&lt;-c(16.50,19.00,25.00)\nwi=c(14,10,2)\n\n#sum(xi*wi)\n\n\n\n\n\nHourly wage ($), xi\nWeight (wi )\n\\(w_ix_i\\)\n\n\n\n\n16.50\n14\n231\n\n\n19.00\n10\n190\n\n\n25.00\n2\n50\n\n\n\nHere, \\(\\sum w_ix_i=471\\) and \\(\\sum w_i=26\\)\nHence, \\(\\bar x=\\frac{\\sum w_i x_i}{\\sum w_i}=\\frac{471}{26}=18.1154\\)\nSo, the weighted mean hourly wage is rounded to $18.12.\nExample 3.2 (Anderson 2020a) : The grade point average for college students is based on a weighted mean computation. For most colleges, the grades are given the following data values: A (4), B (3), C (2), D (1), and F (0). After 60 credit hours of course work, a student at State University earned 9 credit hours of A, 15 credit hours of B, 33 credit hours of C, and 3 credit hours of D.\na. Compute the student’s grade point average.\nb. Students at State University must maintain a 2.5 grade point average for their first 60 credit hours of course work in order to be admitted to the business college. Will this student be admitted?\n\nExample 3.3 (Lind, Marchal, and Wathen 2012): Springers sold 95 Antonelli men’s suits for the regular price of $400. For the spring sale, the suits were reduced to $200 and 126 were sold. At the final clearance, the price was reduced to $100 and the remaining 79 suits were sold.\n(a) What was the weighted mean price of an Antonelli suit?\n(b) Springers paid $200 a suit for the 300 suits. Comment on the store’s profit per suit if a salesperson receives a $25 commission for each one sold.\nAns: (a) $237 (b) $12\n\n\n3.1.3 Median\nThe median is another measure of central location. The median is the value in the middle when the data are arranged in ascending order (smallest value to largest value).\n\nFor an odd number of observations, median is the middle value\nFor an even number of observations, median is the average of the two middle values\n\nExample 3.4 (n is odd): Let us consider the following class size data for a sample of five college classes.\n46, 54, 42, 46, 32\nArranged data: 32, 42, 46, 46, 54.\nBecause \\(n=5\\) is odd, the median is the middle value. Thus the median class size is 46 students.\nExample 3.5 (n is even): Let us consider the following class size data for a sample of five college classes.\n46, 54, 42, 46, 32, 40\nArranged data: 32, 40, 42, 46, 46, 54.\nBecause \\(n=6\\) is even, the\n\\[\nMedian=\\frac{42+46}{2}=44\n\\]\n\n\n\n\n\n\nNote\n\n\n\nAlthough the mean is the more commonly used measure of central location, in some situations the median is preferred. For example, the median is the measure of location most often reported for annual income and property value data because a few extremely large incomes or property values can inflate the mean. In such cases, the median is the preferred measure of central location.\n\n\n\n\n3.1.4 Mode\nThe mode is the value that occurs with greatest frequency.\n\n\n\n\n\n\nNote\n\n\n\nSituations can arise for which the greatest frequency occurs at two or more different values. In these instances, more than one mode exists. If the data contain exactly two modes, we say that the data are bimodal. If data contain more than two modes, we say that the data are multimodal. In multimodal cases the mode is almost never reported because listing three or more modes would not be particularly helpful in describing a location for the data.\n\n\n\n\n3.1.5 Percentiles\nA percentile provides information about how the data are spread over the interval from the smallest value to the largest value.\n\nThe \\(p^{th}\\) percentile is a value such that at least \\(p\\) percent of the observations are less than or equal to this value and at least \\((100-p)\\) percent of the observations are greater than or equal to this value.\nFormula:\n\n\\[\np^{th} \\  \\ percentile=( p\\times \\frac{n+1}{100} )^{th} \\ \\ value\n\\]\nExample 3.6: Here is the monthly starting salary ($) of 12 graduates:\n3450 ,3550 ,3650 ,3480 ,3355, 3310 ,3490 ,3730, 3540 ,3925, 3520 ,3480\nLet us determine the 85th percentile for the starting salary data.\nSolution:\nArranged data: 3310, 3355, 3450, 3480, 3480, 3490, 3520, 3540, 3550, 3650, 3730, 3925\nNow,\n\\[\nL_{85}=( 85\\times \\frac{12+1}{100} )^{th} \\ \\ value\n\\]\n\\[\n=11.05^{th} \\ \\ value =11^{th} \\ \\ value+0.05 (12^{th} -11^{th})\n\\] \\[\n=3730+0.05(3925-3730)\n\\]\n\\[\n=3739.75 \\ \\ dollars\n\\]\nInterpretation: Here, \\(85^{th} \\ \\ percentile =3739.75\\) implies that at least 85% of the total observations (salaries ) are less or equal to 3739.75 dollars.\n\n\n3.1.6 Quartiles\nIt is often desirable to divide data into four parts, with each part containing approximately one-fourth, or 25% of the observations. The division points are referred to as the quartiles and are defined as\nQ1 = first quartile, or 25th percentile\nQ2 = second quartile, or 50th percentile (also the median)\nQ3 = third quartile, or 75th percentile.\nExample 3.7: Here is the monthly starting salary ($) of 12 graduates:\n3450, 3550, 3650, 3480, 3355, 3310, 3490, 3730, 3540, 3925, 3520, 3480\nCompute Q1 and Q3 of the above data (Will be solved in class).\n\n\n3.1.7 Geometric mean\nThe geometric mean is useful in finding the average change of percentages, ratios, indexes, or growth rates over time. It has a wide application in business and economics because we are often interested in finding the percentage changes in sales, salaries, or economic figures, such as the Gross Domestic Product, which compound or build on each other.\n\nGeometric mean (GM): GM is the \\(n^{th}\\) root of the product of \\(n\\) values.\n\n\\[\nGM=\\sqrt[n]{(x_1)(x_2) \\cdot \\cdot \\cdot (x_n)}=[(x_1)(x_2) \\cdot \\cdot \\cdot(x_n)]^{1/n}\n\\]\nExample 3.8: Compute the geometric mean of the following percent increases: 8, 12, 14, 26, and 5.\nSolution: Here, \\(n=5\\). The geometric mean is:\n\\[\nGM=[8\\cdot12\\cdot14\\cdot26\\cdot5]^{1/5}=[174720]^{1/5}\\approx 11.18\n\\]\nExercise 3.9 (Lind, Marchal, and Wathen 2012): The percent increase in sales for the last 4 years at Combs Cosmetics were: 4.91,5.75, 8.12, and 21.60.\n\nFind the geometric mean percent increase.\nFind the arithmetic mean percent increase.\nIs the arithmetic mean equal to or greater than the geometric mean?\n\nExample 3.10: Listed below is the percent increase in sales for the MG Corporation over the last 5 years. Determine the geometric mean percent increase in sales over the period.\n9.4, 13.8, 11.7, 11.9, 14.7",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#measures-of-variability",
    "href": "descriptive_numer_measures.html#measures-of-variability",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.2 Measures of variability",
    "text": "3.2 Measures of variability\nVariability in data means lack of uniformity. It is also referred to as spread, scatter, or dispersion. We turn now to a discussion of some commonly used measures of variability.\n\n3.2.1 Range\n\\(Range =\\) Largest value \\(-\\) Smallest value\n\nThe simplest one, but is highly influenced by extreme values.\n\n\n\n3.2.2 Interquartile Range (IQR)\n\\[IQR=Q_3-Q_1\\]\n\nThe interquartile range is the range for the middle 50% of the data.\n\n\n\n3.2.3 Variance\nThe variance is a measure of variability that utilizes all the data. The variance is based on the difference between the value of each observation (\\(x_i\\)) and the mean. The difference between each \\(x_i\\) and the mean (\\(\\bar x\\) for a sample, \\(\\mu\\) for a population) is called a deviation about the mean.\n\nPopulation variance\n\n\\[\n\\sigma^2 =\\frac{(x_1-\\mu)^2+(x_2-\\mu)^2+\\cdot \\cdot \\cdot+(x_N-\\mu)^2}{N} = \\frac{\\sum (x_i -\\mu)^2}{N}\n\\]\n\nSample variance\n\n\\[\ns^2=\\frac{(x_1-\\bar x)^2+(x_2-\\bar x)^2+ \\cdot \\cdot \\cdot+(x_n-\\bar x)^2}{n-1} = \\frac{\\sum (x_i -\\bar x)^2}{n-1}\n\\]\n\nThe sample variance \\(s^2\\) is the estimator of the population variance \\(\\sigma^2\\) .\n\n\nAn alternative formula for the computation of the sample variance is:\n\n\\[\ns^2=\\frac{\\sum x_i^2-n\\bar x^2}{n-1}\n\\] where, \\(\\sum x_i^2=x_1^2+x_2^2+...+x_n^2\\)\n\n\n\n\n\n\nDerivation\n\n\n\nSince, \\(\\bar x=\\frac{\\sum x}{n}\\) so, \\(\\sum x=n\\cdot \\bar x\\)\nNow, \\(\\sum_{i=1}^n (x_i-\\bar x)^2\\)\n\\(=\\sum_{i=1}^n(x_i^2-2 \\cdot x_i \\cdot \\bar x+\\bar x^2)\\)\n\\(=\\sum_{i=1}^n x_i^2-2\\bar x \\sum_{i=1}^n x_i+\\sum_{i=1}^n \\bar x^2\\)\n\\(=\\sum_{i=1}^n x_i^2 -2\\bar x\\cdot n\\bar x+n\\bar x^2\\)\n\\(=\\sum_{i=1}^n x_i^2 -2n\\bar x^2+n\\bar x^2=\\sum_{i=1}^n x_i^2-n\\bar x^2\\)\n\n\nExample 3.11: Here is the monthly starting salary ($) of 6 graduates:\n3450 ,3550 ,3650 ,3480 ,3355, 3545.\nCompute sample variance (\\(s^2\\)).\nSolution:\nHere, sample size, \\(n=6\\).\nThe sample mean salary,\n\\(\\bar x =\\frac{\\sum x}{n}=\\frac{3450+\\cdot \\cdot \\cdot+3545}{6}=3505 \\ \\ dollars\\)\n\n\nCode\nlibrary(tidyverse)\n\nsal&lt;-c(3450 ,3550 ,3650 ,3480 ,3355, 3310 ,3490 ,3730, 3540 ,3925, 3520 ,3480)\n\nsal6&lt;-c(3450 ,3550 ,3650 ,3480 ,3355, 3545)\n#mean(sal6)\n\nsal6d=as.data.frame(sal6)\n\nsal6d %&gt;% mutate(m=mean(sal6),deviation=sal6-m,squared_deviation=deviation^2)-&gt;varcaltable \n\n#sum(varcaltable$squared_deviation)\n\n#varcaltable %&gt;% knitr::kable()\n\n\n\n\n\nTable 3.1: Computation of the sample variance for the starting Salary data\n\n\n\n\n\n\n\n\n\n\n\nSalary (\\(x_i\\))\nSample mean, \\(\\bar x\\)\n\\((x_i-\\bar x)\\)\n\\((x_i-\\bar x)^2\\)\n\n\n\n\n3450\n3505\n-55\n3025\n\n\n3550\n3505\n45\n2025\n\n\n3650\n3505\n145\n21025\n\n\n3480\n3505\n-25\n625\n\n\n3355\n3505\n-150\n22500\n\n\n3545\n3505\n40\n1600\n\n\n\n\n\\(\\sum (x_i-\\bar x ) =0\\)\n\\(\\sum (x_i-\\bar x )^2 =50800\\)\n\n\n\n\n\n\nHence, the sample variance is:\n\\[\ns^2=\\frac{\\sum (x_i-\\bar x)^2}{n-1}=\\frac{50800}{6-1}=10160 \\ \\ (dollars)^2\n\\]\n\n\n3.2.4 Standard deviation\nThe standard deviation is defined to be the positive square root of the variance\n\nSample standard deviation=\\(s=\\sqrt s^2\\)\nPopulation standard deviation=\\(\\sigma =\\sqrt \\sigma ^2\\)\n\n\nThe sample standard deviation \\(s\\) is the estimator of population standard deviation \\(\\sigma\\).\n\nExample 3.12: The standard deviation of the previous example is :\n\\[\ns=\\sqrt {10160} =100.7968\\approx 100.80 \\ \\ dollars\n\\]\n\n\n\n\n\n\nNote:\n\n\n\nThe standard deviation is easier to interpret than the variance because the standard deviation is measured in the same units as the data.\n\n\nFor example, the sample variance for the starting salary data of business school graduates is \\(s^2=10160 \\ \\ (dollars)^2\\).\nBecause the standard deviation is the square root of the variance, the units of the variance, dollars squared, are converted to dollars in the standard deviation.\nThus, the standard deviation of the starting salary data is 100.80 dollar. In other words, the standard deviation is measured in the same units as the original data. For this reason the standard deviation is more easily compared to the mean and other statistics that are measured in the same units as the original data.\n\n\n\n\n\n\nProperties of variance\n\n\n\n\nNon-negativity: \\(Var(X)\\ge 0\\).\nFor any constant say \\(X=c\\) , \\(Var(c)=0\\).\nVariance is affected by outliers.\nVariance is NOT affected by change origin; but affected by change of scale that is:\n\\(Var(aX+b)=a^2 Var(X)\\)\nHere, \\(a\\) and \\(b\\) are both constants.\n\nProof: For a population data \\(X=\\{ x_1,x_2,..., x_N\\}\\) the population mean of \\(X\\) is\n\\(\\mu_X =\\frac{\\sum_{i=1}^N x_i}{N}\\) and variance of \\(X\\) is\n\\(Var(X)=\\frac{\\sum_{i=1}^N (x_i-\\mu_X)^2}{N}\\)\nNow let, \\(Y=aX+b\\)\nSo, the population mean of \\(Y\\) is\n\\(\\mu_Y=\\frac{\\sum_{i=1}^N y_i}{N}=\\frac{\\sum_{i=1}^N (a x_i+b)}{N}\\)\n\\(=\\frac{\\sum_{i=1}^N (ax_i)+\\sum_{i=1}^N b} {N}=a\\frac{\\sum_{i=1}^N x_i}{N}+\\frac{Nb}{N}=a \\cdot\\mu_X+b\\)\nHence,\n\\[\nVar(Y)=\\frac{\\sum_{i=1}^N (y_i-\\mu_Y)^2}{N}=\\frac{\\sum_{i=1}^N(a\\cdot x_i+b-a\\cdot \\mu_X-b)^2}{N}\n\\]\n\\[\n=\\frac{\\sum_{i=1}^N (a\\cdot x_i -a\\cdot \\mu_X)^2}{N}\n\\]\n\\[\na^2 \\frac{\\sum_{i=1}^N (x_i-\\mu_X)^2}{N}=a^2 Var(X)\n\\]\n\\(\\therefore Var(Y)= Var(aX+b)=a^2 Var(X)\\).\n\n\n\n\n3.2.5 Coefficient of variation (CV)\nIn some situations we may be interested in a descriptive statistic that indicates how large the standard deviation is relative to the mean. This measure is called the coefficient of variation and is usually expressed as a percentage.\nCoefficient variation,\n\\[\nCV=\\frac{Standard \\ \\ deviation}{Mean}\n\\]\n\nThe coefficient of variation is a relative measure of variability; it measures the standard deviation relative to the mean.\nIn general, the coefficient of variation is a useful statistic for comparing the variability of variables that have different standard deviations and different means.\n\nExample 3.13: The table at the left shows the population heights (in inches) and weights (in pounds) of the members of a basketball team. Find the coefficient of variation for the heights and the weights. Then compare the results.\n\nDataCoefficient of variation\n\n\n\n\n\nHeights (inches)\nWeights (pounds)\n\n\n\n\n72\n180\n\n\n74\n168\n\n\n68\n225\n\n\n76\n201\n\n\n74\n189\n\n\n69\n192\n\n\n72\n197\n\n\n79\n162\n\n\n70\n174\n\n\n69\n171\n\n\n77\n185\n\n\n73\n210\n\n\n\n\n\nThe mean height \\(\\mu =\\frac{\\sum x}{N}=\\frac{72+74+\\cdot \\cdot \\cdot+ 73}{12}  \\approx 72.8 \\ \\ inches\\) with a standard deviation \\(\\sigma =\\sqrt {\\frac{\\sum x^2}{N}-\\mu^2} =3.3 \\ \\ inches\\).\nThe coefficient of variation for the heights is\n\\(CV_{height}=\\frac{\\sigma}{\\mu}.100\\%=\\frac{3.3}{72.8} . 100\\% \\approx 4.5\\%\\).\nSimilarly,\nthe mean weight \\(\\mu \\approx 187.8 \\ \\ pounds\\) with a standard deviation \\(\\sigma =17.7 \\ \\ pounds\\).\nThe coefficient of variation for the weights is\n\\(CV_{weight}=\\frac{\\sigma}{\\mu}.100\\%=\\frac{17.7}{187.8}.100\\% \\approx9.4\\%\\)\nInterpretation: The weights (9.4%) are more variable than the heights (4.5%).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#the-mean-and-standard-deviation-of-grouped-data",
    "href": "descriptive_numer_measures.html#the-mean-and-standard-deviation-of-grouped-data",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.3 The mean and standard deviation of Grouped data",
    "text": "3.3 The mean and standard deviation of Grouped data\nIn most cases, measures of location and variability are computed by using the individual data values. Sometimes, however, data are available only in a grouped or frequency distribution form. In the following discussion, we show how the weighted mean formula can be used to obtain approximations of the mean, variance, and standard deviation for grouped data.\n\n3.3.1 Sample mean for grouped data\n\\[\n\\bar x=\\frac{\\sum f_i M_i}{n}\n\\] where,\n\\(M_i=\\frac{Lower \\ \\ limit+Upper\\ \\ limit}{2}=\\) the midpoint for class \\(i\\)\n\\(f_i=\\) the frequency for class \\(i\\)\n\\(n=\\) the sample size \\(=\\sum f_i\\)\n\n\n3.3.2 Sample variance for grouped data\n\\[\ns^2=\\frac{\\sum f_i(M_i-\\bar x)^2}{n-1}=\\frac{\\sum M_i x_i^2-n\\cdot \\bar x^2}{n-1}\n\\]\nEventually the standard deviation is \\(\\sqrt {s^2}\\)\nExample 3.14 The frequency distribution of audit times is given below:\n\nFrequency distribution of audit times\n\n\nAudit Time (days)\nFrequency\n\n\n\n\n10-14\n4\n\n\n15-19\n8\n\n\n20-24\n5\n\n\n25-29\n2\n\n\n30-34\n1\n\n\nTotal\n20\n\n\n\nCompute sample mean and standard deviation of Audit time (days) from the above frequency distribution / grouped data.\nSolution:\n\nComputation of the sample mean audit time for grouped data\n\n\n\n\n\n\n\n\n\nAudit Time (days)\nMid point\\((M_i)\\)\nFrequency \\((f_i)\\)\n\\(f_i M_i\\)\n\\(f_i M_i^2\\)\n\n\n10-14\n12\n4\n48\n576\n\n\n15-19\n17\n8\n136\n2312\n\n\n20-24\n22\n5\n110\n2420\n\n\n25-29\n27\n2\n54\n1458\n\n\n30-34\n32\n1\n32\n1024\n\n\nTotal\n\n20\n380\n7790\n\n\n\nSample mean,\n\\[\n\\bar x=\\frac{\\sum f_i M_i}{n}=\\frac{380}{20}=19 \\ \\ days\n\\]\nSample variance,\n\\[\ns^2=\\frac{\\sum f_i M_i^2-n\\cdot \\bar x^2}{n-1}=\\frac{7790-20\\cdot19^2}{20-1}=30 \\ \\ (days)^2\n\\]\nHence the standard deviation is:\n\\(s=\\sqrt {30} \\ \\ days =5.48 \\ \\ days\\)\n\n\nCode\nM=seq(12,32,5)\nf=c(4,8,5,2,1)\n\n#sum(M*f)\n#sum((M^2)*f)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#measures-of-relative-location-z-score",
    "href": "descriptive_numer_measures.html#measures-of-relative-location-z-score",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.4 Measures of relative location: z-score",
    "text": "3.4 Measures of relative location: z-score\nIn addition to measures of location, variability, and shape, we are also interested in the relative location of values within a data set. Measures of relative location help us determine how far a particular value is from the mean.\n\n3.4.1 z-score\nThe z-score provide how far an observation or value is from the mean or average.\n\n\n\n\n\n\nz-score\n\n\n\nLet, \\(X=\\{x_1,x_2,...,x_n\\}\\) has the sample mean \\(\\bar x\\) and the sample standard deviation \\(s\\). Then the z-score for \\(x_i\\) is :\n\\[\nz_i=\\frac{x_i-\\bar x}{s}\n\\]\n\n\n\nThe z-score is often called the standardized value. The z-score, \\(z_i\\), can be interpreted as the number of standard deviations \\(x_i\\) is from the mean \\(\\bar x\\). For example, \\(z_1 = 1.2\\) would indicate that \\(x_1\\) is 1.2 standard deviations greater than the sample mean. Similarly, \\(z_2 = -0.5\\) would indicate that \\(x_2\\) is 0.5, or 1/2, standard deviation less than the sample mean.\nA z-score greater than zero occurs for observations with a value greater than the mean, and a z-score less than zero occurs for observations with a value less than the mean. A z-score of zero indicates that the value of the observation is equal to the mean.\nThe z-score for any observation can be interpreted as a measure of the relative location of the observation in a data set. Thus, observations in two different data sets with the same z-score can be said to have the same relative location in terms of being the same number of standard deviations from the mean.\n\nExample 3.15 Suppose \\(X=\\{46,54,42,46,32\\}\\). Here \\(X\\) is the number students in each class.\ni) Compute sample mean and standard deviation of \\(X\\)\nii) Compute z-scores\niii) Interpret the z-scores for 54 and 32\niv) Compute the mean and variance of z-scores\nExample 3.16 Consider a very large number of students taking a college entrance exam such as the SAT. And suppose the mean score on the mathematics section of the SAT is 570 with a standard deviation of 40.\na) Find the z-score for a student who scored 600.\nb) A student is told that his z-score on this test is -1.5. What was his actual SAT math score?\n\n\n3.4.2 Chebyshev’s Theorem\nRegardless of the shape of a distribution Chebyshev’s Theorem provides lower bound of proportion of observations lie within a certain interval.\n\n\n\n\n\n\nNote\n\n\n\nChebyshev’s Theorem\nAt least \\((1 - \\frac{1}{z^2})\\) of the data values must be within \\(z\\) standard deviations of the mean, where \\(z&gt;1\\).\nMathematically,\n\\(P(\\bar x-z\\cdot s&lt;X&lt;\\bar x+z\\cdot s)\\ge (1-\\frac{1}{z^2})\\)\n\n\nExample 3.16 Suppose that the midterm test scores for 100 students in a college business statistics course had a mean of 70 and a standard deviation of 5.\ni) How many students (in %) had test scores between 60 and 80?\nii) How many students (in %) had test scores between 58 and 82?\nSolution:\nHere, \\(\\bar x=70; \\ \\ s=5\\)\ni) For \\(x=60\\ \\ ; z=\\frac{60-70}{5}=-2\\)\nFor, \\(x=80\\ \\ ; z=\\frac{80-70}{5}=+2\\)\nApplying Chebyshev’s theorem with \\(z = 2\\), we have\n\\[\n(1-\\frac{1}{z^2})=(1-\\frac{1}{2^2})=0.75\n\\] So, at least 75% of the students must have test scores between 60 and 80.\nii) DIY\nExample 3.16 Suppose that the midterm test scores for 100 students in a college business statistics course had a mean of 70 and a standard deviation of 5. Find the interval in which at least 80% data values lie.\n\n\n3.4.3 Empirical Rule\nIf a distribution is approximately bell-shaped/symmetric/normal then\n\nApproximately 68% of the data values will be within one standard deviation of the mean.\nApproximately 95% of the data values will be within two standard deviations of the mean.\nAlmost all of the data values (99%) will be within three standard deviations of the mean.\n\n\n\n3.4.4 Detecting Outliers\nSometimes a data set will have one or more observations with unusually large or unusually small values. These extreme values are called outliers.\n\n\n\n\n\n\nUsing z-score to detect outlier\n\n\n\nAn observation say \\(x_i\\) is treated as outlier if its corresponding z-score is less than -3 or greater than +3.\nEquivalently, if an observation \\(x_i\\) falls outside the interval \\([\\bar x-3\\cdot s,\\bar x+3\\cdot s]\\).\n\n\n\n\n\n\n\n\nUsing 1.5(IQR) rule to detect outlier\n\n\n\nWe define two limits as follows:\nLower limits, \\(LL=Q_1-1.5 (IQR)\\)\nUpper limits, \\(UL=Q_3+1.5 (IQR)\\)\nAny data value or observation falls outside the interval \\([LL,UL]\\) will be treated as outlier.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#five-number-summary",
    "href": "descriptive_numer_measures.html#five-number-summary",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.5 Five-Number summary",
    "text": "3.5 Five-Number summary\nIn a five-number summary, five numbers are used to summarize the data:\n1. Smallest value\n2. First quartile (Q1)\n3. Median (Q2)\n4. Third quartile (Q3)\n5. Largest value",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#box-plot",
    "href": "descriptive_numer_measures.html#box-plot",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.6 Box-plot",
    "text": "3.6 Box-plot\nThe box plot is a graphical display that simultaneously describes several important features of a data set, such as center, spread, a departure from symmetry, and identification of unusual observations or outliers.\nA key to the development of a boxplot is the computation of the interquartile range, \\(IQR = Q_3 - Q_1\\). Figure 3.1 shows a boxplot for the monthly starting salary data. The steps used to construct the boxplot follow (Anderson 2020b).\n\n\n\n\n\n\nFigure 3.1: Boxplot of the Monthly Starting Salary Data with Lines Showing the Lower and Upper Limits\n\n\n\nSalary data (assenting order)\n5710, 5755, 5850, 5880, 5880, 5890, 5920, 5940, 5950, 6050, 6130, 6325\n1. A box is drawn with the ends of the box located at the first and third quartiles. For the salary data, \\(Q_1 = 5857.5\\) and \\(Q_2 = 6025\\). This box contains the middle 50% of the data.\n2. A vertical line is drawn in the box at the location of the median (5905 for the salary data).\n3. By using the interquartile range, \\(IQR = Q_3 - Q_1\\), limits are located at \\(1.5(IQR)\\) below \\(Q1\\) and \\(1.5(IQR)\\) above \\(Q3\\). For the salary data, \\(IQR = Q3 - Q1 = 6025 – 5857.5 = 167.5\\). Thus, the limits are \\(LL=5857.5 – 1.5(167.5) = 5606.25\\) and \\(UL=6025 + 1.5(167.5) = 6276.25\\). Data outside these limits are considered outliers.\n4. The horizontal lines extending from each end of the box in Figure 3.1 called whiskers. The whiskers are drawn from the ends of the box to the smallest and largest values inside the limits computed in step 3. Thus, the whiskers end at salary values of 5710 and 6130.\n\nHere is the computer generated boxplot of salary data using R programmning language (R Core Team 2024).\n\n\nCode\nsalary_d&lt;-c(5710, 5755, 5850, 5880, 5880, 5890, 5920, 5940, 5950, 6050, 6130, 6325)\n\nboxplot(salary_d,horizontal = T,pch=19,lwd=1,col = \"#B6C5D1\", main=\"Boxplot of the Monthly Starting Salary  Data\" ,xlab=\"Salary (in US dollars)\")\n\n\n\n\n\n\n\n\n\n\n3.6.1 Boxplot and skewness of the data\nWhen we discuss the frequency histogram we also learned about shape of the distribution. By visual inspection of boxplot we can also tell about the distribution shape of a variable. The following boxplots are the typycal examples of skewness of the data.\n\n\nCode\nlibrary(tidyverse)\npar(mar = c(7, 4, 2, 2) + 0.1)\n\n\nl &lt;- layout(matrix(c(1, 1,  # First, second\n                     2, 3), # and third plot\n            nrow = 2,\n            ncol = 2,\n            byrow = TRUE))\n\n#layout.show(l)\n\nset.seed(1)\nx=rbeta(200,2,2)\nboxplot(x,horizontal = T,xlab=\"Value\",main=\"(a) Boxplot of approximately symmetric distribution\")\n\ny=rbeta(200,1,2)\nboxplot(y,horizontal = T,xlab=\"Value\",main=\"(b) Boxplot of positively skewed distribution\",cex.main=0.9)\n\nz=rbeta(200,4,2)\nboxplot(z,horizontal = T,xlab=\"Value\",main=\"(c) Boxplot of negatively skewed distribution\",cex.main=0.9)\n\n\n\n\n\n\n\n\n\nCode\nxyz&lt;-tibble(x,y,z)\nxyz %&gt;% gather(key = \"variable\",value = \"value\")-&gt;xyz.long\n\n#xyz.long %&gt;% ggplot(aes(x=variable,y=value))+\n  #geom_boxplot(fill=\"steelblue\")+\n  #coord_flip()+\n  #theme_classic()\n\n\nExample 3.17 (Anderson 2020a, 158): Household Incomes. The following data represent a sample of 14 household incomes($1000s). Answer the following questions based on this sample.\n49.4 52.4 53.4 51.3 52.1 48.7 52.1\n\n52.2 64.5 51.6 46.5 52.9 52.5 51.2\n\nWhat is the median household income for these sample data?\nAccording to a previous survey, the median annual household income five years ago was $55,000. Based on the sample data above, estimate the percentage change in the median household income from five years ago to today.\nCompute the first and third quartiles.\nProvide a five-number summary.\nUsing the z-score approach, do the data contain any outliers? Does the approach that uses the values of the first and third quartiles and the interquartile range to detect outliers provide the same results?\n\n\n\n3.6.2 Comparative box-plot\nAn example: Cell Phone Companies Customer Satisfaction. Consumer Reports provides overall customer satisfaction scores for AT&T, Sprint, T-Mobile, and Verizon cell-phone services in major metropolitan areas throughout the United States. The rating for each service reflects the overall customer satisfaction considering a variety of factors such as cost, connectivity problems, dropped calls, static interference, and customer support. A satisfaction scale from 0 to 100 is used with 0 indicating completely dissatisfied and 100 indicating completely satisfied. Suppose that the ratings for the four cell-phone services in 20 metropolitan areas are as shown below.\n\nWe can easily compare the ratings for 4- cell-phone services using comparative/parallel box-plots\n\n\nCode\nlibrary(readxl)\nlibrary(tidyverse)\nRating&lt;- read_excel(\"StatForBandE_data.xlsx\", \n    sheet = \"Sheet5\")\n\nRating %&gt;% ggplot(aes(x=Company,y=Rating))+\n  geom_boxplot(fill=\"steelblue\")+\n  theme_bw()+\n  theme(axis.text = element_text(size = 12,color = \"black\"),\n        axis.title =element_text(size = 14,face = \"bold\") )+\n  labs(title = \" \")\n\n\n\n\n\n\n\n\nFigure 3.2: Comparative Boxplots of Rating by customer for cell-phone services\n\n\n\n\n\n\nNow, discuss what a comparison of the boxplots tells about the four services.\nWhich service does Consumer Reports recommend as being best in terms of overall customer satisfaction?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#measures-of-shape-skewness-and-kurtosis",
    "href": "descriptive_numer_measures.html#measures-of-shape-skewness-and-kurtosis",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.7 Measures of shape: Skewness and Kurtosis",
    "text": "3.7 Measures of shape: Skewness and Kurtosis\nMeasures of shape are tools that can be used to describe the shape of a distribution of data. In this section, we examine two measures of shape, skewness and kurtosis.\n\n3.7.1 Skewness\nSkewness refers to lack of symmetry or departure from symmetry. There are three types of skewness based on the histogram or density plot of data.\na) Positive skewness/ Skewed right- where mean&gt;median&gt;mode\nb) Symmetrical distribution- in a perfect symmetrical distribution mean=median=mode\nc) Negative skewness/ Skewed left- where mean&lt;median&lt;mode\nThe typical example of skewness is exhibited in Figure 3.3 with the relative position of mean, median and mode.\n\n\n\n\n\n\nFigure 3.3: Types of skewness and relative position of mean, median, mode\n\n\n\n\n\nCode\nset.seed(1)\n\nskewR&lt;-5+rbeta(10000,2,8)*20\nmean.sk=mean(skewR)\nmedian.sk=median(skewR)\n\n#hist(skewR,freq = F,col = \"white\")\n#lines(density(skewR),lwd=2)\n#abline(v=mean.sk,col=\"red\",lwd=2)\n#abline(v=median.sk,col=\"green\",lwd=2)\n#arrows(x0 = mean.sk, y0 = 0.15,x1 = mean.sk, y1 = 0)\n\n\n\n\n3.7.2 Kurtosis\nKurtosis describes the amount of peakedness of a distribution.\n\nDistributions that are high and thin are referred to as leptokurtic distributions.\nDistributions that are flat and spread out are referred to as platykurtic distributions.\nBetween these two types are distributions that are more “normal” in shape, referred to as mesokurtic distributions.\n\nThese three types of kurtosis are illustrated in Figure 3.4.\n\n\n\n\n\n\nFigure 3.4: Different types of kurtosis\n\n\n\n\n\n3.7.3 Measures of skewness and kurtosis using Moments\nMoments:\nSuppose a sample of size \\(n\\) of variable \\(X\\) with observations \\(x_1,x_2,....,x_n\\).\nThe\\(r^{th}\\)sample raw moment is\n\\[\nm'_{r}=\\frac{\\sum_{i=1}^{n} x_i^r}{n}\n\\tag{3.1}\\]\nHence the first 4 raw moments are:\n\\(m'_1=\\frac{\\sum_{i=i}^n x_i}{n}=\\bar x\\)\n\\(m'_2=\\frac{\\sum_{i=i}^n x_i^2}{n}\\)\n\\(m'_3=\\frac{\\sum_{i=i}^n x_i^3}{n}\\)\n\\(m'_4=\\frac{\\sum_{i=i}^n x_i^4}{n}\\)\nThe\\(r^{th}\\)sample central moment (about mean) is:\n\\[\nm_r=\\frac{\\sum_{i=1}^n (x_i-\\bar x)^r}{n}\n\\tag{3.2}\\]\nHence the first 4 central moments are:\n\\(m_1=\\frac{\\sum(x-\\bar x)}{n}=\\frac{0}{n}=0\\)\n\\(m_2=\\frac{\\sum(x-\\bar x)^2}{n}\\)\n\\(m_3=\\frac{\\sum(x-\\bar x)^3}{n}\\)\n\\(m_4=\\frac{\\sum(x-\\bar x)^4}{n}\\)\nRelation between raw moments and central moments\na) \\(m_1=0\\)\nb) \\(m_2=m'_2-{m'_1}^2\\)\nc) \\(m_3=m'_3-3m'_1 m'_2+2{m'_1}^3\\)\nd) \\(m_4=m'_4-4m'_1 m'_3+6{m'_1}^2 m'_2-3{m'_1}^4\\)\nExample\nCalculate the first 4 central moments from the following sample data.\n3,5,6,9,12\nSolution:\n\n\nCode\nmoments&lt;-function(x,r){\n  x_bar=mean(x)\n  n=length(x)\n  mr=numeric(r)\n  for (i in 1:r) {\n    mr[i]=sum((x-x_bar)^i)/n\n    #print(mr[i])\n  }\n  return(mr)\n}\n\nx=c(3,5,6,9,12)\n\n#moments(x,4)\n\n\nHere sample mean, \\(\\bar x=\\frac{\\sum x}{n}=\\frac{3+5+...+12}{5}=7\\)\n\n\n\n\n\n\n\n\n\n\n\\(x\\)\n\\((x-\\bar x)\\)\n\\((x-\\bar x)^2\\)\n\\((x-\\bar x)^3\\)\n\\((x-\\bar x)^4\\)\n\n\n\n\n3\n-4\n16\n-64\n256\n\n\n5\n-2\n4\n-8\n16\n\n\n6\n-1\n1\n-1\n1\n\n\n9\n2\n4\n8\n16\n\n\n12\n5\n25\n125\n625\n\n\n\\(\\sum x=35\\)\n\\(\\sum (x-\\bar x)=0\\)\n\\(\\sum(x-\\bar x)^2=50\\)\n\\(\\sum(x-\\bar x)^3=60\\)\n\\(\\sum (x-\\bar x)^4=914\\)\n\n\n\nThe central moments are:\n\\(m_1=0\\)\n\\(m_2=\\frac{50}{5}=10\\)\n\\(m_3=\\frac{60}{5}=12\\)\n\\(m_4=\\frac{914}{5}=182.8\\)\nCoefficient of skewness and kurtosis\nLet we have a sample data \\(X=\\{x_1,x_2,...,x_n\\}\\) from a population. The following formulas are used to measure skewness and kurtosis from a sample data (Newbold, Carlson, and Thorne 2013).\n\\[\nSkewness = \\frac{1}{n} \\left[ \\sum \\left( \\frac{X_i - \\overline{X}}{s} \\right)^3 \\right]=\\frac{1}{n} \\sum  z_i^3\n\\]\nFor calculation purpose the above formula is written as\n\\[\nSkewness=\\frac{1}{n}\\frac{\\sum (X-\\bar X)^3}{s^3}\n\\]\nDecision:\na) \\(Skewness&gt;0\\) indicates positive skewness\nb) \\(Skewness\\approx 0\\) indicates symmetrical distribution\nc) \\(Skewness&lt;0\\) indicates negative skewness\n\\[\nKurtosis = \\frac{1}{n} \\left[ \\sum \\left( \\frac{X_i - \\overline{X}}{s} \\right)^4 \\right]=\\frac{1}{n} \\sum  z_i^4\n\\]\nFor calculation purpose the above formula is written as\n\\[ Kurtosis=\\frac{1}{n}\\frac{\\sum (X-\\bar X)^4}{s^4} \\]\nDecision:\na) \\(Kurtosis&gt;3\\) indicates leptokurtic;\nb) \\(Kurtosis \\approx 3\\) indicates mesokurtic/normal;\nc) \\(Kurtosis&lt;3\\) indicates platykurtic.\nExample A sample of five data entry clerks employed in the Harry County Tax Office revised the following number of tax records last hour: 100, 75, 70, 65, and 50.\nComment about skewness and kurtosis of the number of tax records.\nSolution:\nHome work\n1) Compute coefficient of skewness and kurtosis and comment for the following data : 20,21,5,9,14,6,19,16.\n2) Suppose the following data are the ages of Internet users obtained from a sample.\n41, 15 ,31, 25 ,24, 23 ,21 ,22 ,22 ,18, 30 ,20 ,19 ,19 ,16, 23 ,27 ,38 ,34 ,24, 19 ,20, 29 ,17, 23.\n\n\nCode\nlibrary(moments)\n\nskurt&lt;-c(41, 15 ,31, 25 ,24, 23 ,21 ,22 ,22 ,18, 30 ,20 ,19 ,19 ,16, 23 ,27 ,38 ,34 ,24, 19 ,20, 29 ,17, 23)\n\n#smean&lt;-mean(skurt)\n#hist(skurt)\n#skewness(skurt)\n#kurtosis(skurt)+3\n#sum((skurt-smean)^2)/(length(skurt)-1)\n#var(skurt)\n\n#sum((skurt-smean)^2)\n#sum((skurt-smean)^3)\n#sum((skurt-smean)^4)\n\n\nFrom sample data we have following statistics: \\(\\sum(X-\\bar X)^2=1062\\), \\(\\sum(X-\\bar X)^3=7020\\) and \\(\\sum(X-\\bar X)^4=153198\\).\na) Plot a histogram. What is your observation about skewness? Is it possible to have an idea about form the histogram?\nb) Now compute the coefficient of skewness and kurtosis of the given data and comment.\nc) Does your observation in part (a) match with the result in part (b)?\n\n\nCode\n#hist(skurt,xlab = \"Age of users (in year)\",main=\"\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "descriptive_numer_measures.html#exercise",
    "href": "descriptive_numer_measures.html#exercise",
    "title": "3  Descriptive statistics: Numerical Measures",
    "section": "3.8 Exercise",
    "text": "3.8 Exercise\n3.1 What are the common measures of central tendency/ location?\n3.2 When median is preferable to mean?\n3.3 Discuss the nature of unimodal, bimodal and multimodal data/ distribution.\n3.4 What are the common measures of dispersion/ variation?\n3.5 (a) Compute the mean of the following sample values: 5, 9, 4, 10 (b) Show that \\(\\sum (x-\\bar x)=0\\).\n3.6 (a) Compute the mean of the following sample values: 1.3, 7.0, 3.6, 4.1, 5.0 (b) Show that \\(\\sum (x-\\bar x)=0\\).\n3.7 Show that variance is affected by change of scale; but not by origin.\n3.8 The monthly starting salary ($) of 12 graduates:\n\n3450 ,3550 ,3650 ,3480 ,3355, 3310 ,3490 ,3730, 3540 ,3925, 3520 ,3480\n\n\nCompute sample mean and standard deviation.\nCompute sample median and IQR.\nTo be in top 10% earners what should be the starting salary of a graduate?\n\n3.9 Automobile Fuel Efficiencies. In automobile mileage and gasoline-consumption testing, 13 automobiles were road tested for 300 miles in both city and highway driving conditions. The following data were recorded for miles-per-gallon performance.\n\nCity: 16.2, 16.7, 15.9, 14.4, 13.2, 15.3, 16.8, 16.0, 16.1, 15.3, 15.2, 15.3, 16.2\nHighway: 19.4, 20.6, 18.3, 18.6, 19.2, 17.4, 17.2, 18.6, 19.0, 21.1, 19.4, 18.5, 18.7\n\nUse the mean, median, and mode to make a statement about the difference in performance for city and highway driving.\n3.10 Air Quality Index. The Los Angeles Times regularly reports the air quality index for various areas of Southern California. A sample of air quality index values for Pomona provided the following data: 28, 42, 58, 48, 45, 55, 60, 49, and 50.\ni) Compute the range and interquartile range.\nii) Compute the sample variance and sample standard deviation.\niii) A sample of air quality index readings for Anaheim provided a sample mean of 48.5, a sample variance of 136, and a sample standard deviation of 11.66. What comparisons can you make between the air quality in Pomona and that in Anaheim on the basis of these descriptive statistics?\n\n3.11 Reliability of Delivery Service. The following data were the number of days required to fill orders for Dawson Supply, Inc., and J.C. Clark Distributors.\n\nDawson Supply Days for Delivery: 11, 10, 9, 10, 11, 11, 10, 11, 10, 10\nClark Distributors Days for Delivery: 8, 10, 13, 7, 10, 11, 10, 7, 15, 12\n\nWhich company is more consistent to fill orders?\nHints: Compute and compare standard deviation (SD) of the number days for each company. The less SD would indicate more consistency.\n3.12 Amateur Golfer Scores. Scores turned in by an amateur golfer at the Bonita Fairways Golf Course in Bonita Springs, Florida, during 2017 and 2018 are as follows:\n\n2017 Season: 74, 78, 79, 77, 75, 73, 75, 77\n2018 Season: 71, 70, 75, 77, 85, 80, 71, 79\n\ni) Use the mean and standard deviation to evaluate the golfer’s performance over the two-year period.\nii) What is the primary difference in performance between 2017 and 2018? What improvement, if any, can be seen in the 2018 scores?\n3.13 Consistency of Running Times. The following times were recorded by the quarter-mile and mile runners of a university track team (times are in minutes).\n\nQuarter-Mile Times: 0.92, 0.98, 1.04, 0.90, 0.99\nMile Times: 4.52, 4.35, 4.60, 4.70, 4.50\n\nAfter viewing this sample of running times, one of the coaches commented that the quarter-milers turned in the more consistent times.\ni) Use the standard deviation and the coefficient of variation to summarize the variability in the data.\nii) Does the use of the coefficient of variation indicate that the coach’s statement should be qualified?\n\n3.14 Automobiles traveling on a road with a posted speed limit of 55 miles per hour are checked for speed by a state police radar system. Following is a frequency distribution of speeds.\n\n\n\n\nSpeed (miles per hour)\nFrequency\n\n\n45-49\n10\n\n\n50-54\n40\n\n\n55-59\n150\n\n\n60-64\n175\n\n\n65-69\n75\n\n\n70-74\n15\n\n\n75-79\n10\n\n\nTotal\n475\n\n\n\ni) What is the mean speed of the automobiles traveling on this road?\nii) Compute the variance and the standard deviation.\n\n3.15 Consider a sample with a mean of 500 and a standard deviation of 100. What are the z-scores for the following data values: 520, 650, 500, 450, and 280?\n3.16 Consider a sample with a mean of 30 and a standard deviation of 5. Use Chebyshev’s theorem to determine the percentage of the data within each of the following ranges:\n\n20 to 40\n15 to 45\n\n3.17 The results of a national survey showed that on average, adults sleep 6.9 hours per night. Suppose that the standard deviation is 1.2 hours.\n\nUse Chebyshev’s theorem to calculate the percentage of individuals who sleep between 4.5 and 9.3 hours.\nUse Chebyshev’s theorem to calculate the percentage of individuals who sleep between 3.9 and 9.9 hours.\nAssume that the number of hours of sleep follows a bell-shaped distribution. Use the empirical rule to calculate the percentage of individuals who sleep between 4.5 and 9.3 hours per day. How does this result compare to the value that you obtained using Chebyshev’s theorem in part (a)?\n\n3.18 The high costs in the California real estate market have caused families who cannot afford tobuy bigger homes to consider backyard sheds as an alternative form of housing expansion. Many are using the backyard structures for home offices, art studios, and hobby areas as well as for additional storage. The mean price of a customized wooden, shingled backyard structure is $3100 (Newsweek, September 29, 2003). Assume that the standard deviation is $1200. a. What is the z-score for a backyard structure costing $2300?\n\nWhat is the z-score for a backyard structure costing $4900?\nInterpret the z-scores in parts (a) and (b). Comment on whether either should be considered an outlier.\nThe Newsweek article described a backyard shed-office combination built in Albany, California, for $13,000. Should this structure be considered an outlier? Explain.\n\n3.19 Consider a sample with data values of 27, 25, 20, 15, 30, 34, 28, and 25. Provide the five-number summary for the data. Also construct a boxplot.\n3.20 A data set has a first quartile of 42 and a third quartile of 50. Compute the lower and upper limits for the corresponding box plot. Should a data value of 65 be considered an outlier?\n\n3.21 A sample of 28 time shares in the Orlando, Florida, area revealed the following daily charges (in USD dollars) for a one-bedroom suite. For convenience, the data are ordered from smallest to largest.\n116, 121, 157, 192, 207, 209, 209, 229, 232, 236, 236, 239, 243, 246,\n260,264, 276, 281, 283, 289, 296, 307, 309, 312, 317, 324, 341, 353\na) Compute the lower and upper limits and check for outlier(s).\nb) Then construct a boxplot of the daily charges and show the outlier(s) if any in the boxplot.\nc) Comment on the distribution of the daily charges.\n\n3.22 Suppose a consumer group asked 18 consumers to keep a yearly log of their shopping practices and that the following data represent the number of coupons used by each consumer over the yearly period.\n\nDataOrdered data\n\n\n81, 68, 70, 100, 94, 47, 66, 70, 82, 110, 105, 60, 21, 70, 66, 90, 78, 85\n\n\n\n\n\nCode\nthree20&lt;-c( 81, 68, 70, 100, 94, 47, 66, 70, 82, 110, 105,60, 21, 70, 66, 90, 78, 85)\n\n#sort(three20)\n\n\n21, 47, 60, 66, 66, 68, 70, 70, 70, 78, 81, 82, 85, 90, 94, 100, 105, 110\n\n\n\na) Use the data to construct a box-and-whisker plot.\nb) Discuss the skewness of the distribution of these data and point out any outliers.\n\n\n\n\n\n\n\nAnderson, David R. 2020a. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\n———. 2020b. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nAnderson, David R., and Dennis J. Sweeney. 2011. Statistics for Business and Economics. 11e [ed.]. Australia ; Mason, Ohio: South-Western Cengage Learning.\n\n\nLind, Douglas A., William G. Marchal, and Samuel Adam Wathen. 2012. Statistical Techniques in Business & Economics. 15th ed. New York, NY: McGraw-Hill/Irwin.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013. Statistics for business and economics. 8. ed., global ed. Always learning. Boston, Mass. Munich: Pearson.\n\n\nR Core Team. 2024. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive statistics: Numerical Measures</span>"
    ]
  },
  {
    "objectID": "Probability.html",
    "href": "Probability.html",
    "title": "4  Probability",
    "section": "",
    "text": "4.1 Random experiment\nA random experiment is a process leading to two or more possible outcomes, without knowing exactly which outcome will occur (Newbold, Carlson, and Thorne 2013).\nExample 4.1: Tossing a coin, throwing a dice, change in the stock prices etc.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#sample-space",
    "href": "Probability.html#sample-space",
    "title": "4  Probability",
    "section": "4.2 Sample space",
    "text": "4.2 Sample space\nA sample space is the collection of all outcomes of a random experiment. The sample space is usually denoted by \\(S\\) or Greek letter \\(\\Omega\\) (omega).\nExample 4.2:\n\nIf we toss a coin then the sample space is: \\(S=\\{H,T\\}\\)\nIf we toss 2 coins then the sample space is: \\(S=\\{HH,HT,TH,TT\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#event",
    "href": "Probability.html#event",
    "title": "4  Probability",
    "section": "4.3 Event",
    "text": "4.3 Event\nAn event is a subset of a sample space.\nFor example suppose, \\(S=\\{HH,HT,TH,TT\\}\\) and \\(A=\\{HH,TT\\}\\) is an event which a subset of sample space \\(S\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#complement-of-an-event",
    "href": "Probability.html#complement-of-an-event",
    "title": "4  Probability",
    "section": "4.4 Complement of an event",
    "text": "4.4 Complement of an event\nThe complement of an event A with respect to Ω is the subset of all elements of \\(\\Omega\\) that are not in A. We denote the complement of A by the symbol \\(A^C\\).\nExample 4.3: Consider the sample space:\n\\(\\Omega =\\{ 1,2,3,4,5,6\\}\\)\nLet, \\(A=\\{1,3,5 \\}\\). Then the complement of \\(A\\) is \\(A^C=\\Omega-A=\\{2,4,6\\}\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#mutually-exclusive-events",
    "href": "Probability.html#mutually-exclusive-events",
    "title": "4  Probability",
    "section": "4.5 Mutually exclusive events",
    "text": "4.5 Mutually exclusive events\nThe occurrence of one event means that none of the other events can occur at the same time.\nExample 4.4:\n\nThe variable “Employment status” presents mutually exclusive outcomes, employed and unemployed. An employee selected at random is either male or female but cannot be both.\nA manufactured part is acceptable or unacceptable. The part cannot be both acceptable and unacceptable at the same time.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#collectively-exhaustive",
    "href": "Probability.html#collectively-exhaustive",
    "title": "4  Probability",
    "section": "4.6 Collectively Exhaustive",
    "text": "4.6 Collectively Exhaustive\nGiven the \\(K\\) events \\(E_1\\), \\(E_2\\), . . . , \\(E_K\\) in the sample space, \\(S\\), if \\(E_1 \\cup E_2 \\cup . . . \\cup E_K = S\\), these \\(K\\) events are said to be collectively exhaustive.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#axiomatic-definition-of-probability",
    "href": "Probability.html#axiomatic-definition-of-probability",
    "title": "4  Probability",
    "section": "4.7 Axiomatic definition of Probability",
    "text": "4.7 Axiomatic definition of Probability\nThe probability of an event \\(A\\) is the sum of the weights of all sample points in \\(A\\). Therefore,\n(a) \\(0 \\le P(A)\\le 1\\)\n(b) If \\(A_1, A_2,A_3,...\\) is a sequence of mutually exclusive events, then\n\\[ P(A_1\\cup A_2 \\cup  A_3\\cup ...).=P(A_1)+P(A_2)+P(A_3)+... \\]\n(c) \\(P(\\Omega)=1\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#probability-of-an-event-classical-approach",
    "href": "Probability.html#probability-of-an-event-classical-approach",
    "title": "4  Probability",
    "section": "4.8 Probability of an event (Classical approach)",
    "text": "4.8 Probability of an event (Classical approach)\nSuppose an event \\(A\\) is defined in the sample space \\(S\\). Then the probability of event \\(A\\) is defined as :\n\\[\nP(A)=\\frac{n(A)}{n(S)};\n\\]\nHere,\n\\(n(A)=\\) number of outcomes favorable to event \\(A\\);\n\\(n(S)=\\) total number of outcomes in the sample space \\(S\\).\nExample 4.5 Consider a random experiment of throwing two six-sided fair dices. Then the sample space is:\n\n\n\n\nDice2\n\n\n\n\n\n\n\n\n\nDice1\n(1,1)\n(1,2)\n(1,3)\n(1,4)\n(1,5)\n(1,6)\n\n\n\n(2,1)\n(2,2)\n(2,3)\n(2,4)\n(2,5)\n(2,6)\n\n\n\n(3,1)\n(3,2)\n(3,3)\n(3,4)\n(3,5)\n(3,6)\n\n\n\n(4,1)\n(4,2)\n(4,3)\n(4,4)\n(4,5)\n(4,6)\n\n\n\n(5,1)\n(5,2)\n(5,3)\n(5,4)\n(5,5)\n(5,6)\n\n\n\n(6,1)\n(6,2)\n(6,3)\n(6,4)\n(6,5)\n(6,6)\n\n\n\nNow compute the following probabilities:\na) probability of same number in both dices;\nb) probability that sum of the numbers of two dices are equal to 5.\nSolution: Here \\(n(\\Omega)=36\\)\na) Let, \\(A\\)={same number in both dices}={(1,1),(2,2),(3,3),(4,4),(5,5),(6,6)}.\nHence, \\(n(A)=6\\). So, \\(P(A)=\\frac{n(A))}{n(\\Omega)}=\\frac{6}{36}=\\frac{1}{6}\\).\nb) DIY (do it yourself).\nExample 4.6 A box/ an urn contains 6 black balls and 4 white balls. If two balls are selected at random (at a time) what is the probability that the\ni) both balls will be black?\nii) both balls will be white?\nSolution-i) Here, 2 balls can be selected in total \\({10\\choose 2}=45\\) ways. So, \\(n(\\Omega)=45\\).\nSuppose, \\(B\\)={2 black balls selected}. Two black balls can be selected in \\({6\\choose 2}=15\\) ways. So, \\(n(B)=15\\).\n\\(\\therefore P(B)=\\frac{n(B)}{n(\\Omega)}=\\frac{15}{45}=\\frac{1}{3}\\).\nSolution-i) DIY.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#probability-of-an-event-empirical-approach",
    "href": "Probability.html#probability-of-an-event-empirical-approach",
    "title": "4  Probability",
    "section": "4.9 Probability of an event (Empirical approach)",
    "text": "4.9 Probability of an event (Empirical approach)\nEmpirical Probability is a type of probability that is calculated based on actual observations, experiments, or historical data rather than theoretical assumptions. It measures the likelihood of an event occurring by analyzing past occurrences or experimental results.\nFormula for Empirical Probability:\n\\[\nP(E)=\\frac{Number\\ \\ of  \\ \\ times \\ \\ the\\ \\  event\\ \\  occurs}{Total \\ \\ number\\ \\  of \\ \\ trials}\n\\]\nWhere:\n\n\\(P(E)\\) is the probability of the event \\(E\\),\nThe numerator is the count of occurrences of the event, and\nThe denominator is the total number of trials or observations.\n\nExample 4.7: Suppose in a class there are 30 students; 20 are male and 10 are females. If a student is selected at random what is the probability that he is a male?\nSolution: Let, \\(E_1=\\) set of male students and \\(E_2=\\) set of female students. And, \\(S=\\) set of all students\nSo, probability that a male student is selected is: \\[\nP(E_1)=\\frac{n(E_1)}{n(S)}=\\frac{20}{30}=0.66667\\approx 0.67\n\\] Interpretation There is almost \\(67\\%\\) chance that the selected student will be male.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#properties-of-probability-laws",
    "href": "Probability.html#properties-of-probability-laws",
    "title": "4  Probability",
    "section": "4.10 Properties of Probability Laws",
    "text": "4.10 Properties of Probability Laws\nProbability laws have a number of properties, which can be deduced from the axioms. Some of them are summarized below.\na) \\(P(A^C)=1-P(A)\\) [complement rule]\nb) \\(P(A \\cap B^C )=P(A)-P(A \\cap B)\\) [only A happens]\nc) \\(P(A \\cup B)=P(A)+P(B)-P(A \\cap B)\\) [additive rule]\nd) \\(P(A^C \\cap B^C )=P(A∪B)^C=1-P(A \\cup B)\\). [neither A NOR B happens]\ne) \\(P(only \\ \\ A \\  \\ \\ or \\ \\ only \\ \\ B)=P(A \\cap B^C)+P(A^C\\cap B)\\)\n\\(=P(A)+P(B)-2 P(A\\cap B)\\)\nExample 4.8: In a class 65% students prefer tea and 35% students prefer coffee. While 15% students prefer both tea and coffee. If a student is selected at random from the class find the probability that\n\nhe/she prefers only coffee\nhe/she prefers tea or coffee\nhe/she prefers none (neither tea nor coffee)\n\nExample 4.9 (Lind, Marchal, and Wathen 2012, 166)A local bank reports that 80 percent of its customers maintain a checking account, 60 percent have a savings account, and 50 percent have both. If a customer is chosen at random, what is the probability the customer has either a checking or a savings account? What is the probability the customer does not have either a checking or a savings account?\nExample 4.10 (Lind, Marchal, and Wathen 2012, 166)All Seasons Plumbing has two service trucks that frequently need repair. If the probability the first truck is available is .75, the probability the second truck is available is .50, and the probability that both trucks are available is .30, what is the probability neither truck is available?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#conditional-probability",
    "href": "Probability.html#conditional-probability",
    "title": "4  Probability",
    "section": "4.11 Conditional Probability",
    "text": "4.11 Conditional Probability\nThe conditional probability of an event \\(A\\), given an event \\(B\\) with \\(P(B) &gt; 0\\), is defined by,\n\\[\nP(A|B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{n(A\\cap B)}{n(B)}\n\\] Example 4.11 The probability that a regularly scheduled flight departs on time is \\(P(D) = 0.83\\); the probability that it arrives on time is \\(P(A) = 0.82\\); and the probability that it departs and arrives on time is \\(P(D \\cap A) = 0.78\\). Find the probability that a plane:\n\narrives on time, given that it departed on time, and\ndeparted on time, given that it has arrived on time.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#the-multiplication-rule",
    "href": "Probability.html#the-multiplication-rule",
    "title": "4  Probability",
    "section": "4.12 The Multiplication Rule",
    "text": "4.12 The Multiplication Rule\nThe multiplication rule is used to calculate the joint probability of two events.\nThe joint probability of any two events A and B is\n\\[ P(A\\cap B)=P(B). P(A|B) \\ \\ [Considering \\ \\ B \\ \\ as \\ \\ prior] \\]\nor, altering the notation,\n\\[ P(A\\cap B)=P(A). P(B|A) \\ \\ [Considering \\ \\ A \\ \\ as \\ \\ prior] \\]\nExample 4.12: Suppose a box contains 10 balls; 4 are black and 6 are white. If 2 balls are drawn at random successively without replacement , what is the probability that both balls are white?\nSolution:\nLet, W1= 1st ball is white ; W2=2nd ball is also white.\nAccording to question, \\[ P(both \\ \\ balls \\ \\ are \\ \\ white)=P(W_1\\cap W_2)=P(W_1).P(W_2|W_1) \\]\n\\[ =\\frac{6}{10}.\\frac{5}{9}=\\frac{1}{3} \\]\nExample 4.13 Suppose \\(P(A)=0.40\\) and \\(P(B|A)=0.30\\). What is the joint probability of \\(A\\) and \\(B\\) ?\nExample 4.14 Suppose \\(P(X_1)=0.75\\) and \\(P(Y_2|X_1)=0.30\\). What is the joint probability of \\(X_1\\) and \\(Y_2\\) ?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#independent-events",
    "href": "Probability.html#independent-events",
    "title": "4  Probability",
    "section": "4.13 Independent events",
    "text": "4.13 Independent events\nIf two events A and B are independent, the probability that both of them occur is equal to the product of their individual probabilities i.e.\n\\[ P(A\\cap B)=P(A) P(B) \\]\n\nCorollary: If A and B are independent events then their complement events also be independent that is,\n\n\\[ P(A^C\\cap B^C)=P(A^C) P(B^C) \\]\n\nIndependence Rule for Multiple events:\n\n\\[ P(A\\cap B \\cap C )=P(A) P(B) P(C)  \\]\nExample 4.15 (Lind, Marchal, and Wathen 2012, 182) You take a trip by air that involves three independent flights. If there is an 80 percent chance each specific leg of the trip is done on time, what is the probability all three flights arrive on time?\nExample 4.16 (Lind, Marchal, and Wathen 2012, 182) The probability a HP network server is down is .05. If you have three independent servers, what is the probability that at least one of them is operational?\nSolution:\nGiven, \\(P(server \\ \\ is \\ \\ down)=0.05\\).\nSo, \\(P(server \\  \\ is \\ \\ operational)=0.95\\)\nNow, let \\(O_i=\\{ i^{th} \\ \\ server \\ \\ is \\ \\ operational\\}\\)\nSo,\n\\(P(at \\ \\ least \\ \\ one\\ \\  of\\ \\  them\\ \\   is \\  \\ operational)\\)\n\\(=P(O_1 \\cup O_2 \\cup O_3)=1-P(O_1^C \\cap O_2^C \\cap O_3^C)\\)\n\\(=1-P(O_1^C) \\cdot P(O_2^C) \\cdot P(O_3^C)\\)\n\\(=1-(0.05)(0.05)(0.05)=0.9999875\\).\nExample 4.17 (Lind, Marchal, and Wathen 2012, 182) Twenty-two percent of all liquid crystal displays (LCDs) are manufactured by Samsung. What is the probability that in a collection of three independent LCD purchases, at least one is a Samsung?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#bivariate-probabilities-joint-and-marginal-probability",
    "href": "Probability.html#bivariate-probabilities-joint-and-marginal-probability",
    "title": "4  Probability",
    "section": "4.14 Bivariate Probabilities: Joint and Marginal Probability",
    "text": "4.14 Bivariate Probabilities: Joint and Marginal Probability\nThe Intersection of events \\(A\\) and \\(B\\) is the event that occurs when both A and B occur.\nIt is denoted as A and B or \\((A\\cap B)\\).\nThe probability of the intersection is called the joint probability that is \\(P(A\\cap B)\\).\nExample 4.18: Suppose that our sample space \\(S\\) is the population of \\(900\\) adults in a small town who have completed the requirements for a college degree. We shall categorize them according to gender and employment status. The data are given in Table 4.1 (also referred as joint frequency table or cross-table)\n\n\n\nTable 4.1: Categorization of the Adults in a Small Town\n\n\n\n\n\n\nEmployed\nUnemployed\n\n\n\n\nMale\n460\n40\n\n\nFemale\n140\n260\n\n\n\n\n\n\nQuestion i: Construct a joint probability table\nSolution i: Let,\n\\(A_1=\\) Male adults\n\\(A_2=\\) Female adults\n\\(B_1=\\) Employed adults\n\\(B_2=\\) Unemployed adults\nHere \\(n(S)=900\\). Now divide all cell frequency by \\(900\\) and round to 2 decimal points, hence we get joint probability table below(see Table 4.2):\n\n\n\nTable 4.2: Joint probability table\n\n\n\n\n\n\nB1\nB2\n\n\n\n\nA1\n0.51\n0.04\n\n\nA2\n0.16\n0.29\n\n\n\n\n\n\nJoint probability: In Table 4.2 the joint probabilities are:\n\n\\(P(A_1\\cap B_1)=0.51\\)\n\\(P(A_1 \\cap B_2)=0.04\\)\n\\(P(A_2\\cap B_1)=0.16\\) and\n\\(P(A_2\\cap B_2)=0.29\\)\n\nMarginal probability: In Table 4.2 the marginal probabilities are:\n\n\\(P(A_1)=0.51+0.04=0.55\\)\n\\(P(A_2)=0.16+0.29=0.45\\)\n\\(P(B_1)=0.51+0.16=0.67\\)\n\\(P(B_2)=0.04+0.29=0.33\\)\n\nFrom a joint probability table we cab also compute conditional probabilities. For example,\n\\(P(A_1|B_1)=\\frac{P(A_1\\cap B_1)}{P(B_1)}=\\frac{0.51}{0.67}\\approx 0.7612\\)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#independent-events-in-joint-probability-table",
    "href": "Probability.html#independent-events-in-joint-probability-table",
    "title": "4  Probability",
    "section": "4.15 Independent Events in Joint probability table",
    "text": "4.15 Independent Events in Joint probability table\nLet \\(A\\) and \\(B\\) be a pair of events, each broken into mutually exclusive and collectively exhaustive event categories denoted by labels \\(A_1\\), \\(A_2\\), . . . , \\(A_H\\) and \\(B_1\\),\\(B_2\\), . . . , \\(B_K\\). If every event \\(A_i\\) is statistically independent of every event \\(B_j\\), then \\(A\\) and \\(B\\) are independent events (Newbold, Carlson, and Thorne 2013).\nExample 4.19 Students in a business statistics class were asked what grade they expected in the course and whether they worked on additional problems beyond those assigned by the instructor. The following table gives proportions of students in each of eight joint classifications (Newbold, Carlson, and Thorne 2013, exercise 3.68).\n\n\n\n\n\n\nFind the probability that a randomly chosen student from this class worked on additional problems.\nFind the probability that a randomly chosen student from this class expects an A.\nFind the probability that a randomly chosen student expects an A given that he/she worked on additional problems .\nFind the probability that a randomly chosen student worked on additional problems given that he/she expects an A .\nAre “worked additional problems” and “expected grade” statistically independent?\n\nSolution:\nLet, Y={Yes} and N={No}.\nThe joint probability table with marginal probability table is given below:\n\n\n\n\n\n\n\n\n\n\n\n\nA\nB\nC\nD (Below C)\nRow total\n\n\n\n\nY\n0.12\n0.06\n0.12\n0.02\n0.32\n\n\nN\n0.13\n0.21\n0.26\n0.08\n0.68\n\n\nColumn total\n0.25\n0.27\n0.38\n0.10\n1.00\n\n\n\nSolution of (e): To show whether “worked additional problems” and “expected grade” statistically independent we have to verify whether “Y, N” and “A”, “B”, “C” are independent events.\nNow from joint probability table, \\(P(Y\\cap A)=0.12\\).\nAnd \\(P(Y\\cap A)=P(Y)\\cdot P(A)=0.32\\times 0.25=0.08\\).\nSince \\(P(Y\\cap A) \\ne P(Y) \\cdot P(A)\\) so, \\(Y\\) and \\(A\\) are not independent. Hence, we do not need to test other combinations.\nIn conclusion we can say that “worked additional problems” and “expected grade” are not statistically independent.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#probability-trees",
    "href": "Probability.html#probability-trees",
    "title": "4  Probability",
    "section": "4.16 Probability Trees",
    "text": "4.16 Probability Trees\nConsider a sequential experiment where in the first stage either \\(A_1\\) or \\(A_2\\) can be happened with some probabilities . And in the second stage event \\(B\\) can be happened. If \\(B^C\\) is the complement of \\(B\\) then this experiment can be shown in the following tree diagram.\n\n\n\n\n\nExample 4.20:\nTwo balls are drawn in succession, without replacement, from a box containing 3 blue and 2 white balls .\n\nWhat is the probability that both balls will be white ?\n\nSolution: Here, two balls are drawn in succession (one by one) without replacement. This experiment can be shown in the following tree:\n\n\n\n\n\nThe probability of drawing a white ball on the first draw and a white ball on the second draw (both are white) is:\n\\(P(W_1\\cap W_2)=P(W_1) P(W_2|W_1)=(\\frac {2}{5}) (\\frac {1}{4})=\\frac {1}{10}\\)\n\nWhat is the probability that the second ball is white?\n\nSolution:\n\\(P(W_2)=P(W_1\\cap W_2)+P(B_1\\cap W_2)\\)\n\\(=P(W_1)P(W_2|W_1)+P(B_1)P(W_2|B_1)\\)\n\\(=(\\frac{2}{5})(\\frac{1}{4})+(\\frac{3}{5})(\\frac{2}{4})=\\frac{1}{10}+\\frac{3}{10}=\\frac{4}{10}=\\frac{2}{5}\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#exercises-4.1",
    "href": "Probability.html#exercises-4.1",
    "title": "4  Probability",
    "section": "4.17 Exercises 4.1",
    "text": "4.17 Exercises 4.1\n4.1) (Anderson and Sweeney 2011) Suppose that we have two events, A and B, with \\(P(A)= .50\\), \\(P(B) = .60\\), and \\(P(A \\cap B) = .40\\) .\n\nFind \\(P(A | B)\\).\nFind \\(P(B | A)\\).\nAre A and B independent? Why or why not?\n\n4.2) Suppose P(A)=0.40 and P(B|A)=0.30. What is the joint probability of A and B?\n4.3) A local bank reports that 80 percent of its customers maintain a checking account, 60 percent have a savings account, and 50 percent have both. If a customer is chosen at random, what is the probability the customer has either a checking or a savings account? What is the probability the customer does not have either a checking or a savings account?\n4.4) (Keller 2014) Suppose we have the following joint probabilities .\n\n\n\n\nA1\nA2\nA3\n\n\nB1\n0.15\n0.20\n0.10\n\n\nB2\n0.25\n0.25\n0.05\n\n\n\nCompute the marginal probabilities.\n4.5) Refer to Exercise 4.\n\nCompute \\(P(A_2|B_2)\\).\nCompute \\(P(B_1|A_2)\\).\n\n4.6) Refer to Exercise 2.\n\nCompute \\(P(A_1 \\ \\ or \\ \\ A_2)\\).\nCompute \\(P(A_2\\ \\ or \\ \\ B_2)\\).\n\n4.7) Credit scorecards are used by financial institutions to help decide to whom loans should be granted. An analysis of the records of one bank produced the following probabilities.\n\n\n\nLone Performance\nScore Under 400\nScore 400 or more\n\n\n\n\nFully repaid\n0.19\n0.64\n\n\nDefaulted\n0.13\n0.04\n\n\n\n\nWhat proportion of loans are fully repaid?\nWhat proportion of loans was fully repaid if someone’s score is less than 400 ?\nWhat proportion of loans was fully repaid if someone’s score is than 400 or more?\nAre score and whether the loan is fully repaid independent? Explain.\n\n4.8) A firm has classified its customers in two ways: (1) according to whether the account is overdue and (2) whether the account is new (less than 12 months) or old. An analysis of the firm’s records provided the input for the following table of joint probabilities.\n\n\n\n\nOverdue\nNot overdue\n\n\nNew\n0.06\n0.13\n\n\nOld\n0.52\n0.29\n\n\n\nOne account is randomly selected.\n\nIf the account is overdue, what is the probability that it is new?\nIf the account is new, what is the probability that it is overdue?\nIs the age of the account related to whether it is overdue? Explain.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#total-probability-rule-and-bayes-theorem",
    "href": "Probability.html#total-probability-rule-and-bayes-theorem",
    "title": "4  Probability",
    "section": "4.18 Total Probability rule and Bayes’ Theorem",
    "text": "4.18 Total Probability rule and Bayes’ Theorem\nSuppose \\(A_1\\), \\(A_2\\),and \\(A_3\\) are mutually exclusive and exhaustive events, that is:\n\\(P(A_i \\cap A_j)=0\\) for \\(i\\ne j=1,2,3\\);\nand\n\\[\nP(A_1 \\cup A_2 \\cup A_3)=1\n\\]\n\nThe prior probabilities are \\(P(A_1)\\), \\(P(A_2)\\) and \\(P(A_3)\\).\nThe likelihood/conditional probabilities are \\(P(B|A_1)\\), \\(P(B|A_2)\\) and \\(P(B|A_3)\\)(see Figure 4.1).\n\n\n\n\n\n\n\nFigure 4.1\n\n\n\nThe total probability rule\n\\[\nP(B)=P(A_1).P(B|A_1)+P(A_2).P(B|A_2)+P(A_3).P(B|A_3)\n\\]\nBayes’ theorem\nThe Bayes’ theorem is used to find the posterior/revised/update probabilities of prior probabilities.\n\\[\nP(A_1|B)=\\frac{P(A_1\\cap B)}{P(B)}\n=\\frac{P(A_1).P(B|A_1)}{P(A_1).P(B|A_1)+P(A_2).P(B|A_2)+P(A_3).P(B|A_3)}\n\\]\nIn the same way we can compute \\(P(A_2|B)\\) and \\(P(A_3|B)\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "Probability.html#exercises-4.2",
    "href": "Probability.html#exercises-4.2",
    "title": "4  Probability",
    "section": "4.19 Exercises 4.2",
    "text": "4.19 Exercises 4.2\n4.9) (Anderson and Sweeney 2011) The prior probabilities for events \\(A_1\\) and \\(A_2\\) are \\(P(A_1) = .40\\) and \\(P(A2) = .60\\). It is also known that \\(P(A_1\\cap A_2) = 0\\). Suppose \\(P(B | A_1) = .20\\) and \\(P(B | A_2)= .05\\).\n\nAre \\(A_1\\) and \\(A_2\\) mutually exclusive? Explain.\nCompute \\(P(A_1 \\cap B)\\) and \\(P(A_2 \\cap B)\\).\nCompute \\(P(B)\\).\nApply Bayes’ theorem to compute \\(P(A_1 | B)\\) and \\(P(A_2 | B)\\).\n\n4.10) (Lind, Marchal, and Wathen 2012, 171) The Ludlow Wildcats baseball team, a minor league team in the Cleveland Indians organization, plays 70 percent of their games at night and 30 percent during the day. The team wins 50 percent of their night games and 90 percent of their day games. According to today’s newspaper, they won yesterday. What is the probability the game was played at night?\n4.11) (Lind, Marchal, and Wathen 2012, 171) Dr. Stallter has been teaching basic statistics for many years. She knows that 80 percent of the students will complete the assigned problems. She has also determined that among those who do their assignments, 90 percent will pass the course. Among those students who do not do their homework, 60 percent will pass. Mike Fishbaugh took statistics last semester from Dr. Stallter and received a passing grade. What is the probability that he completed the assignments?\n4.12) (Anderson and Sweeney 2011) A local bank reviewed its credit card policy with the intention of recalling some of its credit cards. In the past approximately 5% of cardholders defaulted, leaving the bank unable to collect the outstanding balance. Hence, management established a prior probability of .05 that any particular cardholder will default. The bank also found that the probability of missing a monthly payment is .20 for customers who do not default. Of course, the probability of missing a monthly payment for those who default is 1.\n\nGiven that a customer missed one or more monthly payments, compute the posterior probability that the customer will default.\nThe bank would like to recall its card if the probability that a customer will default is greater than .20. Should the bank recall its card if the customer misses a monthly payment? Why or why not?\n\n4.13) (Black 2012)In a manufacturing plant, machine A produces 10% of a certain product, machine B produces 40% of this product, and machine C produces 50% of this product. Five percent of machine A products are defective, 12% of machine B products are defective, and 8% of machine C products are defective. The company inspector has just sampled a product from this plant and has found it to be defective. Determine the revised probabilities that the sampled product was produced by machine A,machine B, or machine C .\n4.14) (Black 2012) Suppose 70% of all companies are classified as small companies and the rest as large companies. Suppose further, 82% of large companies provide training to employees, but only 18% of small companies provide training. A company is randomly selected without knowing if it is a large or small company; however, it is determined that the company provides training to employees. What are the prior probabilities that the company is a large company or a small company? What are the revised probabilities that the company is large or small? Based on your analysis, what is the overall percentage of companies that offer training?\n4.15) (Black 2012) Alex, Alicia, and Juan fill orders in a fast-food restaurant. Alex incorrectly fills 20% of the orders he takes. Alicia incorrectly fills 12% of the orders she takes. Juan incorrectly fills 5% of the orders he takes. Alex fills 30% of all orders, Alicia fills 45% of all orders, and Juan fills 25% of all orders. An order has just been filled.\n\nWhat is the probability that Alicia filled the order?\nIf the order was filled by Juan, what is the probability that it was filled correctly?\nWho filled the order is unknown, but the order was filled incorrectly. What are the revised probabilities that Alex, Alicia, or Juan filled the order?\nWho filled the order is unknown, but the order was filled correctly. What are the revised probabilities that Alex, Alicia, or Juan filled the order?\n\n\n\n\n\nAnderson, David R., and Dennis J. Sweeney. 2011. Statistics for Business and Economics. 11e [ed.]. Australia ; Mason, Ohio: South-Western Cengage Learning.\n\n\nBlack, Ken. 2012. Business statistics: for contemporary decision making. 7th ed. Hoboken, NJ: Wiley.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nLind, Douglas A., William G. Marchal, and Samuel Adam Wathen. 2012. Statistical Techniques in Business & Economics. 15th ed. New York, NY: McGraw-Hill/Irwin.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013. Statistics for business and economics. 8. ed., global ed. Always learning. Boston, Mass. Munich: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html",
    "href": "randomvariable_and_discrete probability dist.html",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "",
    "text": "5.1 Definition\nA variable is said to be random if its values are determined by a random experiment. In other word, random variable is a numerical description of the outcome of an experiment.\nIllustration Consider a random experiment of tossing a coin (fair/unfair) 2 times. Then the sample space is\n\\[\nS=\\{ HH,HT,TH,TT \\}\n\\]\nNow let, \\(X= number\\ \\  of\\ \\  heads \\ \\ occur\\)\nFrom the sample space we can see that \\(X\\) can take following values:\nSince the values of \\(X\\) completely determined by the outcomes of the random experiment, so \\(X\\) is a random variable (discrete).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html#definition",
    "href": "randomvariable_and_discrete probability dist.html#definition",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "",
    "text": "A random variable often denoted with an uppercase letter (say \\(X\\))\nThe value of a random variable is denoted with a lowercase letter (say \\(x\\))\n\n\n\n\n\n\n\n\nSample point\n\\(x\\)\n\n\n\\(HH\\)\n2\n\n\n\\(HT\\)\n1\n\n\n\\(TH\\)\n1\n\n\n\\(TT\\)\n0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html#types-of-random-variable",
    "href": "randomvariable_and_discrete probability dist.html#types-of-random-variable",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "5.2 Types of random variable",
    "text": "5.2 Types of random variable\nThere are two types of random variables, discrete and continuous.\nA discrete random variable can assume only a certain number of separated values. A discrete random variable is usually the result of counting something. For example, number of customers arrive, number of calls receive etc.\nA continuous random variable is one whose values are uncountable or which can take any value in a given interval. Generally a continuous random variable is usually the result of measuring something.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html#discrete-random-variable-and-probability-mass-function",
    "href": "randomvariable_and_discrete probability dist.html#discrete-random-variable-and-probability-mass-function",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "5.3 Discrete random variable and Probability mass function",
    "text": "5.3 Discrete random variable and Probability mass function\nSuppose \\(X\\) is a discrete random variable. The probability mass function (PMF) of \\(X\\) can be denoted as \\(f(x)\\) where\n\\[ f(x)=P(X=x) \\]For each possible outcome \\(x\\) ; \\(f(x)\\) must satisfies:\n\n\\[f(x) \\ge 0\\]\n\\[\\sum _x f(x)=1\\]\n\nThe PMF \\(f(x)\\) is also called probability distribution of the discrte random variable \\(X\\).\nExample 5.1 John Ragsdale sells new cars for Pelican Ford. John usually sells the largest number of cars on Saturday. He has developed the following probability distribution for the number of cars he expects to sell on a particular Saturday.\n\n\n\nNumber of cars sold, \\(x\\)\nProbability, \\(f(x)\\)\n\n\n0\n0.10\n\n\n1\n0.20\n\n\n2\n0.30\n\n\n3\n0.30\n\n\n4\n0.10\n\n\n\nCompute (i) \\(P(X=2)\\) ; (ii) \\(P(X&lt;2)\\) ; (iii) \\(P(X \\ge 3)\\)\n\n\n5.3.1 Expectation (Mean) of discrete random variable\nLet \\(X\\) be a discrete random variable with probability mass function \\(f(x) = P(X = x)\\).\nThe mean of \\(X\\) is given by\n\\[\\mu=\\sum_x x.f(x)\\]\nThe mean of \\(X\\) is sometimes called the expectation, or expected value, of X and may also be denoted by \\(E(X)\\) or by \\(\\mu\\).\n\nExample 5.2 John Ragsdale sells new cars for Pelican Ford. John usually sells the largest number of cars on Saturday. He has developed the following probability distribution for the number of cars he expects to sell on a particular Saturday.\n\n\n\nNumber of cars sold, \\(x\\)\nProbability, \\(f(x)\\)\n\n\n0\n0.10\n\n\n1\n0.20\n\n\n2\n0.30\n\n\n3\n0.30\n\n\n4\n0.10\n\n\n\nOn a typical Saturday, how many cars does John expect to sell?\n\nSolution:\n\nCalculation of the Expected Value for the Number of Cars Sold\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(x \\cdot f(x)\\)\n\n\n\n\n0\n0.10\n0.00\n\n\n1\n0.20\n0.20\n\n\n2\n0.30\n0.60\n\n\n3\n0.30\n0.90\n\n\n4\n0.10\n0.40\n\n\nTotal\n\\(\\sum f(x)=1\\)\n\\(\\mu =\\sum x\\cdot f(x)=2.10\\)\n\n\n\nAlternative: The mean number of cars is:\n\\[\\mu =E[X]=\\sum_{x=0}^4 x.f(x)\\]\n\\[=0(0.10)+1(0.20)+2(0.30)+3(0.30)+4(0.10)=2.1\\]\nSo on a typical Saturday, John Ragsdale expects to sell a mean of 2.1 cars a day.\n\n\n5.3.2 Variance of discrete random variable\nLet \\(X\\) be a discrete random variable with probability distribution \\(f(x)\\) and mean \\(\\mu\\). The variance of \\(X\\) is\n\\[var(X)=\\sigma^2 =E[(X-\\mu)^2]=\\sum_x (x-\\mu)^2 f(x)\\]Alternative:\n\\[var (X)=E(X^2)-\\mu^2\\] Where,\n\\[E(X^2)=\\sum_{x} x^2.f(x)\\]\nExample 5.3: From Example 5.2 compute variance and standard deviation of \\(X\\).\nSolution: From Example 5.2 we have \\(\\mu =2.1\\).\n\nCalculation of the Variance for the Number of Cars Sold\n\n\n\n\n\n\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\\(x-\\mu\\)\n\\((x-\\mu)^2\\)\n\\((x-\\mu)^2 f(x)\\)\n\n\n\n\n0\n0.10\n-2.1\n4.41\n0.441\n\n\n1\n0.20\n-1.1\n1.21\n0.242\n\n\n2\n0.30\n-0.1\n0.01\n0.003\n\n\n3\n0.30\n0.9\n0.81\n0.243\n\n\n4\n0.10\n1.9\n3.61\n0.361\n\n\nTotal\n\\(\\sum f(x)=1\\)\n\n\n\\(\\sigma^2 =1.290\\)\n\n\n\n\nAlternative: Here,\n\\[E(X^2)=\\sum_{x=0}^4 x^2.f(x)\\]\n\\(=0^2(0.10)+1^2 (0.20)+2^2 (0.30)+3^2 (0.30)+4^2 (0.10)\\)\n\\(=5.70\\)\nHence, \\(var(X)=\\sigma^2 =E(X^2)-\\mu^2=5.70-(2.10)^2=1.29\\)\n\nThe variance is, \\(\\sigma^2=1.29\\) and\nThe standard deviation is, \\(\\sigma=\\sqrt {1.29}=1.136\\)\n\n\n\n\n\n\n\nProperties of E(.) and var(.)\n\n\n\nIf \\(a\\) and \\(b\\) are constants, then\na) \\(E(b)=b\\)\nb) \\(E(aX+b)=aE(X)+b\\)\nc) \\(var(b)=0\\)\nd) \\(var(aX+b)=a^2 \\ \\ var (X)\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html#exercise-discrete-random-variable",
    "href": "randomvariable_and_discrete probability dist.html#exercise-discrete-random-variable",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "5.4 Exercise: Discrete random variable",
    "text": "5.4 Exercise: Discrete random variable\n5.1) Which of these variables are discrete and which are continuous random variables?\na. The number of new accounts established by a salesperson in a year.\nb. The time between customer arrivals to a bank ATM.\nc. The number of customers in Big Nick’s barber shop.\nd. The amount of fuel in your car’s gas tank.\ne. The number of minorities on a jury.\nf. The outside temperature today.\n\n5.2) Compute the mean and variance of the following probability distribution.\n\n\n\n\\(x\\)\n\\(f(x)\\)\n\n\n5\n0.10\n\n\n10\n0.30\n\n\n15\n0.20\n\n\n20\n0.40\n\n\n\n5.3) The information below is the number of daily emergency service calls made by the volunteer ambulance service of Walterboro, South Carolina, for the last 50 days. To explain, there were 22 days on which there were 2 emergency calls, and 9 days on which there were 3 emergency calls.\n\n\n\nNumber of calls\nFrequency\n\n\n0\n8\n\n\n1\n10\n\n\n2\n22\n\n\n3\n9\n\n\n4\n1\n\n\nTotal\n50\n\n\n\na. Convert this information on the number of calls to a probability distribution.\nb. Is this an example of a discrete or continuous probability distribution?\nc. What is the mean number of emergency calls per day?\nd. What is the standard deviation of the number of calls made daily?\n5.4) Consider the following probability distribution of random variable \\(X\\):\n\n\n\n\\(x\\)\n1\n3\n5\n7\n\n\n\\(f(x)\\)\nk\n2k\n2k\n3k\n\n\n\n(i) Find the value of k.\n(ii) Find the probability of the value of X exactly 4.\n(iii) Find the probability of the value of X between 3 and 7 (inclusive).\n(iv) Estimate expected value and standard deviation of X.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "randomvariable_and_discrete probability dist.html#some-discrete-probability-distributions",
    "href": "randomvariable_and_discrete probability dist.html#some-discrete-probability-distributions",
    "title": "5  Random variable and Discrete Probability Distribution",
    "section": "5.5 Some Discrete Probability Distributions",
    "text": "5.5 Some Discrete Probability Distributions\nIn the following sections we will discuss some commonly used discrete probability distributions which are used to predict number of success in finite number of random trials, or number of occurrence in a given interval or space and so on.\n\n5.5.1 Bernoulli distribution/r.v\nBernoulli r.v comes from Bernoulli trial-a trial which has TWO possible outcomes (success or failure).\nConsider the toss of a biased coin, which comes up a head with probability \\(p\\), and a tail with probability \\(1 - p\\). The Bernoulli random variable takes the two values 1 and 0, depending on whether the outcome is a head or a tail:\n\\[\nX=1 ; if \\ \\  a \\ \\ head,\\\\\nX=0 ;  if\\ \\  a \\ \\ tail.\n\\]\nPMF: \\(P(X=x)=f(x)=p^x (1-p)^{1-x}; \\ \\ x=0,1\\)\nMean: \\(E(X)=p\\)\nVariance: \\(Var(X)=p(1-p)\\)\nFor all its simplicity, the Bernoulli random variable is very important. In practice, it is used to model generic probabilistic situations with just two outcomes, such as:\n(a) The state of a telephone at a given time that can be either free or busy.\n(b) A person who can be either healthy or sick with a certain disease.\n(c) The preference of a person who can be either for or against a certain political candidate.\n\nFurthermore, by combining multiple Bernoulli random variables, one can construct more complicated random variables.\n\n\n\n\n\n\nNote\n\n\n\nDerivation of Mean and Variance of Bernoulli r.v\nMean:\n\\[E(X)=\\sum_{x=0}^1 x\\cdot f(x)=(0) f(0)+(1)f(1)=0+1\\cdotp p=p\\]\nVariance:\n\\(Var(X)=E(X^2)-[E(X)]^2=p-p^2=p(1-p)\\)\n\n\n\n\n5.5.2 Binomial r.v\nIn a Binomial experiment , the Bernoulli trial is repeated \\(n\\) times with the following conditions:\na) The trials are independent\nb) In each trial \\(P(success)=p\\) remains constant\nSuppose \\(X=number \\ \\ of \\ \\ successs \\ \\ in \\ \\ n\\ \\ trials\\). Then \\(X\\) is called a Binomial r.v or follows Binomial distribution.\nPMF: \\[P(X=x)=f(x)=\\binom {n}{x} p^x (1-p)^{n-x} ; x=0,1,2,...,n\\]\nMean: \\(E(X)=np\\)\nVariance: \\(Var(X)=np(1-p)\\)\nWe write \\(X\\sim Bin (n,p)\\)\n\n\n\n\n\n\nNote\n\n\n\nIf \\(Y=number \\ \\ of \\ \\ failures\\ \\ in \\ \\ n\\ \\ trials\\) then\n\\(Y\\sim Bin(n,1-p)\\)\n\n\n\n\n\n\n\n\nRelation between Bernoulli r.v and Binomial r.v\n\n\n\nA Binomial Random Variable Is a Sum of Bernoulli Random Variables\nLet, \\(Y_i\\) is a Bernoulli r.v appeared in \\(i^{th}\\) Bernoulli trial. If we conduct \\(n\\) independent Bernoulli trials then we have \\(n\\) independent Bernoulli r.vs such as \\(Y_1, Y_2, ..., Y_n\\). Each \\(Y_i\\) has values of either \\(1\\) or \\(0\\).\nNow if \\(X\\) is a Binomial r.v then,\n\\[\nX=Y_1+Y_2+...+Y_n =\\sum_{i=1}^n Y_i\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\nDerivation of Mean and Variance of Binomial r.v\nFrom previous note, we know if \\(Y_i\\) is a Bernoulli r.v then\n\\(E(Y_i)=p\\) and \\(Var(Y_i)=p(1-p)\\)\nSo, the mean of Binomial r.v that is\n\\[\nE(X)=E(Y_1+Y_2+...+Y_n)\n\\]\n\\[\n=E(Y_1)+E(Y_2)+...+E(Y_n)\n\\]\n\\[\n=p+p+...+p=np\n\\]\nNow, the variance of \\(X\\) is:\n\\[\nVar(X)=Var(Y_1+Y_2+...+Y_n)\n\\]\n\\[\n=Var(Y_1)+Var(Y_2)+...+Var(Y_n)\n\\]\n\\[\n=p(1-p)+p(1-p)+...+p(1-p)=np(1-p)\n\\]\n\n\nProbability plot of binomial r.v for different values of \\(p\\) and shape characteristics\n\n\nCode\nlibrary(tidyverse)\nsuccess &lt;- 0:10\np1&lt;-dbinom(success, size=10, prob=.2)\np2&lt;-dbinom(success, size=10, prob=.5)\np3&lt;-dbinom(success, size=10, prob=.8)\n\nwide.df&lt;-data.frame(success,p1,p2,p3)\n#wide.df\nwide.long&lt;-wide.df%&gt;%gather(key = \"p\",value = \"prob\",-success)\n#head(wide.long)\n\nwide.long&lt;-wide.long%&gt;%\n        mutate(p=recode(p,\n                        \"p1\"=\"p=0.2, positively skewed\",\n                        \"p2\"=\"p=0.5, symmetric\",\n                        \"p3\"=\"p=0.8, negatively skewed\"))\nwide.long%&gt;%ggplot(aes(success,prob))+\n        geom_col(width = .3,fill=\"black\")+\n        facet_wrap(~p)+\n        scale_x_continuous(breaks = seq(0, 10, 1))+\n        labs(x=\"x=# of success\",y=\"f(x)\",\n             title = \"Probability plot of Binomial distribution (n=10)\" )+\n  theme_bw()+\n  theme(axis.title = element_text(face = \"italic\"),\n                         plot.background = element_rect(color = \"black\"))-&gt;binomplot\n\nbinomplot\n\n\n\n\n\n\n\n\n\nExample 5.4 Consider a binomial experiment with \\(n = 10\\) and \\(p =0.30\\).\na) Compute \\(P(X=0)\\) ; b) Compute \\(P(X=2)\\);\nc) Compute \\(P(X \\le 1)\\) ; d) Compute \\(P(X\\ge 2)\\);\ne) Compute \\(E(X)\\) ; f) Compute \\(Var(X)\\) and \\(\\sigma\\).\n\nExample 5.5 A manufacturer of window frames knows from long experience that 30 percent of the production will have some type of minor defect that will require an adjustment. What is the probability that in a sample of 20 window frames:\na) none will need adjustment?\nb) at most two will need adjustment?\nc) at least two will need adjustment?\nd) Estimate the mean and standard deviation of number of adjustment.\nExample 5.6 A certain type of tomato seed germinates 90% of the time. A backyard farmer planted 25 seeds.\na) What is the probability that exactly 20 germinate?\nb) What is the probability that 23 or more germinate?\nc) What is the probability that 24 or fewer germinate?\nd) What is the expected number of seeds that germinate?\n\nExample 5.7 A shoe store’s records show that 30% of customers making a purchase use a credit card to pay. This morning, 10 customers purchased shoes from the store. Answer the following:\na) Find the probability that at least 8 of the customers used a credit card.\nb) What is the probability that at least three customers, but not more than five, used a credit card?\nc) What is the expected number of customers who used a credit card? What is the standard deviation?\n*d) Find the probability that exactly 5 customers did not use a credit card.\n*e) Find the probability that at least nine customers did not use a credit card\n\n\n\n5.5.3 Poisson r.v\nIn this section we consider a discrete random variable that is often useful in estimating the number of occurrences over a specified interval of time or space. For example, the random variable of interest might be\n\nthe number of arrivals at a car wash in one hour,\nthe number of repairs needed in 10 miles of highway, or\nthe number of leaks in 100 miles of pipeline.\n\nPROPERTIES OF A POISSON EXPERIMENT\n\nThe probability of an occurrence is the same for any two intervals of equal length.\nThe occurrence or nonoccurrence in any interval is independent of the occurrence or nonoccurrence in any other interval.\n\nSuppose \\(X\\) be the number occurrences in a given interval. Then,\nPMF:\n\\[\nP(X=x)=f(x)=\\frac{\\mu^x e^{-\\mu}}{x!}\\ \\ ; \\ \\ x=0,1,2,...,\\infty\n\\]\nWhere, \\(\\mu\\) is the expected value or mean number of occurrences in an interval.\nMean: \\(E(X)=\\mu\\)\nVariance: \\(Var(X)=\\mu\\)\nWe write, \\(X \\sim Pois(\\mu)\\)\nFinding probability of Poisson r.v\nLet, \\(X\\) be a Poisson r.v with \\(\\mu=2.5\\). Find the following probabilities.\na) \\(P(X=2)\\)\nb) \\(P(X&lt;=1)\\)\nc) \\(P(X&gt;3)\\)\nExample 911 Calls. Emergency 911 calls to a small municipality in Idaho come in at the rate of one every 2 minutes. (Anderson 2020, page no. 261)\na. What is the expected number of 911 calls in one hour?\nb. What is the probability of three 911 calls in five minutes?\nc. What is the probability of no 911 calls in a five-minute period?\n\nExample Airport Passenger-Screening Facility. Airline passengers arrive randomly and independently at the passenger-screening facility at a major international airport. The mean arrival rate is 10 passengers per minute. (Anderson 2020, page no. 261)\na. Compute the probability of no arrivals in a one-minute period.\nb. Compute the probability that three or fewer passengers arrive in a one-minute period.\nc. Compute the probability of no arrivals in a 15-second period.\nd. Compute the probability of at least one arrival in a 15-second period.\nPoisson Approximation to the Binomial Distribution\nWhen,\n\n\\(p \\rightarrow0\\) (Success rate is very low);\n\\(n\\rightarrow \\infty\\) (Number of trials is very large);\n\nThen Binomial distribution can be approximated by Poisson distribution.\n\nMathematically, \\(Bin (x; n,p)\\approx Pois(x;\\mu)\\); where \\(\\mu=np\\).\n\n\n\n\n\n\n\nNote\n\n\n\nIn practical situation if \\(n &gt; 20\\) and \\(np\\le 7\\) ; then the approximation is close enough to use the Poisson distribution for binomial problems(Black 2012).\n\n\nExample A college has 250 personal computers. The probability that any 1 of them will require repair in a given week is 0.01. Find the probability that fewer than 3 of the personal computers will require repair in a particular week. Use the Poisson approximation to the binomial distribution.\n\nExample It is estimated that 0.5 percent of the callers to the Customer Service department of Dell Inc. will receive a busy signal. What is the probability that of today’s 1,200 callers at least 3 received a busy signal?\nExample Ms. Bergen is a loan officer at Coast Bank and Trust. From her years of experience, she estimates that the probability is .025 that an applicant will not be able to repay his or her installment loan. Last month she made 40 loans. a. What is the probability that 3 loans will be defaulted?\nb. What is the probability that at least 3 loans will be defaulted?\n\n\n\n\n\n\nAnderson, David R. 2020. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nBlack, Ken. 2012. Business statistics: for contemporary decision making. 7th ed. Hoboken, NJ: Wiley.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Random variable and Discrete Probability Distribution</span>"
    ]
  },
  {
    "objectID": "continuous_r.v.html",
    "href": "continuous_r.v.html",
    "title": "6  Continuous r.v and Probability density function",
    "section": "",
    "text": "6.1 Definition\nA continuous r.v \\(X\\) must have a probability density function (PDF) \\(f(x)\\) such that\n\\(1) f(x) \\ge 0\\) [Non-negativity]\n\\(2) \\int_{x\\in \\mathbb{R}} f(x)dx =1\\) [Total AREA under the curve \\(f(x)\\) always 1]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous r.v and Probability density function</span>"
    ]
  },
  {
    "objectID": "continuous_r.v.html#illustration-with-an-example",
    "href": "continuous_r.v.html#illustration-with-an-example",
    "title": "6  Continuous r.v and Probability density function",
    "section": "6.2 Illustration with an example",
    "text": "6.2 Illustration with an example\nGiven \\(f(x)=\\frac{1}{2}x \\ \\ ; 0\\le x\\le 2\\)\na) Show/plot the graph of \\(f(x)\\).\nb) Is \\(f(x)\\) a PDF?\nc) Find \\(P(X&lt;1.0)\\).\nd) Find \\(P(X=1.0)\\)\nSolution:\n(a)\n\n\nCode\npar(mar = c(1.8, 2, 1, 1))\n\ncurve(0.5*x,ylab = \"f(x)\",lwd=2,col=\"red\",xlim=c(0,2),main=\"Graph of  f(x)=0.5x\", cex.axis=0.7,cex.lab=1.0,cex.main=0.8)\n\n\n\n\n\n\n\n\n\nb) Here, \\(f(x)\\ge 0\\) for all values of \\(x\\) in the interval \\(0\\le x\\le2\\).\nNow, total area under curve \\(f(x)\\) from \\(x=0\\) to \\(x=2\\) is\n\\(\\int_{0}^2 f(x)dx\\)\n\\(=AREA \\ \\ of\\ \\  the\\ \\  SHADED\\ \\  Triangle\\)\n\n\nCode\npar(mar = c(1.8, 2, 1, 1))\n# Create a plot\nplot(1, type = \"n\", xlab = \"x\", ylab = \"f(x)\",main=\"\", \n     xlim = c(0, 2), ylim = c(0, 1), \n     cex.axis=1.0,cex.lab=1.0,cex.main=1)\n\n# Define the vertices of the triangle\nx &lt;- c(0, 2, 2)\ny &lt;- c(0, 0, 1)\n\n# Draw the triangle\npolygon(x, y,  border = \"blue\")\npolygon(x,y,col=\"lightblue\")\ntext(1.5, 0.3, labels = \"P(0&lt;X&lt;2)=1\", pos = 3, col = \"black\")\n\n\n\n\n\n\n\n\n\n\\[\n=\\frac{1}{2} \\times base\\times height\n\\]\n\\[\n=\\frac{1}{2} \\times 2\\times 1=1\n\\]\nSo, total area under curve \\(f(x)\\) is \\(1\\) that is \\(\\int_{0}^{2} f(x)dx=1\\).\nHence, \\(f(x)\\) is a PDF.\nc) Here,\n\\[\nP(X&lt;1)=Area \\ \\ under\\ \\ the \\ \\ curve \\ \\ from \\ \\ x=0 \\ \\ to  \\ \\ x=1\n\\]\n\\[\n=Area \\ \\ of \\ \\ the \\ \\ SHADED \\ \\ Triangle\n\\]\n\n\nCode\npar(mar = c(1.8, 2, 1, 1))\n# Create a plot\nplot(1, type = \"n\", xlab = \"x\", ylab = \"f(x)\",main=\"\", \n     xlim = c(0, 2), ylim = c(0, 1), \n     cex.axis=0.8,cex.lab=0.8,cex.main=0.9)\n\n# Define the vertices of the triangle\nx &lt;- c(0, 2, 2)\ny &lt;- c(0, 0, 1)\n\n# Draw the triangle\npolygon(x, y,  border = \"blue\")\npolygon(c(0,1,1),c(0,0,.5),col=\"lightblue\")\n# Add labels to the vertices\ntext(0.73, 0.1, labels = \"P(X&lt;1)=0.25\", pos = 3, col = \"black\",cex=.8)\n\n\n\n\n\n\n\n\n\n\\[\n=\\frac{1}{2}\\times 1 \\times f(1)=\\frac{1}{2}\\times 1 \\times 0.5=0.25\n\\]\nTherefore \\(P(X&lt;1)=0.25\\)\nd) \\(P(X=1.0)=0\\) [Because there is no area at \\(x=1.0\\)]\n\n\n\n\n\n\nNote\n\n\n\nWe always remember that Probability in an interval of \\(X\\) is actually the \\(AREA\\) under the pdf \\(f(x)\\).\n\n\nProblem 6.2.1 A random variable has the following density function.\n\\[\nf(x)=1-0.5x \\ \\ ; \\ \\ 0&lt;x&lt;2\n\\]\na) Graph the density function.\nb) Verify that \\(f(x)\\) is a density function.\nc) Fond \\(P(X&gt;1)\\).\nd) Find \\(P(X&lt;0.5)\\).\ne) Find \\(P(X=1.5)\\).\nProblem 6.2.2 The following function is the density function for the random variable X :\n\\[\nf(x)=\\frac{x-1}{8} \\ \\ ; 1&lt;x&lt;5\n\\]\na) Graph the density function.\nb) Find the probability that X lies between 2 and 4.\nc) What is the probability that X is less than 3?",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous r.v and Probability density function</span>"
    ]
  },
  {
    "objectID": "continuous_r.v.html#expectation-and-variance-of-continuous-r.v",
    "href": "continuous_r.v.html#expectation-and-variance-of-continuous-r.v",
    "title": "6  Continuous r.v and Probability density function",
    "section": "6.3 Expectation and variance of continuous r.v",
    "text": "6.3 Expectation and variance of continuous r.v\nIf \\(X\\) is a continuous r.v with PDF \\(f(x)\\) then\nExpected value of \\(X\\) is\n\\[\n\\mu=E(X)= \\int_{x\\in \\mathbb{R}} x\\cdot f(x)dx\n\\] Variance of \\(X\\) is\n\\[\nVar(X)=E(X^2)-\\mu^2=\\int_{x\\in \\mathbb{R}} x^2\\cdot f(x)dx-\\mu^2\n\\]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous r.v and Probability density function</span>"
    ]
  },
  {
    "objectID": "continuous_r.v.html#uniform-probability-distributionr.v",
    "href": "continuous_r.v.html#uniform-probability-distributionr.v",
    "title": "6  Continuous r.v and Probability density function",
    "section": "6.4 Uniform probability distribution/r.v",
    "text": "6.4 Uniform probability distribution/r.v\nA continuous r.v \\(X\\) is said to be uniform r.v ranges between \\(a\\) to \\(b\\) if it has the following PDF\n\\[\nf(x)=\\frac{1}{b-a} \\ \\ ; \\ \\ a&lt;x&lt;b\n\\tag{6.1}\\]\n\n\n\n\n\n\nFigure 6.1: Graph of f(x)\n\n\n\nwith\nMean: \\(\\mu=E(X)=\\frac{a+b}{2}\\)\nVariance: \\(\\sigma^2=\\frac{(b-a)^2}{12}\\)\nWe write, \\(X\\sim U(a,b)\\)\n\n6.4.1 Finding probability for uniform r.v (Keller 2014)\nIf \\(X\\sim U(a,b)\\) then the \\(P(x_1&lt;X&lt;x_2)\\) is actually the area of the shaded rectangle.\n\n\n\n\n\n\nFigure 6.2: Computing area for an interval of Uniform distribution\n\n\n\nThat is,\n\\[\nP(x_1&lt;X&lt;x_2)=Base\\times Heght=(x_2-x_1)\\times \\frac{1}{b-a}\n\\]\nProblem 6.4.1 The random variable \\(X\\) is known to be uniformly distributed between 10 and 30.\na) Show the graph of the probability density function.\nb) Compute \\(P(X&lt;15)\\).\nc) Compute \\(P(X\\ge 22)\\).\nd) Compute \\(P(13 \\le X&lt;23)\\).\ne) Compute \\(P(X=29)\\).\nf) Compute \\(E(X)\\).\ng) Compute \\(Var(X)\\) and \\(SD(X)\\).\n\n\n\nProblem 6.4.2 (Keller 2014, 263) The amount of gasoline sold daily at a service station is uniformly distributed with a minimum of 2,000 gallons and a maximum of 5,000 gallons.\n\nFind the probability that daily sales will fall between 2,500 and 3,000 gallons.\nWhat is the probability that the service station will sell at least 4,000 gallons?\nWhat is the probability that the station will sell exactly 2,500 gallons?\nWhat is the mean and standard deviation of amount of daily gasoline sold? (*)\n\nProblem 6.4.3 (Keller 2014, 265) The weekly output of a steel mill is a uniformly distributed random variable that lies between 110 and 175 metric tons.\n\nCompute the probability that the steel mill will produce more than 150 metric tons next week.\nDetermine the probability that the steel mill will produce between 120 and 160 metric tons next week.\nThe operations manager labels any week that is in the bottom 20% of production a “bad week.” How many metric tons should be used to define a bad week? (*)\n\nProblem 6.4.4 (Keller 2014, 265) The amount of time it takes for a student to complete a statistics quiz is uniformly distributed between 30 and 60 minutes. One student is selected at random. Find the probability of the following events.\n\nThe student requires more than 55 minutes to complete the quiz.\nThe student completes the quiz in a time between 30 and 40 minutes.\nThe student completes the quiz in exactly 37.23 minutes.\n\nProblem 6.4.5 (Keller 2014, 265) Refer to previous problem.\n\nThe professor wants to reward (with bonus marks) students who are in the lowest quarter of completion times. What completion time should he use for the cutoff for awarding bonus marks? (*)\nThe professor would like to track (and possibly help) students who are in the top 10% of completion times. What completion time should he use? (*)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous r.v and Probability density function</span>"
    ]
  },
  {
    "objectID": "continuous_r.v.html#normal-distributionr.v",
    "href": "continuous_r.v.html#normal-distributionr.v",
    "title": "6  Continuous r.v and Probability density function",
    "section": "6.5 Normal distribution/r.v",
    "text": "6.5 Normal distribution/r.v\nThe normal distribution is arguably the most popular and commonly used distribution. It is compatible with a wide range of human attributes, including height, weight, length, speed, IQ, academic success, and years of life expectancy.\n\nA large number of business and industrial variables are also normally distributed. Several variables, such as the annual cost of household insurance, the cost per square foot of warehouse space rental, and managers’ happiness with ownership support on a five-point scale, could result in data that are normally distributed. Also, most things that are manufactured or filled by machines are normally distributed.\nDue to its numerous uses, the normal distribution is a very significant distribution. In addition to the several variables that are normally distributed that have been described, statistical inference, statistical process control rely heavily on the normal distribution. No matter the form of the underlying distribution from which they are derived, many statistics are normally distributed when sufficiently large sample sizes are obtained (Black 2012).\n\n6.5.1 Definition\nA continuous r.v \\(X\\) is said to be normal r.v if it has the following PDF:\n\\[\nf(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} (\\frac{x-\\mu}{\\sigma})^2}\\ \\ ; -\\infty&lt;x&lt;\\infty\n\\tag{6.2}\\]\nThe graph of \\(f(x)\\) is called normal curve (Figure 6.3).\n\n\nCode\nlibrary(tidyverse)\n\n# Create a sequence of x values\nx &lt;- seq(10, 30, length = 100)\n\n# Calculate the y values for the normal distribution\ny &lt;- dnorm(x,20,3)\n\n# Create a data frame\ndata &lt;- data.frame(x, y)\n\n\nggplot(data, aes(x = x, y = y)) +\n  geom_line(color = \"blue\",lwd=1) +\n  labs(title = \" \", \n  x=expression(mu), y = \"f(x)\")+\n  geom_vline(xintercept=20)+\n  theme_classic()+\n  theme(axis.text=element_blank(),\n        axis.title = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5)\n        )-&gt;normal.curve\nnormal.curve  \n\n\n\n\n\n\n\n\nFigure 6.3: Normal Curve\n\n\n\n\n\nMean: \\(E(X)=\\mu\\)\nVariance: \\(Var(X)=\\sigma^2\\)\nWe write: \\(X\\sim N(\\mu , \\sigma^2)\\)\nProperties of normal distribution\n\nThe total area under the normal curve \\(f(x)\\) is 1 that is\n\\[\n\\int_{-\\infty}^{\\infty} f(x)dx=1\n\\]\nNormal distribution is symmetric about mean, \\(\\mu\\)\nMean, median and mode is identical in normal distribution that is \\(Mean=Median=Mode=\\mu\\)\nAlmost \\(99\\%\\) observations of \\(X\\) lie within 3 standard deviation of mean that is\n\\[\nP(\\mu-3\\sigma&lt;X&lt;\\mu+3\\sigma)\\approx 0.99\n\\]\nAlmost \\(95\\%\\) observations of \\(X\\) lie within 2 standard deviation of mean that is \\[\nP(\\mu-2\\sigma&lt;X&lt;\\mu+2\\sigma)\\approx 0.95\n\\]\nAlmost \\(68\\%\\) observations of \\(X\\) lie within 1 standard deviation of mean that is \\[\nP(\\mu-\\sigma&lt;X&lt;\\mu+\\sigma)\\approx 0.68\n\\]\n\n\n\n6.5.2 Standard normal r.v\nSuppose \\(X\\sim N(\\mu, \\sigma^2)\\). Then the variable \\(Z=\\frac{X-\\mu}{\\sigma}\\) is said to be standard normal variable with PDF\n\\[\nf(z)=\\frac{1}{\\sqrt {2\\pi}} e^ \\frac{-z^2}{2} \\ \\ ; -\\infty&lt;z&lt;\\infty\n\\tag{6.3}\\]\nMean: \\(E(Z)=0\\)\nVariance: \\(Var(Z)=1\\)\nWe write: \\(Z\\sim N(0,1)\\)\n\n\nCode\npar(mar = c(3.77, 3.77, 1, 1))\n\nfz=function(x) {(1/sqrt(2*pi))*exp(-x^2)}\n\ncurve(fz,from = -3.2, to = 3.2,\n      xlab = \"z\",ylab = \"f(z)\",lwd=2)\n\nabline(v = 0, col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\nFigure 6.4: Standard normal curve\n\n\n\n\n\n\n\n6.5.3 Computing probability(area) under standard normal curve\nTo compute area (probability) under the standard normal curve for a given interval of \\(z\\) we use standard Normal Distribution table which provides cumulative probabilities.\nRULE-I: Suppose we want to find \\(P(Z&lt;1.25)\\).\nFrom TABLE 1 (Appendix B) in Anderson (2020) we have\n\\[\nP(Z&lt;1.25)=0.8944\n\\]\n\n\nThe probability \\(P(Z&lt;1.25)\\) is shown in Figure 6.5.\n\n\nCode\n# Load ggplot2 package\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 0\nsd &lt;- 1\n\n# Define the shading bounds for the central 95% interval\nlower &lt;- -1.96  # Lower bound (e.g., -1.96 for 95% CI)\nupper &lt;- 1.96   # Upper bound (e.g., 1.96 for 95% CI)\n\n# Create a data frame to specify the x range\nx_range &lt;- data.frame(x = c(-4, 4))\n\n# Create the plot\nggplot(x_range, aes(x)) +\n  scale_x_continuous(breaks = seq(-4,4,1)) +\n  # Plot the normal distribution curve\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd)) +\n  \n  # Shade the area under the curve between the lower and upper bounds\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), geom = \"area\", \n                xlim = c(-4, 1.25), fill = \"skyblue\", alpha = 0.5) +\n  \n  # Labels and theme\n  labs(x = \"z\", y = \"f(z)\", title = \"\") +\n  theme_classic()+\n  annotate(\"text\",x=0,y=0.15,label=\"P(Z&lt;1.25)=0.8944\")\n\n\n\n\n\n\n\n\nFigure 6.5: Area under standard normal curve for Z&lt;1.25\n\n\n\n\n\nRULE-II: Now we find \\(P(Z&gt;1.36)\\)\nSo, due to symmetry we can write \\(P(Z&gt;1.36)=P(Z&lt;-1.36)=0.0869\\)\n\n\n\nCode\n# Create the plot\nggplot(x_range, aes(x)) +\n  scale_x_continuous(breaks = seq(-4,4,1)) +\n  # Plot the normal distribution curve\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  \n  # Shade the area under the curve between the lower and upper bounds\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), geom = \"area\", xlim = c(1.36, 4), fill = \"skyblue\", alpha = 0.5) +\n  \n  # Labels and theme\n  labs(x = \"z\", y = \"f(z)\", title = \"\") +\n  theme_classic()+\n  annotate(\"text\",x=3,y=0.1,label=\"P(Z&gt;1.36)=0.0869\")\n\n\n\n\n\n\n\n\nFigure 6.6: Area under standard normal curve for Z&gt;1.36\n\n\n\n\n\nRULE-III: Let us evaluate \\(P(-1.96&lt;Z&lt;2.58)\\).\nWe can write\n\\[\n=P(-1.96&lt;Z&lt;2.58)\n\\]\n\\[\n=P(Z&lt;2.58)-P(Z&lt;-1.96)\n\\]\n\\[\n=0.9951-0.0250=0.9701\n\\]\n\n\nCode\n# Create the plot\nggplot(x_range, aes(x)) +\n  scale_x_continuous(breaks = seq(-4,4,1)) +\n  # Plot the normal distribution curve\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +\n  \n  # Shade the area under the curve between the lower and upper bounds\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), geom = \"area\", xlim = c(-1.96, 2.58), fill = \"skyblue\", alpha = 0.5) +\n  \n  # Labels and theme\n  labs(x = \"z\", y = \"f(z)\", title = \"\") +\n  theme_classic()+\n  annotate(\"text\",x=-.02,y=.1,label=\"P(-1.96&lt;Z&lt;2.58)=0.9701\")\n\n\n\n\n\n\n\n\nFigure 6.7: Area under standard normal curve for -1.96&lt;Z&lt;2.58\n\n\n\n\n\n\n\n6.5.4 Finding quantiles (percentiles, quartiles, deciles etc) of \\(Z\\)\nWhat is the \\(90^{th}\\) percentile of \\(Z\\)? To answer this question, let \\(k\\) is the \\(90^{th}\\) percentile of \\(Z\\). So we can write\n\\[\nP(Z&lt;k)=0.90 \\ \\  \\ \\ \\ \\ \\ \\ \\ \\cdot \\cdot \\cdot (1)\n\\]\nFrom TABLE 1 (Appendix-B) (Anderson 2020) we have\n\\[\nP(Z&lt;1.28)=0.90 \\ \\  \\ \\ \\ \\ \\ \\ \\ \\cdot \\cdot \\cdot(2)\n\\]\nComparing eq.(1) with eq.(2) we have \\(k=1.28\\). So the \\(90^{th}\\) percentile of \\(Z\\) is \\(1.28\\).\nProblem 1 Find \\(c\\) such that \\(P(Z&gt;c)=0.05\\).\nProblem 2 Find \\(c\\) such that \\(P(-c&lt;Z&lt;c)=0.95\\).\n\n\n6.5.5 Computing probability(area) under normal curve:\nSuppose \\(X\\sim N(30, 5^2)\\) . Then find the following:\na) \\(P(X&lt;22)\\)\nb) \\(P(X&gt;44)\\)\nc) \\(P(20&lt;X&lt;35)\\)\nd) If \\(P(X&lt;x)=0.25\\) then find the value of \\(x\\).\nSolution:\nHere, \\(\\mu=30\\) and \\(\\sigma=5\\)\n\na) \\(P(X&lt;22)=P(\\frac{X-\\mu}{\\sigma}&lt;\\frac{22-30}{5})=P(Z&lt;-1.60)=0.0548\\).\n\nb) \\(P(X&gt;44)=P(\\frac{X-\\mu}{\\sigma}&gt;\\frac{44-30}{5})\\)\n\\(=P(Z&gt;2.80)=P(Z&lt;-2.80)=0.0026\\)\n\nc) \\(P(20&lt;X&lt;35)=P(\\frac{20-30}{5}&lt;\\frac{X-\\mu}{\\sigma}&lt;\\frac{35-30}{5})\\)\n\\(=P(-2&lt;Z&lt;1)=P(Z&lt;1)-P(Z&lt;-2)\\)\n\\(=0.8413-0.0228=0.8185\\)\n\nd) To find the value of \\(x\\) we proceed this way.\n\\[\nP(X&lt;x)=0.25\n\\] \\[\n\\implies P(\\frac{X-\\mu}{\\sigma}&lt;\\frac{x-30}{5})=0.25\n\\]\n\\[\n\\implies P(Z&lt;\\frac{x-30}{5})=0.25 \\ \\ \\ \\ \\ \\cdot \\cdot \\cdot (1)\n\\]\nFrom TABLE (Appendix B) we have\n\\[\nP(Z&lt;-0.67)=0.25  \\ \\ \\ \\ \\cdot \\cdot \\cdot (2)\n\\]\nComparing (1) with (2) we can write\n\\[\n\\frac{x-30}{5}=-0.67\n\\] \\[\n\\implies x=30+(-0.67)\\times 5\n\\]\n\\[\n\\therefore x=26.65\n\\]\n\n\n\n\n\n\nNote\n\n\n\nIf \\(P(X&lt;x)=p\\) and\n\\(P(Z&lt;z)=p\\) then\n\\[\nx=\\mu+z\\sigma\n\\]\n\n\n\n\n6.5.6 Applications\nIn this section we will discuss about some problems which are connected to the normal distribution.\nProblem 6.5.1 (Anderson 2020, 298) Automobile repair costs continue to rise with an average 2015 cost of $367 per repair (U.S. News & World Report website). Assume that the cost for an automobile repair is normally distributed with a standard deviation of $88. Answer the following questions about the cost of automobile repairs.\na. What is the probability that the cost will be more than $450?\nb. What is the probability that the cost will be less than $250?\nc. What is the probability that the cost will be between $250 and $450?\nd. If the cost for your car repair is in the lower 5% of automobile repair charges, what is your cost?\n\nProblem 6.5.2 (Anderson 2020, 298) Labor Day Travel Costs. The American Automobile Association (AAA) reported that families planning to travel over the Labor Day weekend spend an average of $749. Assume that the amount spent is normally distributed with a standard deviation of $225.\na. What is the probability of family expenses for the weekend being less that $400?\nb. What is the probability of family expenses for the weekend being $800 or more?\nc. What is the probability that family expenses for the weekend will be between $500 and $1000?\nd. What would the Labor Day weekend expenses have to be for the 5% of the families with the most expensive travel plans?\n\nProblem 6.5.3 (Keller 2014 , 280) A new gas–electric hybrid car has recently hit the market. The distance traveled on 1 gallon of fuel is normally distributed with a mean of 65 miles and a standard deviation of 4 miles. Find the probabilityof the following events.\na. The car travels more than 70 miles per gallon.\nb. The car travels less than 60 miles per gallon.\nc. The car travels between 55 and 70 miles per gallon.\nProblem 6.5.4 (Anderson 2020, 298) Mensa Membership. A person must score in the upper 2% of the population on an IQ test to qualify for membership in Mensa, the international high-IQ society. If IQ scores are normally distributed with a mean of 100 and a standard deviation of 15, what score must a person have to qualify for Mensa?\nProblem 6.5.5 (Keller 2014 , 282) The lifetimes of televisions produced by the Hishobi Company are normally distributed with a mean of 75 months and a standard deviation of 8 months. If the manufacturer wants to have to replace only 1% of its televisions, what should its warranty be?\n\nProblem 6.5.6 (Newbold, Carlson, and Thorne 2013, 218) I am considering two alternative investments. In both cases I am unsure about the percentage return but believe that my uncertainty can be represented by normal distributions with the means and standard deviations shown in the accompanying table. I want to make the investment that is more likely to produce a return of at least 10%. Which investment should I choose?\n\n\n\n\nMean\nStandard deviation\n\n\nInvestment A\n10.4\n1.2\n\n\nInvestment B\n11.0\n4.0\n\n\n\n\n\n\n\n\n\nAnderson, David R. 2020. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nBlack, Ken. 2012. Business statistics: for contemporary decision making. 7th ed. Hoboken, NJ: Wiley.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013. Statistics for business and economics. 8. ed., global ed. Always learning. Boston, Mass. Munich: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Continuous r.v and Probability density function</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html",
    "href": "Further_topics_on_rv.html",
    "title": "7  Further topics on random variables",
    "section": "",
    "text": "7.1 Joint distribution of two discrete r.vs\nThe function \\(f(x, y)\\) is a joint probability distribution or probability mass function of the discrete random variables \\(X\\) and \\(Y\\) if",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#joint-distribution-of-two-discrete-r.vs",
    "href": "Further_topics_on_rv.html#joint-distribution-of-two-discrete-r.vs",
    "title": "7  Further topics on random variables",
    "section": "",
    "text": "\\(f(x,y)\\ge 0\\) for all \\((x,y)\\),\n\\(\\sum_x \\sum_y f(x,y)=1\\),\n\\(P(X=x, Y=y)=f(x,y)\\)\n\n\n7.1.1 Marginal distribution \\(X\\) and \\(Y\\) (discrete)\nThe marginal distributions of \\(X\\) alone and of \\(Y\\) alone are\n\n\\(f_X(x)=\\sum_y f(x,y)\\)\n\\(f_Y(y)=\\sum_x f(x,y)\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#joint-distribution-of-two-continuous-r.vs",
    "href": "Further_topics_on_rv.html#joint-distribution-of-two-continuous-r.vs",
    "title": "7  Further topics on random variables",
    "section": "7.2 Joint distribution of two continuous r.vs",
    "text": "7.2 Joint distribution of two continuous r.vs\nThe function \\(f(x, y)\\) is a joint density function of the continuous random variables \\(X\\) and \\(Y\\) if\n\n\\(f(x,y)\\ge 0\\),\n\\(\\int_{-\\infty}^\\infty \\int_{-\\infty}^\\infty f(x,y)\\ \\ dx\\ \\ dy=1\\).\n\n\n7.2.1 Marginal distribution \\(X\\) and \\(Y\\) (continuous )\nThe marginal distributions of \\(X\\) alone and of \\(Y\\) alone are\n\n\\(f_X(x)= \\int_{-\\infty}^\\infty f(x,y) \\ \\ dy\\),\n\\(f_Y(y)= \\int_{-\\infty}^\\infty f(x,y) \\ \\ dx\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#covariance-and-correlation-between-x-and-y",
    "href": "Further_topics_on_rv.html#covariance-and-correlation-between-x-and-y",
    "title": "7  Further topics on random variables",
    "section": "7.3 Covariance and correlation between \\(X\\) and \\(Y\\)",
    "text": "7.3 Covariance and correlation between \\(X\\) and \\(Y\\)\n\n\n\n\n\n\nCovariance\n\n\n\n\\[\nCov(X,Y)=\\sigma_{XY}=E \\left[ (X-\\mu_X)(Y-\\mu_Y)\\right]\n\\]\nIn other way,\n\\[\nCov(X,Y)=\\sigma_{XY}=E(XY)-\\mu_X\\mu_Y\n\\]\n\n\n\n\n\n\n\n\nCorrelation coefficient\n\n\n\n\\[\n\\rho=\\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y}\\ \\ ; -1\\le\\rho\\le+1\n\\]",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#laws-of-expected-value-and-variance-of-the-linear-combination-of-two-variables",
    "href": "Further_topics_on_rv.html#laws-of-expected-value-and-variance-of-the-linear-combination-of-two-variables",
    "title": "7  Further topics on random variables",
    "section": "7.4 Laws of Expected Value and Variance of the Linear combination of Two Variables",
    "text": "7.4 Laws of Expected Value and Variance of the Linear combination of Two Variables\nSuppose a new random variable is \\(Z\\) as follows:\n\\[\nZ=aX+bY\n\\]\nWhere \\(a\\) and \\(b\\) are both constants.\n\n\\(E(Z)=E(aX+bY)=aE(X)+bE(Y)\\),\n\\(Var(Z)=Var(aX+bY)=a^2 Var(X)+b^2 Var(Y)+2ab \\ \\ Cov (X,Y)\\)\n\nN.B: If \\(X\\) and \\(Y\\) are independent, \\(Cov(X,Y ) = 0\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#some-problem-on-discrete-joint-distribution",
    "href": "Further_topics_on_rv.html#some-problem-on-discrete-joint-distribution",
    "title": "7  Further topics on random variables",
    "section": "7.5 Some problem on discrete joint distribution",
    "text": "7.5 Some problem on discrete joint distribution\nProblem 7.5.1 The joint probability distribution of X and Y is shown in the following table.\n\na. Determine the marginal distributions of \\(X\\) and \\(Y\\) .\nb. Compute the covariance and coefficient of correlation between \\(X\\) and \\(Y\\) .\nc. Develop the probability distribution of \\(X + Y\\) .\nd. Find \\(P(X+Y\\le3)\\).\n\nProblem 7.5.2 After analyzing several months of sales data, the owner of an appliance store produced the following joint probability distribution of the number of refrigerators and stoves sold daily.\n\na. Find the marginal probability distribution of the number of refrigerators sold daily.\nb. Find the marginal probability distribution of the number of stoves sold daily.\nc. Compute the mean and variance of the number of refrigerators sold daily.\nd. Compute the mean and variance of the number of stoves sold daily.\ne. Compute the covariance and the coefficient of correlation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#some-problem-on-continuous-joint-distribution",
    "href": "Further_topics_on_rv.html#some-problem-on-continuous-joint-distribution",
    "title": "7  Further topics on random variables",
    "section": "7.6 Some problem on continuous joint distribution",
    "text": "7.6 Some problem on continuous joint distribution\nLet \\(X\\) denote the reaction time, in seconds, to a certain stimulus and \\(Y\\) denote the temperature (◦F) at which a certain reaction starts to take place. Suppose that two random variables \\(X\\) and Y have the joint density.\n\\[\nf(x, y) = \\begin{cases}\n4xy, & 0 &lt; x &lt; 1, \\, 0 &lt; y &lt; 1, \\\\\n0, & \\text{elsewhere}.\n\\end{cases}\n\\]\nFind\na. \\(P(0\\le X \\le \\frac{1}{2} \\ \\ {and}\\ \\ \\frac{1}{4} \\le Y\\le \\frac{1}{2})\\);\nb. \\(P(X&lt;Y)\\).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#sum-and-average-of-independent-random-variables",
    "href": "Further_topics_on_rv.html#sum-and-average-of-independent-random-variables",
    "title": "7  Further topics on random variables",
    "section": "7.7 Sum and Average of Independent Random Variables",
    "text": "7.7 Sum and Average of Independent Random Variables\nSum of Independent Random Variables:\n\\(Y = a_1X_1+a_2X_2+...+a_nX_n\\), for \\(a_1, a_2,..., a_n \\in \\mathbb{R}\\)\n\n\\(E(Y) = a_1E(X_1)+a_2E(X_2)+...+a_nE(X_n)\\)\n\\(Var(Y) = a_1^2Var(X_1) + a_2^2Var(X_2) + ... + a_n^2Var(X_n)\\)\n\nIf \\(n\\) random variables \\(X_i\\) have common mean \\(\\mu\\) and common variance \\(\\sigma^2\\) then,\n\n\\(E(Y) = (a_1 + a_2 + ... + a_n)\\mu\\)\n\\(Var(Y) = (a_1^2 + a_2^2 + ... + a_n^2)\\sigma^2\\)\n\nAverage of Independent Random Variables:\n\\(X_1,X_2,...,X_n\\) are \\(n\\) independent random variables\n\n\\(\\overline{X} = \\frac{X_1+X_2+...+X_n}{n}\\)\n\\(E[\\overline{X}] = \\frac{1}{n}[E(X_1)+E(X_2)+...+E(X_n)]\\)\n\\(Var[\\overline{X}] = \\frac{1}{n^2}[Var(X_1)+Var(X_2)+...+Var(X_n)]\\)\n\nIf \\(n\\) random variables \\(X_i\\) have common mean \\(\\mu\\) and common variance \\(\\sigma^2\\) then,\n\n\\(E[\\overline{X}] = \\mu\\)\n\\(Var[\\overline{X}] = \\frac{\\sigma^2}{n}\\)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "Further_topics_on_rv.html#some-approximations",
    "href": "Further_topics_on_rv.html#some-approximations",
    "title": "7  Further topics on random variables",
    "section": "7.8 Some approximations",
    "text": "7.8 Some approximations\n\n7.8.1 Normal Approximation to the Binomial Distribution\nLet \\(X \\sim Bin(n,p)\\). When \\(n\\) is large so that both \\(np \\geq 5\\) and \\(n(1-p) \\geq 5\\). We can use the normal distribution to get an approximate answer. Remember to use continuity correction.\n\\(X \\sim N(\\mu=np, \\sigma^2=np(1-p))\\), approx.\nProblem 7.8.1 A car-rental company has determined that the probability a car will need service work in any given month is 0.2. The company has 900 cars (Newbold, Carlson, and Thorne 2013).\n(a) What is the probability that more than 200 cars will require service work in a particular month?\n(b) What is the probability that fewer than 175 cars will need service work in a given month?\n\nProblem 7.8.2 The tread life of Stone Soup tires can be modeled by a normal distribution with a mean of 35,000 miles and a standard deviation of 4,000 miles. A sample of 100 of these tires is taken. What is the probability that more than 25 of them have tread lives of more than 38,000 miles? (Newbold, Carlson, and Thorne 2013)\n\n\n\n7.8.2 Normal Approximation to the Poisson Distribution\nLet \\(X \\sim Poisson(\\mu)\\). When \\(\\mu\\) is large (\\(\\mu &gt; 5\\)) then the Normal distribution can be used to approximate the Poisson distribution.\n\\(X\\sim N(\\mu,\\mu)\\) approx.\nProblem 7.8.3 Hits to a high-volume Web site are assumed to follow a Poisson distribution with a mean of 10,000 per day. Approximate each of the following: (Montgomery and Runger 2014)\n(a) Probability of more than 20,000 hits in a day,\n(b) Probability of less than 9900 hits in a day .\n\n\n\n7.8.3 \n\n\n\n\nMontgomery, Douglas C., and George C. Runger. 2014. Applied Statistics and Probability for Engineers. Sixth edition. Hoboken, NJ: John Wiley; Sons, Inc.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013. Statistics for business and economics. 8. ed., global ed. Always learning. Boston, Mass. Munich: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Further topics on random variables</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html",
    "href": "sampling_and_sampling_distributions.html",
    "title": "8  Sampling and Sampling distributions",
    "section": "",
    "text": "8.1 Some preliminary idea (Anderson 2020)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#some-preliminary-idea-anderson2020",
    "href": "sampling_and_sampling_distributions.html#some-preliminary-idea-anderson2020",
    "title": "8  Sampling and Sampling distributions",
    "section": "",
    "text": "An element is the entry on which data are collected.\nA population is the collection of all the elements of interest.\nA sample is a subset of the population.\nA sampling frame is the list of all the elements in the population of interest.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-from-a-finite-population",
    "href": "sampling_and_sampling_distributions.html#sampling-from-a-finite-population",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.2 Sampling from a Finite Population",
    "text": "8.2 Sampling from a Finite Population\n\n8.2.1 Simple random sample (Finite population)\nA simple random sample (SRS) of size \\(n\\) from a finite population of size \\(N\\) is a sample selected such that each possible sample of size \\(n\\) has the same probability of being selected.\n\nSampling can be with replacement.\nSampling can be without replacement (recommended).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-from-an-infinite-population",
    "href": "sampling_and_sampling_distributions.html#sampling-from-an-infinite-population",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.3 Sampling from an Infinite Population",
    "text": "8.3 Sampling from an Infinite Population\nIn the case of infinite population, it is not possible to develop a sampling from. In that case statisticians recommend selecting a random sample\n\n8.3.1 Random sample (Infinite population)\nA random sample of size \\(n\\) from an infinite population is a sample selected such that the following conditions are satisfied.\n1. Each element selected comes from the same population.\n2. Each element is selected independently.\n\n\n\n\n\n\nNotes and Comments\n\n\n\n1) A sample selected randomly from a population (finite or infinite) is referred as a random sample. The procedure of selecting a sample randomly is known as probability sampling.\n2) The number of different simple random samples of size \\(n\\) that can be selected from a finite population of size \\(N\\) is\n\\[\n{N \\choose{n}}=\\frac{N!}{n!(N-n)!}\n\\]\n3) Some other probability sampling methods are stratified random sampling, cluster sampling, and systematic sampling. We will discuss these methods later.\n4) We use the term “simple” in simple random sampling to clarify that this is the probability sampling method that assures each sample of size n has the same probability of being selected.\n\n\n\n\n8.3.2 Selecting simple random sample using R\nSuppose we have a variable \\(X\\) and let it contains \\(N=5\\) elements as follows:\n\\(X=\\{1,3,5,7,9\\}\\)\nUsing R we can draw several simple random samples of size \\(n=3\\) in \\({N\\choose n}={5\\choose 3}=10\\) ways. Now we draw a random sample using sample() function in base R.\n\n\nCode\nset.seed(2103) # To keep reproducibility\nX=c(1,3,5,7,9) # The elemnets in X variable\n\n# Drawing a random sample without replacement\nsample(X,3, replace = FALSE)\n\n\n[1] 3 7 5\n\n\nCode\n# Drawing a random sample with replacement\nsample(X,3, replace = TRUE)\n\n\n[1] 1 9 9\n\n\nThe all possible that is 10 samples (without replacement) are :\n\n\n         [,1] [,2] [,3]\nSample1     1    3    5\nSample2     1    3    7\nSample3     1    3    9\nSample4     1    5    7\nSample5     1    5    9\nSample6     1    7    9\nSample7     3    5    7\nSample8     3    5    9\nSample9     3    7    9\nSample10    5    7    9",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-distribution",
    "href": "sampling_and_sampling_distributions.html#sampling-distribution",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.4 Sampling distribution",
    "text": "8.4 Sampling distribution\nThe probability distribution of a sample statistic is called a sampling distribution.\nFor example, due to sampling variability the sample mean \\(\\bar x\\) has a sampling distribution.\nIllustration Consider a population of variable X: 1,3,5,7,9.\nTask-1: Compute population mean \\(\\mu\\) .\nSolution:\nHere, \\(\\mu=\\frac{\\sum x}{N}=\\frac{1+3+...+9}{5}=5\\)\nTask-2: Draw all possible samples of size \\(n=2\\) from this population. Then compute the means of all samples.\nSolution:\n\n\n\nTable 8.1: All Samples of Size 2 and Their Means\n\n\n\n\n\nSample\nSample mean, \\(\\bar x\\)\n\n\n1,3\n2\n\n\n1,5\n3\n\n\n1,7\n4\n\n\n1,9\n5\n\n\n3,5\n4\n\n\n3,7\n5\n\n\n3,9\n6\n\n\n5,7\n6\n\n\n5,9\n7\n\n\n7,9\n8\n\n\n\n\n\n\nTask-3: Construct a probability distribution of sample mean, \\(\\bar x\\) (discrete) and plot it.\nSolution:\n\n\n\nTable 8.2: Sampling distribution of \\(\\bar x\\)\n\n\n\n\n\n\\(\\bar x\\)\n\\(f(\\bar x)\\)\n\n\n\n\n2\n\\(\\frac{1}{10}\\)\n\n\n3\n\\(\\frac{1}{10}\\)\n\n\n4\n\\(\\frac{2}{10}\\)\n\n\n5\n\\(\\frac{2}{10}\\)\n\n\n6\n\\(\\frac{2}{10}\\)\n\n\n7\n\\(\\frac{1}{10}\\)\n\n\n8\n\\(\\frac{1}{10}\\)\n\n\n\n\n\n\n\n\nCode\nY&lt;-seq(1,9,2)\nall_sampl&lt;-combn(Y,2)\n#class(all_sampl)\n#colnames(all_sampl)&lt;-c(\"Sample1\",\"Sample2\",\"Sample3\",\"Sample4\",\"Sample5\",\"Sample6\",\"Sample7\",\"Sample8\",\"Sample9\",\"Sample10\",\"Sample11\",\"Sample12\",\"Sample13\",\"Sample14\",\"Sample15\")\n#t(all_sampl)\n#rowMeans(t(all_sampl))\n\n#barplot(table(rowMeans(t(all_sampl))))\n\nsam_dist&lt;-data.frame(x_bar=2:8,f=c(1,1,2,2,2,1,1))\nlibrary(tidyverse)\nsam_dist %&gt;% mutate(px_bar=f/sum(f)) %&gt;% ggplot(aes(x=x_bar,y=px_bar))+\n  geom_col(fill=\"gray20\",width = 0.9)+\n  labs(x=expression(bar(x)),y=expression(f(bar(x))))+\n  theme_bw()+\n  theme(axis.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\nFigure 8.1: Sampling distribution of \\(\\bar{x}\\)\n\n\n\n\n\nTask-4: Find the \\(E(\\bar x)\\) . Does \\(E(\\bar x)\\) same as population mean \\(\\mu\\)?\nSolution:\n\\(E(\\bar x)=\\sum \\bar x \\cdot f(\\bar x)\\)\n\\(=2(1/10)+3(1/10)+4(2/10)+\\cdot \\cdot \\cdot+8(1/10)=5\\)\nWe can see that \\(E(\\bar x) =5\\) is same as \\(\\mu=5\\).\nNOTE: This phenomenon is known as the unbiasedness of a sample statistic or an estimator. We will discuss it briefly in next chapter.\nHome work: Consider a population of variable X: 3,6,9,12,15.\ni) Compute population mean \\(\\mu\\) .\nii) Draw all possible samples of size \\(n=3\\) from this population without replacement. Then compute the means of all samples.\niii) Construct a probability distribution of sample mean, \\(\\bar x\\) (discrete) and plot it.\niv) Find the \\(E(\\bar x)\\) . Does \\(E(\\bar x)\\) same as population mean \\(\\mu\\)?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-distribution-of-bar-x",
    "href": "sampling_and_sampling_distributions.html#sampling-distribution-of-bar-x",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.5 Sampling distribution of \\(\\bar x\\)",
    "text": "8.5 Sampling distribution of \\(\\bar x\\)\nThe sampling distribution of \\(\\bar x\\) is the probability distribution of all possible values of the sample mean \\(\\bar x\\).\nIf samples are drawn from a infinite population (or finite but \\(n/N\\le 0.05\\) (Anderson 2020) then the\n\nExpected value of \\(\\bar x\\):\n\n\\[\nE(\\bar x)=\\mu_{\\bar x}=\\mu\n\\]\n\nStandard deviation of \\(\\bar x\\):\n\n\\[\n\\sigma_{\\bar x}=\\frac{\\sigma}{\\sqrt n}\n\\]\nStandard deviation of \\(\\bar x\\) is also known as Standard error of \\(\\bar x\\) or \\(s.e(\\bar x)\\).\nBut what is the form of the sampling distribution of \\(\\bar x\\)?\n\n8.5.1 Central limit theorem (CLT)\nThe sampling distribution of the mean of a random sample drawn from any population is approximately normal for a sufficiently large sample size. The larger the sample size, the more closely the sampling distribution of \\(\\bar x\\) will resemble a normal distribution.\n\n\n\n\n\n\nThe Central Limit Theorem\n\n\n\nLet, \\(X_1\\),\\(X_2\\), …. be a sequence of independently and identically distributed random variables with common mean \\(\\mu\\) and common variance \\(\\sigma^2\\). We define\n\\[\nZ=\\frac{\\bar x -\\mu_{\\bar x}}{\\sigma_{\\bar x}}\n\\]\nThen the \\(Z\\) will be approximately normally distributed as the sample size \\(n \\rightarrow\\infty\\).\n\n\nThe definition of “sufficiently large” depends on the extent of non-normality of \\(X\\) . Some authors consider a sample will be sufficiently large if \\(n\\ge30\\) (Walpole et al. 2017).\n\n\n8.5.2 Central Limit Theorem through simulation\nIn this section we illustrates how sampling distributions of sample means approximate to normal or bell shaped distribution as we increase the sample size .\nAt first, we consider a population data regarding gdp per capita (USD),2023 of 218 countries. We can see that the distribution of gdp per capita is highly skewed to the right (see Figure 8.2).\n\n\nCode\nlibrary(readxl)\n\nGDP_percap23 &lt;- read_excel(\"StatForBandE_data.xlsx\", \n    sheet = \"GDP_percap23\")\n#View(GDP_percap23)\nlibrary(tidyverse)\nlibrary(scales)\n\n\n#GDP_percap23 %&gt;% select(`Country Name`,Y_2023) %&gt;%arrange(-Y_2023)\n\nGDP_percap23 %&gt;% select(`Country Name`,Y_2023) %&gt;%\n  filter(`Country Name`!=\"Monaco\") %&gt;% \n  drop_na()-&gt;gdp_2023\n\n#gdp_2023 %&gt;% summarise(mu=mean(Y_2023), sigma=sd(Y_2023)) %&gt;% \n#  knitr::kable(digits = 2)\n\ngdp_2023%&gt;%\n  ggplot(aes(x=Y_2023))+\n  geom_histogram(col=\"black\",fill=\"lightblue\",bins = 10)+\n  scale_x_continuous(labels = comma)+\n  labs(x=\"GDP per capita (USD)\",y=\"Number of countries\",\n       caption=\"Source: World Bank, 2023\")+\n  theme_bw()+\n  theme(plot.caption =element_text(face = \"italic\",size = 12))+\n  annotate(\"text\", x=100000,y=75, \n           label = expression(~mu == 19575.12),\n           color = \"black\", size = 4)+\n  annotate(\"text\", x=100000,y=70, \n           label = expression( ~ sigma == 25324.77),\n           color = \"black\", size = 4)+\n  annotate(\"rect\",xmin = 83000, xmax = 119500, ymin = 65, ymax = 80, \n           alpha = 0.2, fill = \"lightblue\")\n\n\n\n\n\n\n\n\nFigure 8.2: Frequency histogram of GDP percapita of N=218 countries\n\n\n\n\n\nNow we draw 1000 random samples (without replacement) of different sample sizes and then plot the histogram of samples means.\n\nCode\nxgdp&lt;-gdp_2023$Y_2023\nnsim=1000 # no of simulations/ samples\n\nset.seed(231)\n\nreplicate(nsim,sample(xgdp,10)) %&gt;%colMeans() %&gt;%as.data.frame() %&gt;% ggplot(aes(x=.))+\n  geom_histogram(bins = 10,fill=\"steelblue1\",col=\"black\")+\n  theme_bw()-&gt;pclt_1\n\n  \n\nreplicate(nsim,sample(xgdp,30)) %&gt;%colMeans() %&gt;%as.data.frame() %&gt;% ggplot(aes(x=.))+\n  geom_histogram(bins = 10,fill=\"steelblue2\",col=\"black\")+\n  theme_bw()-&gt;pclt_2\n  \n\nreplicate(nsim,sample(xgdp,100)) %&gt;%colMeans() %&gt;%as.data.frame() %&gt;% ggplot(aes(x=.))+\n  geom_histogram(bins = 10,fill=\"steelblue3\",col=\"black\")+\n  theme_bw()-&gt;pclt_3\n\npclt_1\npclt_2\npclt_3\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Sampling distribution of sample mean for sample size n=10\n\n\n\n\n\n\n\n\n\n\n\n(b) Sampling distribution of sample mean for sample size n=30\n\n\n\n\n\n\n\n\n\n\n\n(c) Sampling distribution of sample mean for sample size n=100\n\n\n\n\n\n\n\nFigure 8.3: Demonstration of Central Limit Theorem through simulation\n\n\n\nFrom Figure 8.3 we can see that as the sample size increases, the sampling distribution of sample mean tends to bell-shaped or normal though the population data was very skewed to the right. This simulation clearly demonstrate the fact of Central Limit Theorem (CLT).\nFor more interactive simulation of CLT please visit the shinyApp.\nProblem 8.1 The foreman of a bottling plant has observed that the amount of soda in each 32-ounce bottle is actually a normally distributed random variable, with a mean of 32.2 ounces and a standard deviation of .3 ounce (Keller 2014, 308).\na. If a customer buys one bottle, what is the probability that the bottle will contain more than 32 ounces?\nb. If a customer buys a carton of four bottles, what is the probability that the mean amount of the four bottles will be greater than 32 ounces?\n\nProblem 8.2 Suppose a subdivision on the southwest side of Denver, Colorado, contains 2215 houses. The subdivision was built in 1983. A sample of 100 houses is selected randomly and evaluated by an appraiser. If the mean appraised value of a house in this subdivision for all houses is $177,000, with a standard deviation of $8,500, what is the probability that the sample average is greater than $185,000? (Black 2012, 243 (population size is changed))\n\nProblem 8.3 A scientist is studying the heights of men in Australia. The true population mean \\(\\mu\\) is unknown but the true population standard deviation is assumed to be 2.5 inches. Suppose the scientist randomly samples 100 men. Find the probability that the difference between the sample mean and the true population mean is less than 0.5 inches.\nProblem 8.4 In winter, it tends to rain a lot in Canberra. Suppose that the amount of rain that falls on any given winter day in Canberra is normally distributed with a mean of \\(2.3 mm\\) and a variance of \\(1.1 \\ \\ mm^2\\).\n\n(a) Find the probability that between 1.9 and 3.4 mm of rain fell today.\n(b) Find the probability that the total amount of rain that falls over the next 20 days is between 54.3 and 57.1 mm.\nProblem 8.5 Suppose, we load on a plane 100 packages whose weights are independent random variables that are uniformly distributed between 5 and 50 pounds. What is the probability that the total weight will exceed 3000 pounds?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-distribution-of-sample-proportion-hat-p",
    "href": "sampling_and_sampling_distributions.html#sampling-distribution-of-sample-proportion-hat-p",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.6 Sampling distribution of sample proportion, \\(\\hat p\\)",
    "text": "8.6 Sampling distribution of sample proportion, \\(\\hat p\\)\nThe sample proportion \\(\\hat p\\) is the point estimator of the population proportion \\(p\\). The formula for computing the sample proportion is\n\\[\n\\hat p=\\frac {x}{n}\n\\] Where,\n\\(x=\\) number of successes in the sample of size \\(n\\).\nCase-I (small sample): If \\(X\\sim Bin(n,p)\\) then \\(\\hat p\\) also follows binomial distribution with\n\\[\nMean: E(\\hat p)=p\n\\]\n\\[\nVariance: \\sigma^2_{\\hat p}=\\frac{p(1-p)}{n}\n\\]\n\nCase-II (large sample): When the sample size is large enough so that \\(np\\) and \\(n(1-p)\\) are greater than or equal to \\(5\\) then \\(\\hat p\\) will be approximately normally distributed with\n\\[ Mean: E(\\hat p)=p \\]\n\\[ Variance: \\sigma^2_{\\hat p}=\\frac{p(1-p)}{n} \\]\nProblem 8.6 According to the Internal Revenue Service, 75% of all tax returns lead to a refund. A random sample of 100 tax returns is taken.\n\nWhat is the mean of the distribution of the sample proportion of returns leading to refunds?\nWhat is the variance of the sample proportion?\nWhat is the standard error of the sample proportion?\nWhat is the probability that the sample proportion exceeds 0.8?\n\nProblem 8.7 A random sample of 270 homes was taken from a large population of older homes to estimate the proportion of homes with unsafe wiring. If, in fact, 20% of the homes have unsafe wiring, what is the probability that the sample proportion will be between 16% and 24%?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#sampling-distribution-of-the-sample-variances",
    "href": "sampling_and_sampling_distributions.html#sampling-distribution-of-the-sample-variances",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.7 Sampling Distribution of the Sample Variances",
    "text": "8.7 Sampling Distribution of the Sample Variances\nLike as sample mean, sample variance is also considered as a random variable due to sampling variability. If we a random sample \\(\\{x_1,x_2, . . . , x_n\\}\\) is a random sample of size \\(n\\) then the quantity\n\\[\ns^2=\\frac{1}{n-1} \\sum_{i=1}^n (x_i-\\bar x)^2\n\\]\nis called the sample variance.\n\n\n\n\n\n\nSampling Distribution of the Sample Variances\n\n\n\nIf \\(s^2\\) is the variance of a random sample of size \\(n\\) taken from a normal population having the variance \\(\\sigma^2\\), then the statistic\n\\[\n\\chi^2=\\frac{(n-1)s^2}{\\sigma^2}=\\frac{\\sum_{i=1}^n (x_i-\\bar x)^2}{\\sigma^2}\n\\]\nhas a Chi-squared distribution with \\(\\nu =n-1\\) degrees of freedom.\n\n\nMean of \\(s^2\\): \\(E(s^2)=\\sigma^2\\)\nVariance of \\(s^2\\): \\(Var(s^2)=\\frac{2\\sigma^4}{(n-1)}\\)\nHow to to determine the area under the curve of \\(\\chi^2\\) distribution?\nIn every statistics textbook area under the \\(\\chi^2\\) distribution can be determined for a given degrees of freedom. The distribution is defined for only positive values, since variances are all positive values. For a given probability or area say \\(\\alpha\\) and degrees of freedom \\(\\nu\\) we can determine the value of \\(\\chi^2\\) to the upper tail such that:\n\\[\nP(\\chi^2&gt;\\chi^2_{\\alpha})=\\alpha\n\\]\n\n\n\n\n\n\nFigure 8.4: The chi-squared distribution\n\n\n\nFor example, when \\(\\alpha=0.05\\) and \\(\\nu=10\\) the value of \\(\\chi^2_{\\alpha}\\) is \\(18.307\\).\n\n\n\n\n\n\nFigure 8.5: Chi-square distribution. Source: Appendix B, TABLE 3 (Anderson 2020)\n\n\n\nProblem 8.8 A random sample of size \\(n = 18\\) is obtained from a normally distributed population with a population mean of \\(\\mu = 46\\) and a variance of \\(\\sigma^2 = 50\\).\n\nWhat is the probability that the sample mean is greater than 50?\nWhat is the value of the sample variance such that 5% of the sample variances would be less than this value?\nWhat is the value of the sample variance such that 5% of the sample variances would be greater than this value?\n\nProblem 8.9 A process produces batches of a chemical whose impurity concentrations follow a normal distribution with a variance of 1.75. A random sample of 20 of these batches is chosen. Find the probability that the sample variance exceeds 3.10.\nSolution:\nLet, \\(X\\) be the impurity concentration\nGiven, \\(\\sigma^2=1.75\\); \\(n=20\\) . We have to compute\n\\[\nP[s^2&gt;3.10]=P\\left[  \\frac{(n-1)s^2}{\\sigma^2}&gt;\\frac{(20-1)(3.10)}{1.75} \\right ]\n\\]\n\\[\n=P\\left[ \\chi^2&gt;33.657 \\right]\\approx 0.01\n\\]\nSo there is approximately 1% chance that the sample variance exceeds 3.10.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#t-distribution",
    "href": "sampling_and_sampling_distributions.html#t-distribution",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.8 t-Distribution",
    "text": "8.8 t-Distribution\nLet \\(Z\\sim N(0,1)\\) and \\(V\\sim \\chi^2 _\\nu\\) . If \\(Z\\) and \\(V\\) are independent then the random variable\n\\[\nT=\\frac{Z}{\\sqrt {V/\\nu}}\n\\]\nsaid to have a Student-t distribution with \\(\\nu\\) degrees of freedom. The PDF of \\(T\\) is\n\\[\nf(t)=\\frac{\\Gamma [(\\nu+1)/2]}{\\sqrt{ \\pi\\nu} \\ \\ \\Gamma{(\\nu/2)}}\\left(1+\\frac{t^2}{\\nu}\\right)^{-(\\nu+1)/2} ; -\\infty&lt;t&lt;\\infty.\n\\]\n\n\n\n\n\n\nTheorem\n\n\n\nGiven a random sample of \\(n\\) observations, with sample mean \\(\\bar x\\) and sample standard deviation \\(s\\), from a normally distributed population with mean \\(\\mu\\), the random variable \\(t\\) follows the Student’s t distribution with \\(\\nu=(n - 1)\\) degrees of freedom and is given by\n\\[\nt=\\frac{\\bar x-\\mu}{s/\\sqrt n}\n\\]\n\n\nProperties:\n\nSymmetry: \\(t\\)-distribution is symmetric about mean (zero). So\nif \\(P(T&gt;t_\\nu)=\\alpha\\) then \\(P(T&lt;-t_\\nu)=\\alpha\\).\nConvergence to Normal: As \\(n\\rightarrow\\infty\\) then the distribution of \\(T_\\nu\\) approaches the standard Normal distribution.\nCauchy as special case: The \\(T_1\\) distribution is the same as the Cauchy distribution.\n\nHow to to determine the area under the curve of \\(t\\)- distribution?\nFrom \\(t\\) -distribution table we can determine the value of \\(t\\) for a given \\(area\\) and degrees of freedom.\nFor example, with \\(n=11\\) and area in upper tail 0.05 the the value of \\(t\\) is \\(1.812\\). That is\n\\[\nP(T&gt;1.812)=0.05\n\\]\nDue to symmetry\n\\[\nP(T&lt;-1.812)=0.05\n\\]\n\n\n\nt-distribution. Source: Appendix B, TABLE 3 (Anderson 2020)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "sampling_and_sampling_distributions.html#f-distribution",
    "href": "sampling_and_sampling_distributions.html#f-distribution",
    "title": "8  Sampling and Sampling distributions",
    "section": "8.9 F-Distribution",
    "text": "8.9 F-Distribution\n\n8.9.1 The F -Distribution with Two Sample Variances\nIf \\(s_1^2\\) and \\(s_2^2\\) are the variances of independent random samples of size \\(n_1\\) and \\(n_2\\) taken from normal populations with variances \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\), respectively, then the random variable\n\\[\nF=\\frac{s_1^2/\\sigma_1^2}{s_2^2/\\sigma_2^2}\n\\]\nhas an \\(F\\) distribution with numerator degrees of freedom \\((n_1-1)\\) and denominator degrees of freedom \\((n_2-1)\\).\n\n\n\n\nAnderson, David R. 2020. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nBlack, Ken. 2012. Business statistics: for contemporary decision making. 7th ed. Hoboken, NJ: Wiley.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nWalpole, Ronald E., Raymond H. Myers, Sharon L. Myers, and Keying Ye. 2017. Probability & statistics for engineers & scientists: MyStatLab update. Ninth edition. Boston: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sampling and Sampling distributions</span>"
    ]
  },
  {
    "objectID": "estimation.html",
    "href": "estimation.html",
    "title": "9  Introduction to estimation",
    "section": "",
    "text": "9.1 Point Estimation",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduction to estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#point-estimation",
    "href": "estimation.html#point-estimation",
    "title": "9  Introduction to estimation",
    "section": "",
    "text": "To estimate the value of a population parameter, we compute a corresponding characteristic of the sample, referred to as a sample statistic.\nBy making the preceding computations, we perform the statistical procedure called point estimation. For instance, we refer to the sample mean \\(\\bar x\\) as the point estimator of the population mean \\(\\mu\\).\nThe numerical value obtained for , is called the point estimate.\n\n\n\n\nTable 9.1: Some common population parameters and their estimators\n\n\n\n\n\n\n\n\n\n\nPopulation parameter\nSymbol\nPoint estimator\n\n\n\n\nPopulation mean\n\\(\\mu\\)\nSample mean,\n\\(\\bar x=\\frac{\\sum x}{n}\\)\n\n\nPopulation standard deviation\n\\(\\sigma\\)\nSample standard deviation,\n\\(s=\\sqrt{\\frac{\\sum(x-\\bar x)^2}{n-1}}=\\sqrt {\\frac{\\sum x^2 -n\\cdot \\bar x^2}{n-1}}\\)\n\n\nPopulation proportion\n\\(p\\)\nSample proportion,\n\\(\\hat p=\\frac{\\# \\ \\ of \\ \\  outcomes\\ \\ of  \\ \\ interest }{n}\\)\n\n\n\n\n\n\n\n9.1.1 Properties of Point Estimators\nSuppose\n\\(\\theta\\) be the population parameter of interest\n\\(\\hat \\theta\\) be the sample statistic or point estimator of \\(\\theta\\)\nA “good” estimator has some desirable properties.\n\n\n\n\n\n\nUnbiased\n\n\n\nA sample statistic \\(\\hat \\theta\\) is said to be unbiased estimator of the population parameter \\(\\theta\\) if\n\\[\nE(\\hat\\theta)=\\theta\n\\]\n\n\nProblem 9.1 Show that the function of sample mean \\(\\bar X\\) is the unbiased estimator of population mean \\(\\mu\\).\nSolution:\nHere \\(X\\) is the variable of interest and let \\(X_1,X_2,...,X_n\\) is a sequence of random sample provided \\(E(X_i)=\\mu\\). The sample mean is \\(\\bar X=\\frac{\\sum_{i=1}^n X_i}{n}\\).\nNow\n\\[\nE(\\bar X)=E\\left( \\frac{\\sum_{i=1}^nX_i }{n}\\right)=\\frac{1}{n}E\\left( \\sum_{i=1}^n X_i\\right)\n\\]\n\\[\n=\\frac{1}{n}\\sum_{i=1}^n E(X_i)=\\frac{1}{n}\\sum_{i=1}^n \\mu=\\frac{1}{n}\\cdot n\\mu=\\mu\n\\]\n\\[\n\\therefore E(\\bar X)=\\mu\n\\]\nSo, \\(\\bar X\\) is an unbiased estimator of \\(\\mu\\).\nProblem 9.2 Show that the function of sample variance \\(S^2=\\frac{\\sum_{i=1}^n(X_i-\\bar X)^2}{n-1}\\) is an unbiased estimator of population variance \\(\\sigma^2\\).\nSolution: See Newbold, Carlson, and Thorne (2013), page 283, or we can proof it as follows:\nSuppose that \\(X\\) is a random variable with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Let \\(X_1, X_2 … X_n\\) be a random sample of size \\(n\\) from the population represented by \\(X\\).\nWe know \\(E(\\bar X)=\\mu_{\\bar X}=\\mu\\) .\nSo,\n\\(Var(X)\\) , \\(\\sigma^2=E(X^2)-\\mu^2\\)\nOr, \\(E(X^2)=\\mu^2+\\sigma^2\\)\nand\n\\(Var(\\bar X)\\), \\(\\sigma^2_{\\bar X}=E(\\bar X^2)-\\mu_{\\bar X}^2\\)\nOr, \\(E(\\bar X^2)=\\mu_{\\bar X}^2+\\sigma^2_{\\bar X}=\\mu^2+\\frac{\\sigma^2}{n}\\)\nNow,\n\\(E(S^2)=E\\left[ \\frac{\\sum_{i=1}^n (X_i-\\bar X)^2}{n-1}\\right]=\\frac{1}{n-1}E \\sum_{i=1}^n (X_i-\\bar X)^2=\\frac{1}{n-1}E\\sum_{i=1}^n(X_i^2+\\bar X^2-2 X_i \\bar X)\\)\n\\(=\\frac{1}{n-1} E\\left ( \\sum_{i=1}^n X_i^2-n\\bar X^2 \\right)=\\frac{1}{n-1} \\left [\\sum_{i=1}^n E(X_i^2)-n E(\\bar X^2) \\right]\\)\n\n\\(=\\frac{1}{n-1} \\left[ \\sum_{i=1}^n (\\mu^2+\\sigma^2)-n(\\mu^2+\\frac{\\sigma^2}{n}) \\right]=\\frac{1}{n-1} \\left[ n\\mu^2+n \\sigma^2-n\\mu^2-\\sigma^2 \\right]\\)\n\\(=\\frac{1}{n-1}(n-1) \\sigma^2=\\sigma^2\\)\n\\(\\therefore E(S^2)=\\sigma^2\\).\nHence \\(S^2\\) is an unbiased estimator of \\(\\sigma^2\\).\n\n\n\n\n\n\nEfficiency\n\n\n\n\n\n\n\n\n\n\n\n\nConsistency\n\n\n\n\n\n\nProblem 9.3 (Anderson 2020) A simple random sample of 30 managers and the corresponding data on annual salary and management training program participation are as shown in Table 9.2\n\n\n\nTable 9.2: Annual Salary and Training Program Status for a Simple Random Sample of 30 EAI Managers\n\n\n\n\n\nAnnual Salary ($000)\nManagement Training Program\n\n\n\n\n49.09\nYes\n\n\n53.26\nYes\n\n\n49.64\nYes\n\n\n49.89\nYes\n\n\n47.62\nNo\n\n\n45.92\nYes\n\n\n49.09\nYes\n\n\n51.40\nYes\n\n\n50.96\nYes\n\n\n45.11\nYes\n\n\n45.92\nNo\n\n\n57.27\nYes\n\n\n55.69\nNo\n\n\n51.56\nNo\n\n\n56.19\nNo\n\n\n51.77\nYes\n\n\n52.54\nNo\n\n\n44.98\nYes\n\n\n51.93\nYes\n\n\n52.97\nYes\n\n\n45.12\nYes\n\n\n51.75\nYes\n\n\n54.39\nNo\n\n\n50.16\nNo\n\n\n52.97\nYes\n\n\n50.24\nYes\n\n\n52.79\nYes\n\n\n50.98\nNo\n\n\n55.86\nYes\n\n\n57.31\nNo\n\n\n\n\n\n\na) Compute sample mean and standard deviation of annual salary ($) of a random sample of 30 EAI managers.\nSolution:\nLet \\(\\mu\\) be the population mean of annual salary of all EAI managers.\nIf \\(X\\) is the annual salary in ’000 USD, then the to estimate \\(\\mu\\) we use sample mean \\(\\bar x\\) as follows:\n\\[\n\\bar x=\\frac{\\sum_{i=1}^n x_i}{n}=\\frac{49.09+53.26+...+57.31}{30}\\approx51.1457\n\\]\nSo the sample mean is \\(\\$ 51145.7\\).\nSimilarly let \\(\\sigma\\) be the population standard deviation of annual salary of all EAI managers.\nThe estimate of \\(\\sigma\\) is the sample standard deviation \\(s\\) as follows:\n\\[\ns=\\sqrt \\frac{\\sum_{i=1}^n x_i^2 -n\\cdot (\\bar x)^2}{n-1}\n\\]\n\\[\n=\\sqrt \\frac{(49.09^2+53.26^2+...+57.31^2)-30\\cdot (51.1457)^2}{30-1}\n\\]\n\\[\n\\approx 3.5408\n\\]\nSo the sample standard deviation is \\(\\$ 3540.8\\).\nb) Also, estimate the proportion of managers in the population who completed the management training program.\nSolution: Here, \\(n=30\\)\nLet, \\(p\\) be the population proportion of managers who completed the training\nThe estimate of \\(p\\) is:\n\\[\n\\hat p=\\frac {\\# \\ \\ of\\ \\ yes}{n}=\\frac{20}{30}=0.6667\\approx 66.67\\%\n\\]\nProblem 9.4 (Anderson 2020)Many drugs used to treat cancer are expensive. Business Week reported on the cost per treatment of Herceptin, a drug used to treat breast cancer (Business Week, January 30, 2006). Typical treatment costs (in dollars) for Herceptin are provided by a simple random sample of 10 patients.\n4376 ,5578, 2717, 4920, 4495, 4798, 6446, 4119, 4237, 3814\na) Develop a point estimate of the mean cost per treatment with Herceptin.\nb) Develop a point estimate of the standard deviation of the cost per treatment with Herceptin.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduction to estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#interval-estimation",
    "href": "estimation.html#interval-estimation",
    "title": "9  Introduction to estimation",
    "section": "9.2 Interval estimation",
    "text": "9.2 Interval estimation\nInstead of estimating a population parameter by a single value (point estimator) it is more reasonable to estimate with an interval with some confidence (probability) that our parameter value will be in the interval.\n\n\n\n\n\n\nInterval Estimator\n\n\n\nAn interval estimator is a rule for determining (based on sample information) an interval that is likely to include the parameter. The general form of an interval estimate is as follows:\n\\[\nPoint\\ \\ estimate \\pm margin \\ \\ of \\ \\ error\n\\]\n\n\nDue to sampling variability, interval estimator is also random.\n\n9.2.1 Interval estimate of a population mean: \\(\\sigma\\) known\nThe \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\) is :\n\\[\n\\bar x \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt n}\n\\tag{9.1}\\]\nOr,\n\\[\n\\bar x-z_{\\alpha/2}\\frac {\\sigma}{\\sqrt n}, \\bar x+z_{\\alpha/2}\\frac {\\sigma}{\\sqrt n}\n\\]\nWe can express this confidence interval in a probabilistic way:\n\\[\nP\\left( \\bar x-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n}&lt;\\mu&lt;\\bar x+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt n}  \\right)=1-\\alpha\n\\]\nNOTE:\n1) Here, \\(z_{\\alpha/2}\\) is the \\(z\\) value providing an area of \\(\\alpha/2\\) in the upper tail of the standard normal distribution that is \\(P(Z&gt;z_{\\alpha/2})=\\alpha/2\\).\n2) \\(z_{\\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt n}\\) is often called margin of error (ME).\n\n\n9.2.2 Interpretation of confidence interval\nThe probabilistic equation of confidence interval says that, if we repeatedly construct confidence intervals in this manner, we will expect \\((1-\\alpha)100\\%\\) of them contain \\(\\mu\\).\n\n\n9.2.3 Understanding confidence interval through Simulation\nSuppose \\(X\\sim N(50,5^2)\\) . Now consider a population data of size \\(N=10000\\) and the histogram of \\(X\\) is:\n\n\nCode\nset.seed(36)\nX&lt;-rnorm(10000,50,5)\n\nhist(X,freq = F,sub= \"Population size, N=10000\")\nlines(density(X),lwd=2)\n\n\n\n\n\n\n\n\n\nNow we draw a random sample of size \\(n=50\\) from this population and construct a 95% confidence interval (CI) for \\(\\mu\\). The CI may or may not include the \\(\\mu=50\\) !!!\n\n\nCode\nset.seed(36)\nmu=50;sigma=5\n\n## Constructing (1-alpha)*100% CI\n\nalpha=0.05 \n\ncon.coef=1-alpha # confidence level\n\nz=round(abs(qnorm(alpha/2)),2)# z=1.96\n\nn=50 # sample size\n\ns.e&lt;-sigma/sqrt(n)\n\nsampl_1&lt;-sample(X,n)\ncat(\"Sample data :\", sampl_1)\n\n\nSample data : 52.60842 55.16664 59.23435 44.2092 50.94234 43.34063 44.65922 53.81687 47.60075 46.63776 49.04826 49.44461 52.87322 46.22968 48.2174 55.67331 53.41989 51.86472 54.8001 41.25542 47.11374 47.38467 46.27874 49.85406 44.46384 52.43189 44.33381 53.19745 53.2059 57.02731 43.5203 48.93579 50.28559 55.69281 48.55212 49.2889 45.48768 46.8649 46.96022 35.22993 54.00936 58.99123 50.92287 45.76209 45.1751 44.65327 48.44115 49.47725 55.49664 44.73951\n\n\nCode\ncat(\"Sample mean:\",round(mean(sampl_1),2))\n\n\nSample mean: 49.3\n\n\nCode\nci_1&lt;-c(lower=mean(sampl_1)-z*s.e,upper=mean(sampl_1)+z*s.e)\n#ci_1[1]\ncat(\"95%  CI:\",\"\\n\", \"[Lower ,Upper]\",\"\\n\", \"[\",round(ci_1[1],2),\",\",round(ci_1[2],2),\"]\")\n\n\n95%  CI: \n [Lower ,Upper] \n [ 47.91 , 50.68 ]\n\n\nLuckily our 95% CI contains the true population mean \\(\\mu=50\\) 😊.\nLets simulate 100 samples each of size \\(n=50\\) and construct all 95% CIs.\n\n\nCode\nlibrary(tidyverse)\n\n# Suppose, X~N(50,5^2); so\n#cat(\"mu=\",50,\",\", \"sigma=\",5)\n\n\n\n# Let simulate 100 samples each of size n=50\n\nsampl=0\n\nB=100 # number of samples we have drawn from population X\n\nsampl&lt;-(replicate(B,sample(X,n,replace = FALSE)))\n\nsample.means&lt;-colMeans(sampl)\n\n#class(sample.means)\n\nsample.means&lt;-as.data.frame(sample.means)\n#class(sample.means)\n\nsample.means%&gt;%rename(x_bar=sample.means)-&gt;sample.means\n\nci&lt;-sample.means%&gt;%mutate(ll=x_bar-z*s.e,ul=x_bar+z*s.e)\n\nci%&gt;%mutate(id=1:100)%&gt;%select(id,x_bar,ll,ul)-&gt;ci\n\nci%&gt;%mutate(Capture=ifelse(50&gt;ll & 50&lt;ul,\"1\",\"0\"))-&gt;ci_95\n\n#ci%&gt;%head()\n\n# https://statisticsglobe.com/draw-plot-with-confidence-intervals-in-r\n\ncolorset = c('0'='red','1'='black')\n\n\nlabels&lt;- expression(\"Population mean,\"~mu == 50)\n\nggplot(ci_95, aes(id, x_bar)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = ll, ymax = ul,color = Capture))+\n  geom_hline(yintercept = 50, linetype = \"dashed\", color = \"blue\")+\n  scale_color_manual(values = colorset)+\n  ylim(45,55)+\n  scale_x_continuous(breaks = seq(1,100,5),limits=c(0, 101))+\n  #annotate(\"text\",label=paste(\"Population mean,mu=\",mu),x=90,y=54)+\n  annotate(\"text\",x=90,y=53.5,label=as.character(labels),parse=TRUE)+\n    labs(title =paste(con.coef*100, \"% Confidence Intervals, n =\", n),\n       x=\"Sample ID\")+\n  coord_flip()+\n  theme_bw()\n\n\n\n\n\n\n\n\nFigure 9.1: Simulation of 95% confidence intervals for \\(\\mu\\)\n\n\n\n\n\nWe can see that out of 100 CIs , 95 of them contain true population mean \\(\\mu=50\\) and the rest 5 do not.\n\n\n\nTable 9.3: Four Commonly Used Confidence Levels and \\(z_{\\alpha/2}\\)\n\n\n\n\n\n\\(1-\\alpha\\)\n\\(\\alpha\\)\n\\(z_{\\alpha/2}\\)\n\n\n\n\n0.90\n0.10\n1.645\n\n\n0.95\n0.05\n1.96\n\n\n0.98\n0.02\n2.33\n\n\n0.99\n0.01\n2.575\n\n\n\n\n\n\n\n\n9.2.4 Interval estimate of a population mean: \\(\\sigma\\) unknown\nThe \\((1-\\alpha)100\\%\\) confidence interval for \\(\\mu\\) is :\n\\[\n\\bar x \\pm t_{\\alpha/2} \\frac{s}{\\sqrt n}\n\\tag{9.2}\\]\nOr,\n\\[\n\\bar x-t_{\\alpha/2}\\frac {s}{\\sqrt n}, \\bar x+t_{\\alpha/2}\\frac {s}{\\sqrt n}\n\\]\nWe can express this confidence interval in a probabilistic way:\n\\[\nP\\left( \\bar x-t_{\\alpha/2}\\frac{s}{\\sqrt n}&lt;\\mu&lt;\\bar x+t_{\\alpha/2}\\frac{s}{\\sqrt n}  \\right)=1-\\alpha\n\\]\nHere, \\(t_{\\alpha/2}\\) is the \\(t\\) value providing an area of \\(\\alpha/2\\) in the upper tail of the \\(t\\) distribution with \\((n-1)\\) degrees of freedom that is \\(P(T&gt;t_{\\alpha/2,n-1})=\\alpha/2\\).\nProblem 9.5 (Keller 2014, 341) In a survey conducted to determine, among other things, the cost of vacations, 64 individuals were randomly sampled. Each person was asked to compute the cost of her or his most recent vacation and the sample mean was $1810.16. Assuming that the standard deviation is $400, estimate with 95% confidence the average cost of all vacations.\n\nProblem 9.6 (Keller 2014, 340) It is known that the amount of time needed to change the oil on a car is normally distributed with a standard deviation of 5 minutes. The amount of time to complete a random sample of 10 oil changes was recorded and listed here. Compute the 99% confidence interval estimate of the mean of the population.\n11, 10, 16, 15 ,18, 12 ,25,20, 18 ,24\nProblem 9.7 (Newbold, Carlson, and Thorne 2013, 302) How much do students pay, on the average, for textbooks during the first semester of college? From a random sample of 400 students the mean cost was found to be $357.75, and the sample standard deviation was $37.89. Assuming that the population is normally distributed, find the 95% confidence interval for the population mean.\n\nProblem 9.8 (Newbold, Carlson, and Thorne 2013, 302)Twenty people in one large metropolitan area were asked to record the time (in minutes) that it takes them to drive to work. These times were as follows:\n30, 42, 35, 40, 45, 22, 32, 15, 41, 45, 28, 32, 45, 27, 47, 50, 30, 25, 46, 25\nAssuming that the population is normally distributed find the 99% confidence interval for the population mean of time it takes to drive to work.\n\n\n9.2.5 Interval estimation for population proportion : Large sample\nFrom previous chapter we know if \\(np\\) and \\(np(1-p)\\) is equal or greater than \\(5\\) then the sample proportion \\(\\hat p\\) will approximately follow normal distribution with mean \\(p\\) and variance \\(\\frac{p(1-p)}{n}\\).\nMathematically,\n\\[\nZ=\\frac{\\hat p-p}{\\sqrt {\\frac{p(1-p)}{n}}}\\approx follows \\ \\ N(0,1)\n\\]\nSince \\(p\\) is unknown we estimate \\(var(\\hat p)\\) as \\(\\sqrt { \\frac{\\hat p(1-\\hat p)}{n}}\\).\nConfidence Interval for Population Proportion, \\(p\\) (Large Samples)\n\\[\n\\hat p\\pm z_{\\alpha/2} \\sqrt {\\frac{\\hat p(1-\\hat p)}{n}}\n\\tag{9.3}\\]\nwhich is valid provided that \\(n\\hat p\\) and \\(n(1 - \\hat p)\\) are greater than 5.\n\nProblem 9.9 (Newbold, Carlson, and Thorne 2013, 305) In a random sample of 95 manufacturing firms, 67 indicated that their company attained ISO certification within the last two years. Find a 99% confidence interval for the population proportion of companies that have been certified within the last 2 years.\nProblem 9.10 (Newbold, Carlson, and Thorne 2013, 305) From a random sample of 400 registered voters in one city, 320 indicated that they would vote in favor of a proposed policy in an upcoming election. Find a 98% confidence interval for the population proportion in favor of this policy.\n\n\n\n\n\n\nAnderson, David R. 2020. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013. Statistics for business and economics. 8. ed., global ed. Always learning. Boston, Mass. Munich: Pearson.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Introduction to estimation</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html",
    "href": "hypothesis_test.html",
    "title": "10  Hypothesis test",
    "section": "",
    "text": "10.1 Definition\nA statistical hypothesis is a statement about the parameters of one or more populations.\nExample 1: A manufacturer claims that the mean life of a smartphone is more than 1.5 years.\nExample 2: A local courier service claims that they deliver a ordered product within 30 minutes on average.\nExample 3: A sports drink maker claims that the mean calorie content of its beverages is 72 calories per serving.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#types-of-hypothesis",
    "href": "hypothesis_test.html#types-of-hypothesis",
    "title": "10  Hypothesis test",
    "section": "10.2 Types of hypothesis",
    "text": "10.2 Types of hypothesis\nStatistical hypothesis are stated in two forms- (i) Null hypothesis (\\(H_0\\)) and (ii) Alternative hypothesis (\\(H_1\\)).\nBoth null and alternative hypothesis are the written about the parameter of interest based on the claim.\n\nWe will always state the null hypothesis as an equality claim.\nHowever, when the alternative hypothesis is stated with the “&lt;” sign, the implicit claim in the null hypothesis can be taken as ” ≥ “ or “=” sign.\nWhen the alternative hypothesis is stated with the “&gt;” sign, the implicit claim in the null hypothesis can be taken as “≤” or “=” sign.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#developing-hypotheses",
    "href": "hypothesis_test.html#developing-hypotheses",
    "title": "10  Hypothesis test",
    "section": "10.3 Developing hypotheses",
    "text": "10.3 Developing hypotheses\nTo develop or state null and alternative hypothesis, at first we have to clearly identify the “claim” about population parameter. Now we will see some examples.\nExample 1: A manufacturer claims that the mean life of a smartphone is more than 1.5 years.\nHypothesis:\n\n\\(H_0:\\mu=1.5\\)\n\\(\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  H_1: \\mu&gt;1.5 \\ \\ (claim)\\)\n\nExample 2: A local courier service claims that they deliver a ordered product within 30 minutes on average.\nHypothesis:\n\n\\(H_0: \\mu=30\\)\n\\(\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ H_1: \\mu&lt;30 \\ \\ (claim)\\)\n\nExample 3: A sports drink maker claims that the mean calorie content of its beverages is 72 calories per serving.\nHypothesis:\n\n\\(\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ H_0: \\mu=72 \\ \\ (claim)\\)\n\\(H_1: \\mu \\ne 72\\)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#types-of-test-based-on-alternative-hypothesis-h_1",
    "href": "hypothesis_test.html#types-of-test-based-on-alternative-hypothesis-h_1",
    "title": "10  Hypothesis test",
    "section": "10.4 Types of test based on alternative hypothesis \\(H_1\\)",
    "text": "10.4 Types of test based on alternative hypothesis \\(H_1\\)\n\n\\(H_1: \\mu&lt; \\mu_0\\) (Lower tailed)\n\\(H_1: \\mu&gt; \\mu_0\\) (Upper tailed)\n\\(H_1: \\mu \\ne \\mu_0\\) (Two-tailed)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#types-of-error-in-hypothesis-test",
    "href": "hypothesis_test.html#types-of-error-in-hypothesis-test",
    "title": "10  Hypothesis test",
    "section": "10.5 Types of error in hypothesis test",
    "text": "10.5 Types of error in hypothesis test\nWhile testing a statistical hypothesis concerning population parameter we commit two types of errors.\n\nType I error occurs when we reject a TRUE \\(H_0\\)\nType II error occurs when we FAIL to reject a FALSE \\(H_0\\)\nThe Level of significance is the probability of comiting Type I error. It is denoted by \\(\\alpha\\).\n\n\\[\n\\alpha= P(Type \\ \\ I \\ \\ error)\n\\]\n\nThe probability of committing a Type II error, denoted by \\(\\beta\\).\n\n\\[\n\\beta =P(Type \\ \\ II \\ \\ error)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nType I error is more serious than Type II error. Because rejecting a TRUE statement is more devastating than FAIL to reject a FALSE statement. So, we always try to keep our probability of Type I error as small as possible (1% or at most 5%). For more detail see (Keller 2014).\n\n\nSo, how these hypotheses will be tested?\nTo test a hypothesis we have to determine\n\na test-statistic; and\ncritical/Rejection region based on the sampling distribution of test-statistic for a given \\(\\alpha\\) ;\nif the value of test-statistic falls in Critical/Rejection region, then we reject Null (\\(H_0\\)) hypothesis; otherwise not.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "hypothesis_test.html#hypothesis-testing-concerning-population-mean-mu",
    "href": "hypothesis_test.html#hypothesis-testing-concerning-population-mean-mu",
    "title": "10  Hypothesis test",
    "section": "10.6 Hypothesis testing concerning population mean (\\(\\mu\\))",
    "text": "10.6 Hypothesis testing concerning population mean (\\(\\mu\\))\nThe following two hypotheses tests are used concerning population mean (\\(\\mu\\)):\n1. One sample z-test (with known \\(\\sigma\\))\n2. One sample t-test (with unknown \\(\\sigma\\))\n\n\n10.6.1 One sample z-test\nWhen sampling is from a normally distributed population or sample size is sufficiently large and the population variance is known, the test statistic for testing \\(H_0: \\mu=\\mu_0\\) at \\(\\alpha\\) is\n\\[\nz=\\frac{\\bar x-\\mu_0}{\\sigma /\\sqrt n}\n\\]\nDecision (Critical value approach): If calculated \\(z\\) falls in rejection region (CR) , then reject \\(H_0\\) . Otherwise, do not reject \\(H_0\\).\n\nFor lower tailed test, reject \\(H_0\\) if \\(z&lt;-z_\\alpha\\) ;\nFor upper tailed test, reject \\(H_0\\) if \\(z&gt; z_\\alpha\\) ;\nFor two-tailed test, reject \\(H_0\\) if \\(z&lt;-z_{\\alpha/2}\\) or \\(z&gt;z_{\\alpha/2}\\) .\n\nProblem 9.6.1.1 The waiting time for customers at MacBurger Restaurants follows a normal distribution with a mean of 3 minutes and a standard deviation of 1 minute. At the Warren Road MacBurger, the quality-assurance department sampled 50 customers and found that the mean waiting time was 2.75 minutes. At the 0.05 significance level, can we conclude that the mean waiting time is less than 3 minutes?\nProblem 9.6.1.2 At the time she was hired as a server at the Grumney Family Restaurant, Beth Brigden was told, “You can average $80 a day in tips.” Assume the population of daily tips is normally distributed with a standard deviation of $3.24. Over the first 35 days she was employed at the restaurant, the mean daily amount of her tips was $84.85. At the 0.01 significance level, can Ms. Brigden conclude that her daily tips average more than $80?\n\nProblem 9.6.1.3 The manufacturer of the X-15 steel-belted radial truck tire claims that the mean mileage the tire can be driven before the tread wears out is 60,000 miles. Assume the mileage wear follows the normal distribution and the standard deviation of the distribution is 5,000 miles. Crosset Truck Company bought 48 tires and found that the mean mileage for its trucks is 59,500 miles. Is Crosset’s experience different from that claimed by the manufacturer at the 0.05 significance level?\n\n\n10.6.2 One sample t-test\nWhen sampling is from a normally distributed population or sample size is sufficiently large and the population variance is unknown, the test statistic for testing \\(H_0: \\mu=\\mu_0\\) at \\(\\alpha\\) is\n\\[\nt=\\frac{\\bar x-\\mu_0}{s /\\sqrt n}\n\\]\nTest statistic \\(t\\) follows a Student’s 𝑡 distribution with \\((n - 1)\\) degrees of freedom.\nDecision (Critical value approach): If calculated \\(t\\) falls in rejection region (CR) , then reject \\(H_0\\) . Otherwise, do not reject \\(H_0\\).\n\nFor lower tailed test, reject \\(H_0\\) if \\(t&lt;-t_\\alpha\\) ;\nFor upper tailed test, reject \\(H_0\\) if \\(t&gt; t_\\alpha\\) ;\nFor two-tailed test, reject \\(H_0\\) if \\(t&lt;-t_{\\alpha/2}\\) or \\(t&gt;t_{\\alpha/2}\\) .\n\nProblem 9.6.2.1 Annual per capita consumption of milk is 21.6 gallons (Statistical Abstract of the United States: 2006). Being from the Midwest, you believe milk consumption is higher there and wish to support your opinion. A sample of 16 individuals from the Midwestern town of Webster City showed a sample mean annual consumption of 24.1 gallons with a standard deviation of \\(s=4.8\\) .\na) Develop a hypothesis test that can be used to determine whether the mean annual consumption in Webster City is higher than the national mean.\nb) Test the hypothesis at \\(\\alpha=0.05\\) .\nc) Draw a conclusion.\nProblem 9.6.2.2 The mean length of a small counterbalance bar is 43 millimeters. The production supervisor is concerned that the adjustments of the machine producing the bars have changed. He asks the Engineering Department to investigate. Engineer selects a random sample of 10 bars and measures each. The results are reported below in millimeters.\n42, 39, 42, 45, 43, 40, 39, 41, 40, 42\nIs it reasonable to conclude that there has been a change in the mean length of the bars?\n\n\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Hypothesis test</span>"
    ]
  },
  {
    "objectID": "Correlation.html",
    "href": "Correlation.html",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "",
    "text": "11.1 Scatter plot: Graphical method to explore correlation\nA scatter plot shows the relationship between two quantitative variables measured for the same individuals. The values of one variable appear on the horizontal axis, and the values of the other variable appear on the vertical axis. Each individual in the data appears as a point on the graph.\nLets draw a scatter plot for the following data.\nCode\nlibrary(tidyverse)\nlibrary(gt)\nx=c(2,5,1,3,4,1,5,3,4,2)\ny=c(50,57,41,54,54,38,63,48,59,46)\nxy=data.frame(x,y)\nxy %&gt;%t() %&gt;% as.data.frame()-&gt;t.xy\ncolnames(t.xy)&lt;-1:10\n#t.xy %&gt;% gt()\nt.xy %&gt;%knitr::kable()\n\n\n\n\nTable 11.1: Data\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nx\n2\n5\n1\n3\n4\n1\n5\n3\n4\n2\n\n\ny\n50\n57\n41\n54\n54\n38\n63\n48\n59\n46\nCode\nlibrary(ggthemes)\n\nggplot(xy,aes(x,y))+\n  geom_point()+\n  labs(subtitle = \"Positive correlation exists between X and Y\")+\n  theme_light ()+\n  theme(plot.background = element_rect(colour = \"black\"),\n        axis.title = element_text(size = 14, face = \"bold\"),\n        axis.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nFigure 11.2: Sctter plot between X and Y\nIn fact, the scatter lot suggests that a straight line could be used as an approximation of the relationship. In the following discussion, we introduce covariance, coefficient of correlation, and coefficient of determination as descriptive measures which provide direction and strength of the linear relationship between two variables.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Correlation.html#scatter-plot-graphical-method-to-explore-correlation",
    "href": "Correlation.html#scatter-plot-graphical-method-to-explore-correlation",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "",
    "text": "A scatterplot displays the strength, direction, and form of the relationship between two quantitative variables (see Figure 11.1).\n\n\n\n\n\n\n\nFigure 11.1: Types of correlations that can be represented using a scatter plot",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Correlation.html#covariance",
    "href": "Correlation.html#covariance",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "11.2 Covariance",
    "text": "11.2 Covariance\nThe covariance between \\(X\\) and \\(Y\\) is defined as follows\nPopulation covariance\n\\[\n\\sigma_{XY}=\\frac{\\sum_{i=1}^N (x_i-\\mu_X)(y_i-\\mu_Y)}{N}\n\\]\nSample covariance\n\\[\ns_{XY}=\\frac{\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)}{n-1}\n\\]\nShortcut for Sample Covariance\n\\[\ns_{XY}=\\frac{\\sum xy -n \\bar x \\bar y }{n-1}\n\\] Or,\n\\[\ns_{XY}=\\frac{1}{n-1}\\left[ \\sum xy -\\frac{\\sum x \\sum y}{n}     \\right ]   \n\\tag{11.1}\\]\nExample: Compute sample covariance between \\(X\\) and \\(Y\\) from Table 11.1.\nSolution:\n\n\nCode\n#sum(x); sum(y)\n#sum(x*y)\n\n\nHere, \\(n=10 ; \\sum x=30 ; \\sum y =510\\).\n\\(\\sum xy =x_1y_1+x_2y_2+ \\cdot \\cdot \\cdot+x_ny_n= 1629\\)\nHence the sample covariance,\n\\[\ns_{XY}=\\frac{1}{n-1} \\left[\\sum xy - \\frac{\\sum x \\sum y}{n}   \\right]\n\\]\n\\[\n=\\frac{1}{10-1} \\left[1629 - \\frac{30\\times 510}{10} \\right]\n\\]\n\\[\n\\therefore s_{XY}=11\n\\]\nSince, \\(s_{XY}&gt;0\\) so there exists positive correlation between \\(X\\) and \\(Y\\).\nDrawback of covariance\nAccording to Keller (2014) , “Unfortunately, the magnitude may be difficult to judge. For example, if you’re told that the covariance between two variables is 500, does this mean that there is a strong linear relationship? The answer is that it is impossible to judge without additional statistics. Fortunately, we can improve on the information provided by this statistic by creating another one.”",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Correlation.html#coefficient-of-correlation",
    "href": "Correlation.html#coefficient-of-correlation",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "11.3 Coefficient of Correlation",
    "text": "11.3 Coefficient of Correlation\nThe Pearson product-moment coefficient of correlation is defined as the covariance divided by the standard deviations of the variables.\nPopulation correlation coefficient\n\\[\n\\rho=\\frac{\\sigma_{XY}}{\\sigma_X \\times \\sigma_Y}\\ \\ ;\\ \\ -1\\le\\rho \\le +1\n\\]\nSample correlation coefficient\n\\[\nr=\\frac{s_{XY}}{s_X \\times s_Y}\\ \\ ;\\ \\ -1\\le r \\le +1\n\\tag{11.2}\\]\nWhere\n\\(s_{XY}\\) is sample covariance between \\(X\\) and \\(Y\\) \\(s_X\\) is sample standard deviation of \\(X\\) and \\(s_Y\\) is sample standard deviation of \\(Y\\).\nNote: The sample correlation coefficient can be expressed in another form:\n\\[\nr=\\frac{n \\sum xy-(\\sum x) (\\sum y)}{\\sqrt {\\left [n\\sum x^2-(\\sum x)^2 \\right] } \\sqrt{\\left [n\\sum y^2-(\\sum y)^2 \\right]}}\n\\]\n\n11.3.1 Interpretation of correlation coefficient\n(a) \\(r=-1\\) implies perfect negative correlation,\n(b) \\(r=+1\\) implies perfect positive correlation,\n(c) \\(r\\approx 0\\) implies no correlation or very weak correlation,\n(d) As \\(r\\) close to \\(-1\\) , the degree of negative correlation becomes stronger,\n(e) As \\(r\\) close to \\(+1\\) , the degree of positive correlation becomes stronger.\n\n\n11.3.2 Computing the Coefficient of Correlation\nLet us compute sample correlation coefficient between \\(X\\) and \\(Y\\) from Table 11.1.\n\n\nCode\n#sum(x); sum(y)\n#sum(x*y)\n#sum(x^2)\n#sum(y^2)\n\n\nHere, \\(n=10 ; \\sum x=30 ; \\sum y =510\\).\n\\(\\sum xy =x_1y_1+x_2y_2+ \\cdot \\cdot \\cdot+x_ny_n= 1629\\)\n\\(\\sum x^2=2^2+5^2 +...+2^2=110\\)\n\\(\\sum y^2=50^2+57^2 +...+46^2=26576\\)\n\\(\\bar x =3\\)\n\\(\\bar y =51\\)\nSo,\n\\[\ns_X=\\sqrt { \\frac{\\sum x^2 -n \\ \\  \\bar x^2}{n-1}}=1.490712\n\\]\n\\[\ns_Y=\\sqrt { \\frac{\\sum y^2 -n \\ \\ \\bar y^2}{n-1}}=7.930252\n\\]\n\\[\ns_{XY}=\\frac{\\sum xy -n \\ \\ \\bar x \\ \\ \\bar y }{n-1}=11\n\\]\n\n\nCode\n#$s_X=\\sqrt {\\frac{1}{n-1} \\left[ \\sum x^2- \\frac{(\\sum #x)^2}{n}\\right]}$\n\n\nHence,\n\\[\nr=\\frac{s_{XY}}{s_X \\times s_Y}=\\frac{11}{1.490712\\times 7.930252}=0.9305\n\\]\nwhich is close to 1. So the correlation between \\(X\\) and \\(Y\\) is strong and positive.\n\n\n11.3.3 Exercises: Constructing a Scatter Plot and Determining Correlation\nIn Exercises 1–4, (a) display the data in a scatter plot, (b) calculate the sample correlation coefficient \\(r\\), and (c) describe the type of correlation and interpret the correlation in the context of the data.\n1. Age and Blood Pressure. The ages (in years) of 10 men and their systolic blood pressures (in millimeters of mercury) (Larson and Farber 2015, 482)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge, x\n16\n25\n39\n45\n49\n64\n70\n29\n57\n22\n\n\nSystolic blood pressure, y\n109\n122\n143\n132\n199\n185\n199\n130\n175\n118\n\n\n\n\n2. Driving Speed and Fuel Efficiency. A department of transportation’s study on driving speed and miles per gallon for midsize automobiles resulted in the following data (Anderson 2020a, 149):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeed (Miles per Hour)\n30\n50\n40\n55\n30\n25\n60\n25\n50\n55\n\n\nMiles per Gallon\n28\n25\n25\n23\n30\n32\n21\n35\n26\n25\n\n\n\n\n3. Are the marks one receives in a course related to the amount of time spent studying the subject? To analyze this mysterious possibility, a student took a random sample of 10 students who had enrolled in an accounting class last semester. He asked each to report his or her mark in the course and the total number of hours spent studying accounting. These data are listed here (Keller 2014).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy time\n40\n42\n37\n47\n25\n44\n41\n48\n35\n28\n\n\nMarks\n77\n63\n79\n86\n51\n78\n83\n90\n65\n47\n\n\n\n\n4. The owner of a paint store was attempting to analyse the relationship between advertising and sales, and recorded the monthly advertising budget ($’000) and the sales ($m) for a sample of 12 months. The data are listed here\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertising\n23\n46\n60\n54\n28\n33\n25\n31\n36\n88\n95\n99\n\n\nSales\n8\n11\n13\n13\n8.9\n10.7\n9\n10.4\n11\n14\n14.4\n15.9\n\n\n\n\n\n11.3.4 Coefficient of determination\nThe coefficient of determination measures the amount of variation in the dependent variable that is explained by the variation in the independent variable.\nFor example, if \\(r=0.8764\\) between \\(X\\) and \\(Y\\) then coefficient of determination \\(r^2=(0.8764)^2 \\approx 0.7681\\).\nInterpretation: The \\(r^2=0.7681\\) tells us that 76.81% variation in \\(Y\\) (dependent variable) can be explained by \\(X\\) (independent variable).\n\n\n\n11.3.5 Correlation vs. causation\nCorrelation does not always imply causation. For example,\n\nA study(Messerli 2012) found that there was a significant (\\(r=0.791\\)) positive correlation between chocolate consumption per capita and number of Nobel laureates per 10 million persons. This does not necessarily implies that more a country consumes chocolate, more the chance of getting a Nobel prize. Rather differences in socioeconomic status from country to country and geographic and climatic factors may play some role to win a Nobel prize.\nWe might find that there is a positive correlation between the time spent driving on road and the number of accidents but this does not mean that spending more time on road causes accident.Because in that case, in order to avoid accidents one may drive fast so that time spent on road is less (Selvamuthu and Das 2024).\n\n\n\n11.3.6 Effect of outlier on correlation coefficient\nThe correlation coefficient is heavily affected by outlier (see Figure 11.3). It changes the magnitude of the correlation coefficient.\n\n\nCode\n# Set seed for reproducibility\nset.seed(0)\n\n# Generate data with a positive correlation\nx &lt;- runif(50, 0, 10)\ny &lt;- 2 * x + rnorm(50, 0, 2)  # Linear relationship with some noise\n\n# Calculate correlation without outlier\ncorrelation_without_outlier &lt;- cor(x, y)\n\n# Add an outlier\nx_outlier &lt;- c(x, 15)\ny_outlier &lt;- c(y, -15)  # Outlier with opposite trend\n\n# Calculate correlation with outlier\ncorrelation_with_outlier &lt;- cor(x_outlier, y_outlier)\n\n# Plot data\npar(mfrow=c(1,2))  # Arrange plots side-by-side\n\n# Plot without outlier\nplot(x, y, main=paste(\"Without Outlier\\nCorrelation, r =\", round(correlation_without_outlier, 2)),\n     xlab=\"X\", ylab=\"Y\", col=\"steelblue\", pch=19)\nabline(lm(y ~ x), col=\"red\")  # Add line of best fit\n\n# Plot with outlier\nplot(x_outlier, y_outlier, main=paste(\"With Outlier\\nCorrelation, r=\", round(correlation_with_outlier, 2)),\n     xlab=\"X\", ylab=\"Y\", col=\"steelblue\", pch=19)\npoints(15, -15, col=\"red\", pch=4, cex=2)  # Mark the outlier\nabline(lm(y_outlier ~ x_outlier), col=\"red\")  # Add line of best fit\n\npar(mfrow=c(1,1))  # Reset plot layout\n\n\n\n\n\n\n\n\nFigure 11.3: Effect of outlier on the magnitude of correlation coefficient (r)\n\n\n\n\n\nEven sometime the outlier(s) can change the sign of the correlation coefficient (see Figure 11.4).\n\n\nCode\n# Set seed for reproducibility\nset.seed(42)\n\n# Generate data with a positive correlation\nx &lt;- runif(50, 0, 10)\ny &lt;- -0.5 * x + rnorm(40, 0, 1)  # Negative linear relationship with some noise\n\n# Calculate correlation without the outlier\ncorrelation_without_outlier &lt;- cor(x, y)\n\n# Add an outlier that reverses the correlation direction\nx_outlier &lt;- c(x, 50)\ny_outlier &lt;- c(y, 10)  # Extreme negative outlier\n\n# Calculate correlation with the outlier\ncorrelation_with_outlier &lt;- cor(x_outlier, y_outlier)\n\n# Plot data\npar(mfrow=c(1,2))  # Arrange plots side-by-side\n\n# Plot without outlier\n\nplot(x, y, main=paste(\"Without Outlier\\nCorrelation, r=\", round(correlation_without_outlier, 2)),\n     xlab=\"X\", ylab=\"Y\", col=\"#389\", pch=19)\nabline(lm(y ~ x), col=\"red\")  # Add line of best fit\n\n# Plot with outlier\nplot(x_outlier, y_outlier, main=paste(\"With Outlier\\nCorrelation, r=\", round(correlation_with_outlier, 2)),\n     xlab=\"X\", ylab=\"Y\", col=\"#389\", pch=19)\npoints(50, 10, col=\"red\", pch=4, cex=2)  # Mark the outlier\nabline(lm(y_outlier ~ x_outlier), col=\"red\")  # Add line of best fit\n\npar(mfrow=c(1,1))  # Reset plot layout\n\n\n\n\n\n\n\n\nFigure 11.4: Effect of outlier on the sign of correlation coefficient (r)",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Correlation.html#rank-correlation",
    "href": "Correlation.html#rank-correlation",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "11.4 Rank correlation",
    "text": "11.4 Rank correlation\nTo measure the association between two ordinal or rank-ordered data we use the Spearman Rank-correlation coefficient (RCC). Even if in presence of outliers in interval or ratio scale data we can use RCC. The sample Spearman RCC is computed as follows:\n\\[\nr_s=1-\\frac{6\\sum_{i=1}^n d_i^2}{n(n^2+1)}\n\\tag{11.3}\\]\nWhere,\n\\(n\\) = the number of observations in the sample\n\\(x_i\\) = the rank of observation \\(i\\) with respect to the first variable\n\\(y_i\\) = the rank of observation \\(i\\) with respect to the second variable\n\\(d_i\\) = \\(x_i-y_i\\)\nThe interpretation is as usual as Pearson correlation coefficient.\nProblem 8.4.1 Technology Company Reputations and Investor Willingness to Purchase Stock. A national study by Harris Interactive, Inc., evaluated the top technology companies and their reputations. The following shows how 10 technology companies ranked in reputation and how the companies ranked in percentage of respondents who said they would purchase the company’s stock. A positive rank correlation is anticipated because it seems reasonable to expect that a company with a higher reputation would have the more desirable stock to purchase (Anderson 2020b).\n\n\n\nCompany\nReputation\nStock Purchase\n\n\n\n\nMicrosoft\n1\n3\n\n\nIntel\n2\n4\n\n\nDell\n3\n1\n\n\nLucent\n4\n2\n\n\nTexas Instruments\n5\n9\n\n\nCisco Systems\n6\n5\n\n\nHewlett-Packard\n7\n10\n\n\nIBM\n8\n6\n\n\nMotorola\n9\n7\n\n\nYahoo\n10\n8\n\n\n\nCompute and interpret the rank correlation between reputation and stock purchase.\nProblem 8.4.1 Quality of Teaching Assessments. A student organization surveyed both current students and recent graduates to obtain information on the quality of teaching at a particular university. An analysis of the responses provided the following teaching-ability rankings. Do the rankings given by the current students agree with the rankings given by the recent graduates ? (Anderson 2020b)\n\n\n\n\nProfessor\nCurrent Students\nRecent Graduates\n\n\n\n\n1\n4\n6\n\n\n2\n6\n8\n\n\n3\n8\n5\n\n\n4\n3\n1\n\n\n5\n1\n2\n\n\n6\n2\n3\n\n\n7\n5\n7\n\n\n8\n10\n9\n\n\n9\n7\n4\n\n\n10\n9\n10",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "Correlation.html#simple-linear-regression-slr",
    "href": "Correlation.html#simple-linear-regression-slr",
    "title": "11  Correlation and Simple Linear Regression",
    "section": "11.5 Simple linear regression (SLR)",
    "text": "11.5 Simple linear regression (SLR)\nIn regression analysis we try to estimate or predict the outcome/ response of one variable (dependent variable) on the basis of other variables (independent variable). For example, sales of certain product depends of price, advertising cost, quality of the product, brand etc.\nIt involves developing a mathematical model or equation that describes the relationship between the dependent variable and the independent variables.\nIn the following section we will discuss about the Simple linear regression (SLR) where a independent variable and a dependent variable are involved.\n\n11.5.1 Population regression function (PRF)\n\\[\ny_i=\\beta_0+\\beta_1 x_i+\\epsilon_i \\hspace{10pt} ; i=1,2,3,..., N\n\\tag{11.4}\\]\nWhere,\n\\(y\\)= dependent variable\n\\(x\\)= independent variable\n\\(\\beta_0\\) =y-intercept\n\\(\\beta_1\\)= slope of the line/ regression coefficient\n\\(\\varepsilon\\) = error variable\nAssumptions\ni) The errors are independently, identically normally distributed with constant variance \\(\\sigma_\\varepsilon ^2\\) that is \\(\\varepsilon_i \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma_\\epsilon^2)\\) .\nii) The independent variable should not be correlated with the error term (no endogeneity)\nTaking conditional expectation of of PRF for a given \\(x_i\\) we have\n\\[\nE(y_i/x_i)=\\beta_0+\\beta_1 x_i\n\\tag{11.5}\\]\nFrom sample data we have to estimate \\(E(y_i/x_i)\\) which is equivalent to estimate \\(\\beta_0\\) and \\(\\beta_1\\).\n\n\n11.5.2 Ordinary least square (OLS) estimate of \\(E(y_i/x_i)\\)\nLet we have \\(n\\) pairs of sample data: \\(\\{X,Y\\}=\\{ (x_1,y_1), (x_2,y_2),..., (x_n, y_n) \\}\\). From the sample data suppose the estimated regression line of \\(E(y_i/x_i)\\) is\n\\[\n\\hat y_i= \\hat \\beta_0+\\hat \\beta_1 x_i \\hspace {10pt}; i=1,2,....,n\n\\]\nSo,\n\\[\ny_i=\\hat y_i +e_i \\hspace{10pt} ; i=1,2, ..., n\n\\]\nWhere, \\(e_i\\) is the estimated error or residual.\nNow, the sum of square of residuals (SSR) is given as:\n\\[\nSSR=\\sum_{i=1}^n e_i^2=\\sum_{i=1}^n (y_i-\\hat y_i)^2=\\sum_{i=1}^n (y_i-\\hat \\beta_0-\\hat \\beta_1x_i)^2\n\\tag{11.6}\\]\nIn OLS method we minimize the SSR with respect to \\(\\hat \\beta_0\\) and \\(\\hat \\beta_1\\). To minimize SSR we have to set two equations using partial derivative:\n\\[\n\\frac{\\delta \\hspace{1pt} (SSR)}{\\delta \\hat \\beta_0}=0\n\\tag{11.7}\\]\n\\[\n\\frac{\\delta \\hspace{1pt} (SSR)}{\\delta \\hat \\beta_1}=0\n\\tag{11.8}\\]\nBy solving the two equations we will have the OLS estimates of \\(\\beta_0\\) and \\(\\beta_1\\) as follows:\n\\[\n\\hat \\beta_0=\\bar y-\\hat \\beta_1 \\bar x\n\\]and\n\\[\n\\hat \\beta_1=\\frac{\\sum_{i=1}^n (x_i-\\bar x)(y_i-\\bar y)} {\\sum_{i=1}^n (x_i-\\bar x)^2}=\\frac{s_{xy}}{s^2_x}\n\\]\nOr,\n\\[\n\\hat \\beta_1=r_{xy} \\left (\\frac{s_y}{s_x}\\right )\n\\]\nThus, the estimated regression line is given by\n\\[\n\\hat y_i=\\hat \\beta_0+\\hat \\beta_1 x_i\n\\]\n\n\n11.5.3 Point prediction of \\(y\\) for a give \\(x\\)\nGiven \\(x=x_g\\). Then the estimated \\(y\\) for given \\(x\\) is\n\\[\n\\hat y_g=\\hat \\beta _0+\\hat \\beta_1 \\times x_g\n\\]\n\n\n11.5.4 Partition of sum squares\ni) Total sum of square,\n\\[\nSS(Total)=\\sum_{i=1}^n (y_i-\\bar y)^2=(n-1) s^2_y\n\\]\nii) Regression sum of square,\n\\[\nSSR=\\sum_{i=1}^n (\\hat y_i-\\bar y)^2\n\\]\nIn the case of SLR, SSR can be written as \\[SSR=\\hat \\beta_1^2\\sum_{i=1}^n (x_i-\\bar x)^2=\\hat \\beta_1^2 (n-1)s_y^2\\]\niii) Sum of square of error,\n\\[\nSSE=\\sum_{i=1}^n (y_i-\\hat y_i)^2=SS(Total)-SSR\n\\]\n\n\n11.5.5 Coefficient of determination (Goodness of fit)\n\\[\nR^2=\\frac{SSR}{SS(Total)}  \\hspace{10pt}; \\hspace{10pt} 0\\le R^2\\le1\n\\]\nInterpretation: The \\(R^2\\) explains the amount of variation in \\(Y\\) (dependent variable) by the estimated model.\nIn the case of SLR,\n\\[\nR^2=r_{xy}^2=\\frac{s^2_{xy}}{s_x^2 \\times s^2_y}\n\\]\n\n\n11.5.6 Some problems on SLR\nProblem 10.5.1 : The owner of a paint store was attempting to analyse the relationship between advertising and sales, and recorded the monthly advertising budget ($’000) and the sales ($m) for a sample of 12 months. The data are listed here:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertising\n23\n46\n60\n54\n28\n33\n25\n31\n36\n88\n95\n99\n\n\nSales\n8\n11\n13\n13\n8.9\n10.7\n9\n10.4\n11\n14\n14.4\n15.9\n\n\n\ni) Identify the dependent and independent variable.\nii) Plot the data. Is it appear to be linear?\niii) Now, fit/ estimate a linear regression line.\niv) Interpret the regression/slope coefficient.\nv) Predict the sales for the advertising cost $70, 000.\nvi) Comment about goodness of fit of the estimated model.\nProblem 10.5.2 Age and Blood Pressure. The ages (in years) of 10 men and their systolic blood pressures (in millimeters of mercury).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAge\n16\n25\n39\n45\n49\n64\n70\n29\n57\n22\n\n\nSystolic blood pressure (SBP)\n109\n128\n143\n145\n199\n185\n180\n130\n175\n118\n\n\n\ni) Identify the dependent and independent variable.\nii) Plot the data. Is it appear to be linear?\niii) Now, fit/ estimate a linear regression line.\niv) Interpret the regression/slope coefficient.\nv) Predict the SBP for the age of a person is 40 years .\nvi) Comment about goodness of fit of the estimated model.\nSolution:\nLet, \\(Y\\)=Systolic blood pressure, SBP and \\(X\\) = age (in years)\ni) Here SBP is dependent variable and age is independent variable\nii) Scatter plot of Age versus SBP\n\n\nCode\nlibrary(tidyverse)\nage&lt;-c(16,25,39,45,49,64,70,29,57,22)\nsbp&lt;-c(109,128,143,145,180,185,199,130,175,118)\n#length(sbp)\n#plot(age,sbp,pch=19)\n\nggplot(data.frame(age,sbp),aes(age,sbp))+\n  geom_point()+geom_smooth(method = \"lm\",se=FALSE,lwd=0.5)+\n  labs(x=\"Age (in years)\", y= \"SBP (Hg m)\")+\n  theme_bw()\n\n\n\n\n\n\n\n\nFigure 11.5: Sacter plot of Age and SBP\n\n\n\n\n\nThe scatter plot appears to be linear.\niii) Let the estimated regression line is :\n\\[\n\\hat y_i=\\hat \\beta_0 +\\hat \\beta_1 x_i \\hspace{40pt} (1)\n\\]\nFrom sample data;\n\\(n=10, \\sum x =416  , \\sum y=1512 , \\sum x^2 =20398\\),\n\\(\\sum y^2=237414, \\sum xy=67977\\)\n\\(\\bar x=41.6 , \\hspace{10pt} \\bar y=151.2\\)\nSo,\n\\[\ns_{xy}=\\frac{\\sum xy-n \\cdot \\bar x \\cdot \\bar y}{n-1}=\\frac{67977-10\\times 41.6\\times 151.2}{10-1}=564.2\n\\]\n\\[\ns^2_x=\\frac{\\sum x^2 -n\\times \\bar x^2}{n-1}=343.6\n\\]\n\\[\ns^2_y=\\frac{\\sum y^2 -n\\times \\bar y^2}{n-1}=977.7333\n\\]\n\n\nCode\nsumfun&lt;-function(x,y){\n  sumX=sum(x)\n  sumY=sum(y)\n  sumXY=sum(x*y)\n  sumX_sq=sum(x^2)\n  sumY_sq=sum(y^2)\n  cat( \"SumX=\",sumX, \"\\n\", \"SumY=\",sumY,\"\\n\", \"SumXY=\",sumXY,\"\\n\",\n      \"SumX_sq=\",sumX_sq,\"\\n\", \"SumY_sq=\",sumY_sq)\n}\n\n#sumfun(age,sbp)\n#cov(age,sbp)\n\n\nHence,\n\\[\n\\hat \\beta_1=\\frac{s_{xy}}{s^2_x}=\\frac{564.2}{343.6}=1.642026\\approx 1.642\n\\]\nand,\n\\[\n\\hat \\beta_0=\\bar y-\\hat \\beta_1 \\bar x=151.2-1.642026\\times41.6=82.89172\\approx82.8917\n\\]\n\\[\n\\therefore \\hat y_i=82.8917+1.642\\hspace{3pt}x_i \\hspace{5pt}\n\\]\niv) Interpretation of the regression/slope coefficient:\nHere \\(\\hat \\beta_1=1.642\\) implies that as one year increases, the SBP will increases by 1.642 Hg m on average.\nv) Predict the SBP for the age of a person is 40 years:\nFor \\(x=40\\) years, the predicted SBP (in Hg m) is\n\\(\\hat y_g =82.8917+1.642\\times 40=148.5728\\) Hg m\nvi) Comment about goodness of fit of the estimated model:\nThe goodness of fit measure is\n\\[\nR^2=\\frac{s^2_{xy} }{s^2_x \\cdot s^2_y}=\\frac{(564.2)^2}{(343.6)(977.7333)}=0.9475\n\\]\nHence, \\(R^2=0.9475\\) implies that 94.75% variation in “SBP” can be explained by the estimated model.\n\n\n\n\nAnderson, David R. 2020a. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\n———. 2020b. Statistics for Business & Economics. 14e ed. Boston, MA: Cengage.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics. 10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nLarson, Ron, and Betsy Farber. 2015. Elementary statistics: picturing the world. 6. ed., global ed. Always Learning. Boston, Mass.: Pearson.\n\n\nMesserli, Franz H. 2012. “Chocolate Consumption, Cognitive Function, and Nobel Laureates.” New England Journal of Medicine 367 (16): 1562–64. https://doi.org/10.1056/nejmon1211064.\n\n\nSelvamuthu, Dharmaraja, and Dipayan Das. 2024. Introduction to Probability, Statistical Methods, Design of Experiments and Statistical Quality Control. Springer Nature Singapore. https://doi.org/10.1007/978-981-99-9363-5.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Correlation and Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Anderson, David R. 2020a. Statistics for Business &\nEconomics. 14e ed. Boston, MA: Cengage.\n\n\n———. 2020b. Statistics for Business & Economics. 14e ed.\nBoston, MA: Cengage.\n\n\nAnderson, David R., and Dennis J. Sweeney. 2011. Statistics for\nBusiness and Economics. 11e [ed.]. Australia ; Mason, Ohio:\nSouth-Western Cengage Learning.\n\n\nBlack, Ken. 2012. Business statistics: for contemporary decision\nmaking. 7th ed. Hoboken, NJ: Wiley.\n\n\nKeller, Gerald. 2014. Statistics for Management and Economics.\n10e ed. Stamford, CT, USA : Cengage Learning.\n\n\nLarson, Ron, and Betsy Farber. 2015. Elementary statistics:\npicturing the world. 6. ed., global ed. Always Learning. Boston,\nMass.: Pearson.\n\n\nLind, Douglas A., William G. Marchal, and Samuel Adam Wathen. 2012.\nStatistical Techniques in Business & Economics. 15th ed.\nNew York, NY: McGraw-Hill/Irwin.\n\n\nMesserli, Franz H. 2012. “Chocolate Consumption, Cognitive\nFunction, and Nobel Laureates.” New England Journal of\nMedicine 367 (16): 1562–64. https://doi.org/10.1056/nejmon1211064.\n\n\nMontgomery, Douglas C., and George C. Runger. 2014. Applied\nStatistics and Probability for Engineers. Sixth edition. Hoboken,\nNJ: John Wiley; Sons, Inc.\n\n\nNewbold, Paul, William L. Carlson, and Betty M. Thorne. 2013.\nStatistics for business and economics. 8. ed., global ed.\nAlways learning. Boston, Mass. Munich: Pearson.\n\n\nR Core Team. 2024. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nSelvamuthu, Dharmaraja, and Dipayan Das. 2024. Introduction to\nProbability, Statistical Methods, Design of Experiments and Statistical\nQuality Control. Springer Nature Singapore. https://doi.org/10.1007/978-981-99-9363-5.\n\n\nWalpole, Ronald E., Raymond H. Myers, Sharon L. Myers, and Keying Ye.\n2017. Probability & statistics for engineers & scientists:\nMyStatLab update. Ninth edition. Boston: Pearson.",
    "crumbs": [
      "References"
    ]
  }
]